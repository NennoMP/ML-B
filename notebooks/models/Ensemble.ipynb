{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d3416e-3aee-496b-9a46-d86fab3fe008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15985a7e-4206-4f13-aaad-d38982df5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 01:09:24.043456: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, ValidationCurveDisplay\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal, HeNormal, GlorotUniform, Constant, Zeros\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "dir_parts = os.getcwd().split(os.path.sep)\n",
    "root_index = dir_parts.index('ML-B')\n",
    "root_path = os.path.sep.join(dir_parts[:root_index + 1])\n",
    "sys.path.append(root_path + '/code/')\n",
    "from data.data_config import Dataset\n",
    "from data.data_utils import load_monk, load_cup, store_monk_result, store_cup_result\n",
    "from hyperparameter_tuning import grid_search, random_search, tuning_search_top_configs\n",
    "from training.solver import Solver\n",
    "from training.metrics import mean_euclidean_error as mee\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c866a15-7062-4d33-a206-2ec35f8643f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ENSEMBLE [MODIFICARE COMMENTO SOTTO]\n",
    "In this notebook we implement and test a custom (feed-forward) Neural Network w.r.t. the tasks at hand, i.e. the three MONK's problem and the CUP dataset.\n",
    "\n",
    "Specifically:\n",
    "- **get_nn_classifier(...)**: defines the NN classifier for the MONK's problems;\n",
    "- **get_nn_regressor(...)**: defines the NN regressor for the CUP dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a076d-71ee-46dc-949f-caa3a3bf2df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcfe3c3-e764-453e-879e-96937623ab48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Ensemble'\n",
    "INTERNAL_TEST_SPLIT = 0.1 # internal test split percentage\n",
    "RANDOM_STATE = 128 # reproducibility\n",
    "N_SPLITS = 5 # cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84564330-d564-4700-9865-88576073b71b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b342ae0-1ef2-4bdb-9128-cd10ac83adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "results_dir = root_path + '/results/' + MODEL_NAME\n",
    "\n",
    "# Filepaths (MONK)\n",
    "m1_dev_path, m1_test_path = Dataset.MONK_1.dev_path, Dataset.MONK_1.test_path # MONK 1\n",
    "m2_dev_path, m2_test_path = Dataset.MONK_2.dev_path, Dataset.MONK_2.test_path # MONK 2\n",
    "m3_dev_path, m3_test_path = Dataset.MONK_3.dev_path, Dataset.MONK_3.test_path # MONK 3\n",
    "\n",
    "# Filepaths (CUP)\n",
    "cup_dev_path, cup_test_path = Dataset.CUP.dev_path, Dataset.CUP.test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645437d0-0b3d-412a-a595-51c05110bd03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Models and Ensemles - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad13309-e6ed-43ce-b6be-b641c3a9f418",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model: NN-SGD and NN-Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8787a40f-87d1-45e9-b24d-90b45367ab60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_classifier( optimizer, hparams):\n",
    "    initializer = GlorotUniform(seed=RANDOM_STATE) # Glorot (Xavier)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(hparams['h_dim'], activation='tanh', input_shape=(17,), kernel_initializer=initializer),\n",
    "        Dense(1, activation='sigmoid', kernel_regularizer=l2(hparams['reg']))\n",
    "    ])\n",
    "       \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'mse'])\n",
    "    \n",
    "    model.hparams = hparams\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a5983-8312-4a05-891d-8f919b7935f3",
   "metadata": {},
   "source": [
    "## Ensemble Majority Voting Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6e6cfb-13c1-4cee-8c1b-5d15008633d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_majority_voting(ensemble, svc_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    for i in range(len(ensemble)):\n",
    "        if (svc_preds[i] + nn_sgd_preds[i] + nn_adam_preds[i]) > 1:\n",
    "            ensemble[i] = 1\n",
    "            \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6663eb-164a-426a-8198-6ce6f8b97b1d",
   "metadata": {},
   "source": [
    "## Ensemble Weigheted Voting Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563f4e9b-62fc-4146-8fda-3798e3ab89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weights used are the accuracy\n",
    "def ensemble_weighted_voting(ensemble, svc_preds, nn_sgd_preds, nn_adam_preds, acc_svc, acc_nn_sgd, acc_nn_adam):\n",
    "    for i in range(len(ensemble)):\n",
    "        if (svc_preds[i]*acc_svc + nn_sgd_preds[i]*acc_nn_sgd + nn_adam_preds[i]*acc_nn_adam)/(acc_svc + acc_nn_sgd + acc_nn_adam) >= 0.5:\n",
    "            ensemble[i] = 1\n",
    "            \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05596903-1255-4b87-9ca9-9caa36ad3172",
   "metadata": {},
   "source": [
    "## Ensemble Stacking Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7beb21f-c3de-4d86-9e07-4c383ae0035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_stacking(svc_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    svc_preds = svc_preds.reshape(-1,1)\n",
    "    x_stack = np.hstack((svc_preds, nn_sgd_preds, nn_adam_preds))\n",
    "    clf = LogisticRegression(random_state=RANDOM_STATE)\n",
    "    return clf, x_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859824b9-6c6c-4f09-b4d9-ad5f9c5e2b29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MONK-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905cca8a-3ad3-4f0f-a1d8-8ff6253f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-1\n",
    "x_dev_m1, y_dev_m1, x_test_m1, y_test_m1 = load_monk(m1_dev_path, m1_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5a366-1520-4768-a26e-f461426e2393",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e2540a-245b-47fb-a675-e53749c02f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m1 = SVC(C=10, degree=2, kernel='poly')\n",
    "svc_m1.fit(x_dev_m1, y_dev_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102a1f41-1825-41af-9d22-e526af69b270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 01:09:28.446847: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6823 - accuracy: 0.6048 - mse: 0.2445\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6597 - accuracy: 0.6129 - mse: 0.2338\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6435 - accuracy: 0.6290 - mse: 0.2260\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.6694 - mse: 0.2193\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.6855 - mse: 0.2133\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6048 - accuracy: 0.6855 - mse: 0.2076\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5935 - accuracy: 0.6935 - mse: 0.2024\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5827 - accuracy: 0.7097 - mse: 0.1974\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5723 - accuracy: 0.7258 - mse: 0.1927\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.7339 - mse: 0.1883\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.7419 - mse: 0.1841\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5435 - accuracy: 0.7581 - mse: 0.1801\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5347 - accuracy: 0.7581 - mse: 0.1763\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5263 - accuracy: 0.7742 - mse: 0.1728\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5183 - accuracy: 0.7661 - mse: 0.1694\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5108 - accuracy: 0.7742 - mse: 0.1663\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5038 - accuracy: 0.7742 - mse: 0.1634\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4972 - accuracy: 0.7742 - mse: 0.1608\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4910 - accuracy: 0.7903 - mse: 0.1583\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4854 - accuracy: 0.8065 - mse: 0.1561\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4801 - accuracy: 0.8065 - mse: 0.1540\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4752 - accuracy: 0.7984 - mse: 0.1521\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4707 - accuracy: 0.7984 - mse: 0.1504\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4665 - accuracy: 0.7984 - mse: 0.1487\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4626 - accuracy: 0.7984 - mse: 0.1472\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4589 - accuracy: 0.7984 - mse: 0.1458\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4555 - accuracy: 0.8065 - mse: 0.1445\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4523 - accuracy: 0.8145 - mse: 0.1433\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4492 - accuracy: 0.8226 - mse: 0.1421\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.8226 - mse: 0.1410\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4436 - accuracy: 0.8387 - mse: 0.1399\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.8387 - mse: 0.1389\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8387 - mse: 0.1379\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4359 - accuracy: 0.8387 - mse: 0.1370\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4335 - accuracy: 0.8387 - mse: 0.1360\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.8387 - mse: 0.1352\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4289 - accuracy: 0.8387 - mse: 0.1343\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4266 - accuracy: 0.8387 - mse: 0.1334\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4243 - accuracy: 0.8468 - mse: 0.1326\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4221 - accuracy: 0.8468 - mse: 0.1318\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8387 - mse: 0.1310\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8387 - mse: 0.1302\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8387 - mse: 0.1294\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8387 - mse: 0.1287\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8468 - mse: 0.1280\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4091 - accuracy: 0.8468 - mse: 0.1272\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.8468 - mse: 0.1265\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4049 - accuracy: 0.8468 - mse: 0.1258\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.8468 - mse: 0.1252\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.8468 - mse: 0.1245\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3986 - accuracy: 0.8468 - mse: 0.1238\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.8468 - mse: 0.1232\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3945 - accuracy: 0.8468 - mse: 0.1226\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8468 - mse: 0.1220\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3904 - accuracy: 0.8468 - mse: 0.1214\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3884 - accuracy: 0.8468 - mse: 0.1208\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.8468 - mse: 0.1202\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3845 - accuracy: 0.8468 - mse: 0.1196\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3825 - accuracy: 0.8468 - mse: 0.1190\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3806 - accuracy: 0.8468 - mse: 0.1185\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3787 - accuracy: 0.8468 - mse: 0.1179\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3768 - accuracy: 0.8468 - mse: 0.1174\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3750 - accuracy: 0.8468 - mse: 0.1168\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3731 - accuracy: 0.8468 - mse: 0.1163\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3713 - accuracy: 0.8468 - mse: 0.1158\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3695 - accuracy: 0.8468 - mse: 0.1153\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3677 - accuracy: 0.8468 - mse: 0.1148\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3660 - accuracy: 0.8468 - mse: 0.1143\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3642 - accuracy: 0.8468 - mse: 0.1138\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3625 - accuracy: 0.8468 - mse: 0.1133\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3608 - accuracy: 0.8468 - mse: 0.1128\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3590 - accuracy: 0.8468 - mse: 0.1123\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3574 - accuracy: 0.8468 - mse: 0.1118\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3557 - accuracy: 0.8468 - mse: 0.1113\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3540 - accuracy: 0.8468 - mse: 0.1108\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3523 - accuracy: 0.8468 - mse: 0.1103\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.8468 - mse: 0.1098\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3490 - accuracy: 0.8468 - mse: 0.1093\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3474 - accuracy: 0.8468 - mse: 0.1088\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3457 - accuracy: 0.8548 - mse: 0.1083\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3441 - accuracy: 0.8548 - mse: 0.1078\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3425 - accuracy: 0.8548 - mse: 0.1073\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8548 - mse: 0.1068\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3392 - accuracy: 0.8548 - mse: 0.1063\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3376 - accuracy: 0.8548 - mse: 0.1058\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3359 - accuracy: 0.8548 - mse: 0.1053\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.8548 - mse: 0.1048\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3326 - accuracy: 0.8548 - mse: 0.1042\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3309 - accuracy: 0.8548 - mse: 0.1037\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.8548 - mse: 0.1031\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.8548 - mse: 0.1026\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3259 - accuracy: 0.8548 - mse: 0.1020\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3242 - accuracy: 0.8629 - mse: 0.1015\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3225 - accuracy: 0.8629 - mse: 0.1009\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3208 - accuracy: 0.8629 - mse: 0.1003\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3190 - accuracy: 0.8629 - mse: 0.0997\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3173 - accuracy: 0.8629 - mse: 0.0991\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3155 - accuracy: 0.8629 - mse: 0.0985\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3137 - accuracy: 0.8629 - mse: 0.0979\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3120 - accuracy: 0.8629 - mse: 0.0973\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3102 - accuracy: 0.8629 - mse: 0.0966\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3083 - accuracy: 0.8629 - mse: 0.0960\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3065 - accuracy: 0.8629 - mse: 0.0953\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3047 - accuracy: 0.8629 - mse: 0.0947\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3028 - accuracy: 0.8629 - mse: 0.0940\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3010 - accuracy: 0.8629 - mse: 0.0933\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2991 - accuracy: 0.8629 - mse: 0.0926\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2972 - accuracy: 0.8629 - mse: 0.0919\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2953 - accuracy: 0.8629 - mse: 0.0912\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2934 - accuracy: 0.8629 - mse: 0.0905\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.8629 - mse: 0.0898\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2896 - accuracy: 0.8710 - mse: 0.0891\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2877 - accuracy: 0.8710 - mse: 0.0884\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2858 - accuracy: 0.8710 - mse: 0.0876\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2838 - accuracy: 0.8710 - mse: 0.0869\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2819 - accuracy: 0.8710 - mse: 0.0862\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.8710 - mse: 0.0854\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2780 - accuracy: 0.8710 - mse: 0.0847\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2761 - accuracy: 0.8710 - mse: 0.0839\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2742 - accuracy: 0.8790 - mse: 0.0832\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2722 - accuracy: 0.8790 - mse: 0.0824\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 0.8790 - mse: 0.0817\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2683 - accuracy: 0.8790 - mse: 0.0809\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2664 - accuracy: 0.8790 - mse: 0.0801\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2644 - accuracy: 0.8871 - mse: 0.0794\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2625 - accuracy: 0.8871 - mse: 0.0786\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2605 - accuracy: 0.8790 - mse: 0.0779\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2586 - accuracy: 0.8790 - mse: 0.0771\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2566 - accuracy: 0.8790 - mse: 0.0763\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 0.8790 - mse: 0.0756\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.8790 - mse: 0.0748\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.8790 - mse: 0.0740\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2489 - accuracy: 0.8871 - mse: 0.0733\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2470 - accuracy: 0.8952 - mse: 0.0725\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2451 - accuracy: 0.8952 - mse: 0.0718\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2431 - accuracy: 0.8952 - mse: 0.0710\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2412 - accuracy: 0.8952 - mse: 0.0703\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2393 - accuracy: 0.8952 - mse: 0.0695\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2374 - accuracy: 0.8952 - mse: 0.0688\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2355 - accuracy: 0.8952 - mse: 0.0680\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2337 - accuracy: 0.9113 - mse: 0.0673\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2318 - accuracy: 0.9113 - mse: 0.0666\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2299 - accuracy: 0.9113 - mse: 0.0658\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2280 - accuracy: 0.9194 - mse: 0.0651\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2262 - accuracy: 0.9274 - mse: 0.0644\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.9355 - mse: 0.0637\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.9355 - mse: 0.0629\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2206 - accuracy: 0.9355 - mse: 0.0622\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9355 - mse: 0.0615\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2170 - accuracy: 0.9355 - mse: 0.0608\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2151 - accuracy: 0.9355 - mse: 0.0601\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2133 - accuracy: 0.9355 - mse: 0.0594\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2114 - accuracy: 0.9355 - mse: 0.0586\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9355 - mse: 0.0579\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2077 - accuracy: 0.9355 - mse: 0.0572\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2058 - accuracy: 0.9355 - mse: 0.0565\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2040 - accuracy: 0.9355 - mse: 0.0558\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 0.9355 - mse: 0.0550\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2002 - accuracy: 0.9355 - mse: 0.0543\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.9355 - mse: 0.0535\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1963 - accuracy: 0.9355 - mse: 0.0528\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1943 - accuracy: 0.9355 - mse: 0.0520\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1924 - accuracy: 0.9435 - mse: 0.0513\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1904 - accuracy: 0.9435 - mse: 0.0505\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1883 - accuracy: 0.9435 - mse: 0.0497\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1863 - accuracy: 0.9435 - mse: 0.0489\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1843 - accuracy: 0.9435 - mse: 0.0481\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1822 - accuracy: 0.9516 - mse: 0.0474\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1801 - accuracy: 0.9516 - mse: 0.0466\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9597 - mse: 0.0458\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1759 - accuracy: 0.9597 - mse: 0.0449\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1738 - accuracy: 0.9597 - mse: 0.0441\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9597 - mse: 0.0433\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1695 - accuracy: 0.9597 - mse: 0.0425\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1674 - accuracy: 0.9597 - mse: 0.0417\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1653 - accuracy: 0.9597 - mse: 0.0409\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9677 - mse: 0.0401\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.9677 - mse: 0.0393\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9677 - mse: 0.0384\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9758 - mse: 0.0376\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1545 - accuracy: 0.9758 - mse: 0.0368\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9839 - mse: 0.0360\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1502 - accuracy: 0.9839 - mse: 0.0352\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1480 - accuracy: 0.9839 - mse: 0.0344\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1459 - accuracy: 0.9839 - mse: 0.0336\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1437 - accuracy: 0.9919 - mse: 0.0327\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9919 - mse: 0.0319\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1393 - accuracy: 0.9919 - mse: 0.0311\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9919 - mse: 0.0303\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9919 - mse: 0.0295\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1327 - accuracy: 0.9919 - mse: 0.0287\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1305 - accuracy: 0.9919 - mse: 0.0279\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9919 - mse: 0.0271\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1260 - accuracy: 0.9919 - mse: 0.0263\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1237 - accuracy: 0.9919 - mse: 0.0255\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1215 - accuracy: 0.9919 - mse: 0.0247\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 1.0000 - mse: 0.0239\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1170 - accuracy: 1.0000 - mse: 0.0231\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1147 - accuracy: 1.0000 - mse: 0.0223\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1125 - accuracy: 1.0000 - mse: 0.0215\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1103 - accuracy: 1.0000 - mse: 0.0208\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1081 - accuracy: 1.0000 - mse: 0.0201\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 1.0000 - mse: 0.0193\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1039 - accuracy: 1.0000 - mse: 0.0186\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1018 - accuracy: 1.0000 - mse: 0.0180\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0998 - accuracy: 1.0000 - mse: 0.0173\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 1.0000 - mse: 0.0167\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0959 - accuracy: 1.0000 - mse: 0.0161\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0940 - accuracy: 1.0000 - mse: 0.0155\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0921 - accuracy: 1.0000 - mse: 0.0149\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0903 - accuracy: 1.0000 - mse: 0.0144\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0886 - accuracy: 1.0000 - mse: 0.0138\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0869 - accuracy: 1.0000 - mse: 0.0134\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 1.0000 - mse: 0.0129\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 1.0000 - mse: 0.0124\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 1.0000 - mse: 0.0120\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0808 - accuracy: 1.0000 - mse: 0.0116\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0793 - accuracy: 1.0000 - mse: 0.0112\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 1.0000 - mse: 0.0108\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0766 - accuracy: 1.0000 - mse: 0.0105\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0753 - accuracy: 1.0000 - mse: 0.0101\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0741 - accuracy: 1.0000 - mse: 0.0098\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0729 - accuracy: 1.0000 - mse: 0.0095\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0717 - accuracy: 1.0000 - mse: 0.0092\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 1.0000 - mse: 0.0089\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 1.0000 - mse: 0.0086\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0684 - accuracy: 1.0000 - mse: 0.0084\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0674 - accuracy: 1.0000 - mse: 0.0081\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0664 - accuracy: 1.0000 - mse: 0.0079\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 1.0000 - mse: 0.0076\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0645 - accuracy: 1.0000 - mse: 0.0074\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0635 - accuracy: 1.0000 - mse: 0.0072\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0627 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0618 - accuracy: 1.0000 - mse: 0.0068\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0610 - accuracy: 1.0000 - mse: 0.0066\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0601 - accuracy: 1.0000 - mse: 0.0065\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0593 - accuracy: 1.0000 - mse: 0.0063\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0586 - accuracy: 1.0000 - mse: 0.0061\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0578 - accuracy: 1.0000 - mse: 0.0060\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 1.0000 - mse: 0.0058\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 1.0000 - mse: 0.0057\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 1.0000 - mse: 0.0055\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 1.0000 - mse: 0.0054\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 1.0000 - mse: 0.0053\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 1.0000 - mse: 0.0051\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 1.0000 - mse: 0.0050\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 1.0000 - mse: 0.0049\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0519 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 1.0000 - mse: 0.0047\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0507 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0501 - accuracy: 1.0000 - mse: 0.0045\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0490 - accuracy: 1.0000 - mse: 0.0043\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0485 - accuracy: 1.0000 - mse: 0.0042\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 1.0000 - mse: 0.0038\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 1.0000 - mse: 0.0033\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0371 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 1.0000 - mse: 0.0019\n",
      "Restoring best model weights.\n",
      "Best loss: 0.032545305788517\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.7, 'h_dim': 4, 'reg': 0.0}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m1 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m1, x_dev_m1, y_dev_m1, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938c77fa-41a3-4d60-9f47-8b40befe52d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7197 - accuracy: 0.5000 - mse: 0.2621\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8254 - accuracy: 0.5000 - mse: 0.3056\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6093 - accuracy: 0.7016 - mse: 0.2093\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.5000 - mse: 0.2448\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6547 - accuracy: 0.5000 - mse: 0.2335\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5711 - accuracy: 0.7500 - mse: 0.1928\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5308 - accuracy: 0.7258 - mse: 0.1748\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5300 - accuracy: 0.6774 - mse: 0.1781\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.7016 - mse: 0.1677\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4532 - accuracy: 0.7339 - mse: 0.1482\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4324 - accuracy: 0.7984 - mse: 0.1394\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4023 - accuracy: 0.8548 - mse: 0.1271\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3469 - accuracy: 0.8710 - mse: 0.1059\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3137 - accuracy: 0.8629 - mse: 0.0956\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2977 - accuracy: 0.8629 - mse: 0.0904\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2735 - accuracy: 0.8629 - mse: 0.0816\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2400 - accuracy: 0.8710 - mse: 0.0700\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2111 - accuracy: 0.8790 - mse: 0.0607\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1825 - accuracy: 0.9113 - mse: 0.0513\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1512 - accuracy: 0.9194 - mse: 0.0395\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1287 - accuracy: 0.9919 - mse: 0.0306\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1081 - accuracy: 1.0000 - mse: 0.0223\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0891 - accuracy: 1.0000 - mse: 0.0158\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0731 - accuracy: 1.0000 - mse: 0.0108\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0604 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0426 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0260 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 1.0000 - mse: 7.8844e-04\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 1.0000 - mse: 5.6961e-04\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - mse: 4.0172e-04\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 1.0000 - mse: 2.8542e-04\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - mse: 2.0701e-04\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 1.0000 - mse: 1.5337e-04\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - mse: 1.1554e-04\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0080 - accuracy: 1.0000 - mse: 8.7995e-05\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 1.0000 - mse: 6.7476e-05\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - mse: 5.2065e-05\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - mse: 4.0509e-05\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - mse: 3.1863e-05\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - mse: 2.5363e-05\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - mse: 2.0405e-05\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - mse: 1.6548e-05\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - mse: 1.3487e-05\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - mse: 1.1030e-05\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - mse: 9.0530e-06\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - mse: 7.4662e-06\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - mse: 6.1978e-06\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - mse: 5.1863e-06\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - mse: 4.3791e-06\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - mse: 3.7329e-06\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - mse: 3.2127e-06\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - mse: 2.7908e-06\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - mse: 2.4458e-06\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 2.1608e-06\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 1.9230e-06\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9047e-04 - accuracy: 1.0000 - mse: 1.7224e-06\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.2682e-04 - accuracy: 1.0000 - mse: 1.5514e-06\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6947e-04 - accuracy: 1.0000 - mse: 1.4040e-06\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1757e-04 - accuracy: 1.0000 - mse: 1.2757e-06\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7042e-04 - accuracy: 1.0000 - mse: 1.1629e-06\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2741e-04 - accuracy: 1.0000 - mse: 1.0631e-06\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.8803e-04 - accuracy: 1.0000 - mse: 9.7398e-07\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.5188e-04 - accuracy: 1.0000 - mse: 8.9394e-07\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.1858e-04 - accuracy: 1.0000 - mse: 8.2167e-07\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.8785e-04 - accuracy: 1.0000 - mse: 7.5610e-07\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5942e-04 - accuracy: 1.0000 - mse: 6.9638e-07\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3306e-04 - accuracy: 1.0000 - mse: 6.4183e-07\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0859e-04 - accuracy: 1.0000 - mse: 5.9185e-07\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8582e-04 - accuracy: 1.0000 - mse: 5.4595e-07\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6459e-04 - accuracy: 1.0000 - mse: 5.0373e-07\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4477e-04 - accuracy: 1.0000 - mse: 4.6482e-07\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2622e-04 - accuracy: 1.0000 - mse: 4.2893e-07\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.0882e-04 - accuracy: 1.0000 - mse: 3.9579e-07\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.9248e-04 - accuracy: 1.0000 - mse: 3.6517e-07\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7708e-04 - accuracy: 1.0000 - mse: 3.3687e-07\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.6256e-04 - accuracy: 1.0000 - mse: 3.1071e-07\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4883e-04 - accuracy: 1.0000 - mse: 2.8652e-07\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3583e-04 - accuracy: 1.0000 - mse: 2.6418e-07\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.2350e-04 - accuracy: 1.0000 - mse: 2.4353e-07\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1177e-04 - accuracy: 1.0000 - mse: 2.2448e-07\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0061e-04 - accuracy: 1.0000 - mse: 2.0689e-07\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8998e-04 - accuracy: 1.0000 - mse: 1.9068e-07\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7983e-04 - accuracy: 1.0000 - mse: 1.7573e-07\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.7013e-04 - accuracy: 1.0000 - mse: 1.6197e-07\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6085e-04 - accuracy: 1.0000 - mse: 1.4930e-07\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5197e-04 - accuracy: 1.0000 - mse: 1.3764e-07\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4345e-04 - accuracy: 1.0000 - mse: 1.2692e-07\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3528e-04 - accuracy: 1.0000 - mse: 1.1707e-07\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2744e-04 - accuracy: 1.0000 - mse: 1.0802e-07\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1989e-04 - accuracy: 1.0000 - mse: 9.9698e-08\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1263e-04 - accuracy: 1.0000 - mse: 9.2055e-08\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0564e-04 - accuracy: 1.0000 - mse: 8.5031e-08\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9889e-04 - accuracy: 1.0000 - mse: 7.8575e-08\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9238e-04 - accuracy: 1.0000 - mse: 7.2644e-08\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8609e-04 - accuracy: 1.0000 - mse: 6.7190e-08\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8000e-04 - accuracy: 1.0000 - mse: 6.2171e-08\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7411e-04 - accuracy: 1.0000 - mse: 5.7554e-08\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6840e-04 - accuracy: 1.0000 - mse: 5.3300e-08\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6286e-04 - accuracy: 1.0000 - mse: 4.9381e-08\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5749e-04 - accuracy: 1.0000 - mse: 4.5766e-08\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5226e-04 - accuracy: 1.0000 - mse: 4.2432e-08\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4718e-04 - accuracy: 1.0000 - mse: 3.9351e-08\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4224e-04 - accuracy: 1.0000 - mse: 3.6502e-08\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3743e-04 - accuracy: 1.0000 - mse: 3.3868e-08\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3274e-04 - accuracy: 1.0000 - mse: 3.1431e-08\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2817e-04 - accuracy: 1.0000 - mse: 2.9172e-08\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2372e-04 - accuracy: 1.0000 - mse: 2.7077e-08\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1938e-04 - accuracy: 1.0000 - mse: 2.5134e-08\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1515e-04 - accuracy: 1.0000 - mse: 2.3330e-08\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1102e-04 - accuracy: 1.0000 - mse: 2.1654e-08\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0700e-04 - accuracy: 1.0000 - mse: 2.0095e-08\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0307e-04 - accuracy: 1.0000 - mse: 1.8646e-08\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.9248e-05 - accuracy: 1.0000 - mse: 1.7297e-08\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5522e-05 - accuracy: 1.0000 - mse: 1.6041e-08\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1892e-05 - accuracy: 1.0000 - mse: 1.4872e-08\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.8358e-05 - accuracy: 1.0000 - mse: 1.3783e-08\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4919e-05 - accuracy: 1.0000 - mse: 1.2767e-08\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1574e-05 - accuracy: 1.0000 - mse: 1.1820e-08\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.8322e-05 - accuracy: 1.0000 - mse: 1.0937e-08\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5163e-05 - accuracy: 1.0000 - mse: 1.0114e-08\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2095e-05 - accuracy: 1.0000 - mse: 9.3458e-09\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9119e-05 - accuracy: 1.0000 - mse: 8.6307e-09\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6232e-05 - accuracy: 1.0000 - mse: 7.9633e-09\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3435e-05 - accuracy: 1.0000 - mse: 7.3409e-09\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.0727e-05 - accuracy: 1.0000 - mse: 6.7613e-09\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8106e-05 - accuracy: 1.0000 - mse: 6.2212e-09\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.5571e-05 - accuracy: 1.0000 - mse: 5.7185e-09\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3122e-05 - accuracy: 1.0000 - mse: 5.2503e-09\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0757e-05 - accuracy: 1.0000 - mse: 4.8156e-09\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8474e-05 - accuracy: 1.0000 - mse: 4.4109e-09\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6273e-05 - accuracy: 1.0000 - mse: 4.0357e-09\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.4152e-05 - accuracy: 1.0000 - mse: 3.6876e-09\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.2109e-05 - accuracy: 1.0000 - mse: 3.3656e-09\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0143e-05 - accuracy: 1.0000 - mse: 3.0674e-09\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8252e-05 - accuracy: 1.0000 - mse: 2.7922e-09\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6435e-05 - accuracy: 1.0000 - mse: 2.5383e-09\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4690e-05 - accuracy: 1.0000 - mse: 2.3041e-09\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3015e-05 - accuracy: 1.0000 - mse: 2.0893e-09\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1409e-05 - accuracy: 1.0000 - mse: 1.8923e-09\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9869e-05 - accuracy: 1.0000 - mse: 1.7116e-09\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8395e-05 - accuracy: 1.0000 - mse: 1.5464e-09\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6985e-05 - accuracy: 1.0000 - mse: 1.3957e-09\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5636e-05 - accuracy: 1.0000 - mse: 1.2582e-09\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4346e-05 - accuracy: 1.0000 - mse: 1.1332e-09\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3115e-05 - accuracy: 1.0000 - mse: 1.0198e-09\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1940e-05 - accuracy: 1.0000 - mse: 9.1695e-10\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.0819e-05 - accuracy: 1.0000 - mse: 8.2401e-10\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9750e-05 - accuracy: 1.0000 - mse: 7.3960e-10\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8732e-05 - accuracy: 1.0000 - mse: 6.6392e-10\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7762e-05 - accuracy: 1.0000 - mse: 5.9527e-10\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6839e-05 - accuracy: 1.0000 - mse: 5.3388e-10\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5961e-05 - accuracy: 1.0000 - mse: 4.7826e-10\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5126e-05 - accuracy: 1.0000 - mse: 4.2845e-10\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4333e-05 - accuracy: 1.0000 - mse: 3.8377e-10\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3579e-05 - accuracy: 1.0000 - mse: 3.4375e-10\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2863e-05 - accuracy: 1.0000 - mse: 3.0764e-10\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2183e-05 - accuracy: 1.0000 - mse: 2.7547e-10\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1538e-05 - accuracy: 1.0000 - mse: 2.4658e-10\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0926e-05 - accuracy: 1.0000 - mse: 2.2083e-10\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0346e-05 - accuracy: 1.0000 - mse: 1.9759e-10\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7957e-06 - accuracy: 1.0000 - mse: 1.7702e-10\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2741e-06 - accuracy: 1.0000 - mse: 1.5841e-10\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7798e-06 - accuracy: 1.0000 - mse: 1.4193e-10\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3115e-06 - accuracy: 1.0000 - mse: 1.2717e-10\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8679e-06 - accuracy: 1.0000 - mse: 1.1384e-10\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.4479e-06 - accuracy: 1.0000 - mse: 1.0202e-10\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.0502e-06 - accuracy: 1.0000 - mse: 9.1404e-11\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.6738e-06 - accuracy: 1.0000 - mse: 8.1907e-11\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3175e-06 - accuracy: 1.0000 - mse: 7.3466e-11\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.9803e-06 - accuracy: 1.0000 - mse: 6.5779e-11\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.6612e-06 - accuracy: 1.0000 - mse: 5.9077e-11\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3594e-06 - accuracy: 1.0000 - mse: 5.2889e-11\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.0738e-06 - accuracy: 1.0000 - mse: 4.7512e-11\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8037e-06 - accuracy: 1.0000 - mse: 4.2621e-11\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.5482e-06 - accuracy: 1.0000 - mse: 3.8214e-11\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.3065e-06 - accuracy: 1.0000 - mse: 3.4355e-11\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.0779e-06 - accuracy: 1.0000 - mse: 3.0792e-11\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8617e-06 - accuracy: 1.0000 - mse: 2.7646e-11\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6572e-06 - accuracy: 1.0000 - mse: 2.4807e-11\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4638e-06 - accuracy: 1.0000 - mse: 2.2259e-11\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2809e-06 - accuracy: 1.0000 - mse: 1.9990e-11\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1079e-06 - accuracy: 1.0000 - mse: 1.7988e-11\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9442e-06 - accuracy: 1.0000 - mse: 1.6158e-11\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7894e-06 - accuracy: 1.0000 - mse: 1.4521e-11\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6430e-06 - accuracy: 1.0000 - mse: 1.3052e-11\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5045e-06 - accuracy: 1.0000 - mse: 1.1695e-11\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3735e-06 - accuracy: 1.0000 - mse: 1.0540e-11\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2496e-06 - accuracy: 1.0000 - mse: 9.4793e-12\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1324e-06 - accuracy: 1.0000 - mse: 8.5264e-12\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0215e-06 - accuracy: 1.0000 - mse: 7.6322e-12\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9165e-06 - accuracy: 1.0000 - mse: 6.8953e-12\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8172e-06 - accuracy: 1.0000 - mse: 6.1893e-12\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7233e-06 - accuracy: 1.0000 - mse: 5.5720e-12\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6343e-06 - accuracy: 1.0000 - mse: 5.0104e-12\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5502e-06 - accuracy: 1.0000 - mse: 4.4992e-12\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4705e-06 - accuracy: 1.0000 - mse: 4.0572e-12\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3951e-06 - accuracy: 1.0000 - mse: 3.6339e-12\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3236e-06 - accuracy: 1.0000 - mse: 3.2692e-12\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2560e-06 - accuracy: 1.0000 - mse: 2.9631e-12\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1920e-06 - accuracy: 1.0000 - mse: 2.6476e-12\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1314e-06 - accuracy: 1.0000 - mse: 2.3965e-12\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0739e-06 - accuracy: 1.0000 - mse: 2.1662e-12\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0195e-06 - accuracy: 1.0000 - mse: 1.9317e-12\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.6799e-07 - accuracy: 1.0000 - mse: 1.7607e-12\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.1910e-07 - accuracy: 1.0000 - mse: 1.5731e-12\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.7281e-07 - accuracy: 1.0000 - mse: 1.4205e-12\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.2895e-07 - accuracy: 1.0000 - mse: 1.2789e-12\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.8735e-07 - accuracy: 1.0000 - mse: 1.1511e-12\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.4793e-07 - accuracy: 1.0000 - mse: 1.0310e-12\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1059e-07 - accuracy: 1.0000 - mse: 9.3452e-13\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7522e-07 - accuracy: 1.0000 - mse: 8.4121e-13\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.4167e-07 - accuracy: 1.0000 - mse: 7.5648e-13\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.0984e-07 - accuracy: 1.0000 - mse: 6.9682e-13\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.7965e-07 - accuracy: 1.0000 - mse: 6.2388e-13\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5105e-07 - accuracy: 1.0000 - mse: 5.5439e-13\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2395e-07 - accuracy: 1.0000 - mse: 5.1050e-13\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9825e-07 - accuracy: 1.0000 - mse: 4.6071e-13\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7385e-07 - accuracy: 1.0000 - mse: 4.1136e-13\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5069e-07 - accuracy: 1.0000 - mse: 3.7569e-13\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.2866e-07 - accuracy: 1.0000 - mse: 3.3895e-13\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0777e-07 - accuracy: 1.0000 - mse: 3.0821e-13\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8798e-07 - accuracy: 1.0000 - mse: 2.7295e-13\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6923e-07 - accuracy: 1.0000 - mse: 2.4687e-13\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5147e-07 - accuracy: 1.0000 - mse: 2.2480e-13\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3461e-07 - accuracy: 1.0000 - mse: 2.0493e-13\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1861e-07 - accuracy: 1.0000 - mse: 1.8668e-13\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0340e-07 - accuracy: 1.0000 - mse: 1.7114e-13\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8893e-07 - accuracy: 1.0000 - mse: 1.5211e-13\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7515e-07 - accuracy: 1.0000 - mse: 1.3708e-13\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6203e-07 - accuracy: 1.0000 - mse: 1.2420e-13\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4953e-07 - accuracy: 1.0000 - mse: 1.1874e-13\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3771e-07 - accuracy: 1.0000 - mse: 1.0739e-13\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2654e-07 - accuracy: 1.0000 - mse: 9.6750e-14\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1596e-07 - accuracy: 1.0000 - mse: 8.6233e-14\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0596e-07 - accuracy: 1.0000 - mse: 7.5199e-14\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9647e-07 - accuracy: 1.0000 - mse: 7.0923e-14\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8748e-07 - accuracy: 1.0000 - mse: 6.2457e-14\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7897e-07 - accuracy: 1.0000 - mse: 5.9146e-14\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7089e-07 - accuracy: 1.0000 - mse: 5.1816e-14\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6320e-07 - accuracy: 1.0000 - mse: 4.9164e-14\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5589e-07 - accuracy: 1.0000 - mse: 4.2918e-14\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4894e-07 - accuracy: 1.0000 - mse: 4.0839e-14\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4232e-07 - accuracy: 1.0000 - mse: 3.9009e-14\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3600e-07 - accuracy: 1.0000 - mse: 3.3970e-14\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2996e-07 - accuracy: 1.0000 - mse: 3.2576e-14\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2419e-07 - accuracy: 1.0000 - mse: 2.8275e-14\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1869e-07 - accuracy: 1.0000 - mse: 2.2958e-14\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1344e-07 - accuracy: 1.0000 - mse: 2.1881e-14\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0844e-07 - accuracy: 1.0000 - mse: 2.1104e-14\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0368e-07 - accuracy: 1.0000 - mse: 1.7923e-14\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9156e-08 - accuracy: 1.0000 - mse: 1.7369e-14\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4878e-08 - accuracy: 1.0000 - mse: 1.8285e-14\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0847e-08 - accuracy: 1.0000 - mse: 1.8743e-14\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7053e-08 - accuracy: 1.0000 - mse: 1.5102e-14\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3435e-08 - accuracy: 1.0000 - mse: 1.4954e-14\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9968e-08 - accuracy: 1.0000 - mse: 1.3810e-14\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6652e-08 - accuracy: 1.0000 - mse: 1.3999e-14\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3506e-08 - accuracy: 1.0000 - mse: 1.1399e-14\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0551e-08 - accuracy: 1.0000 - mse: 1.1482e-14\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7812e-08 - accuracy: 1.0000 - mse: 1.0113e-14\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5313e-08 - accuracy: 1.0000 - mse: 7.9093e-15\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3068e-08 - accuracy: 1.0000 - mse: 8.8315e-15\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1088e-08 - accuracy: 1.0000 - mse: 7.1816e-15\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9378e-08 - accuracy: 1.0000 - mse: 8.4599e-15\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7936e-08 - accuracy: 1.0000 - mse: 6.4747e-15\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6758e-08 - accuracy: 1.0000 - mse: 7.7820e-15\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5794e-08 - accuracy: 1.0000 - mse: 6.3926e-15\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4894e-08 - accuracy: 1.0000 - mse: 6.4925e-15\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3638e-08 - accuracy: 1.0000 - mse: 5.1765e-15\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1976e-08 - accuracy: 1.0000 - mse: 5.8636e-15\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0239e-08 - accuracy: 1.0000 - mse: 5.6834e-15\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8606e-08 - accuracy: 1.0000 - mse: 5.4228e-15\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7152e-08 - accuracy: 1.0000 - mse: 5.9351e-15\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5866e-08 - accuracy: 1.0000 - mse: 5.3011e-15\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4752e-08 - accuracy: 1.0000 - mse: 4.4372e-15\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3795e-08 - accuracy: 1.0000 - mse: 4.3763e-15\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2981e-08 - accuracy: 1.0000 - mse: 4.5464e-15\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2301e-08 - accuracy: 1.0000 - mse: 5.4067e-15\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1749e-08 - accuracy: 1.0000 - mse: 5.0095e-15\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1318e-08 - accuracy: 1.0000 - mse: 3.8137e-15\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0986e-08 - accuracy: 1.0000 - mse: 4.3411e-15\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0732e-08 - accuracy: 1.0000 - mse: 3.4404e-15\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0497e-08 - accuracy: 1.0000 - mse: 3.8630e-15\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0202e-08 - accuracy: 1.0000 - mse: 5.0653e-15\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9729e-08 - accuracy: 1.0000 - mse: 3.2091e-15\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9082e-08 - accuracy: 1.0000 - mse: 3.1635e-15\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8330e-08 - accuracy: 1.0000 - mse: 4.4684e-15\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7576e-08 - accuracy: 1.0000 - mse: 2.9385e-15\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6874e-08 - accuracy: 1.0000 - mse: 4.2743e-15\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6257e-08 - accuracy: 1.0000 - mse: 4.4928e-15\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5715e-08 - accuracy: 1.0000 - mse: 2.3047e-15\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5278e-08 - accuracy: 1.0000 - mse: 3.3251e-15\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4936e-08 - accuracy: 1.0000 - mse: 4.0016e-15\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4682e-08 - accuracy: 1.0000 - mse: 4.5636e-15\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4551e-08 - accuracy: 1.0000 - mse: 3.0619e-15\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4491e-08 - accuracy: 1.0000 - mse: 4.1960e-15\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4498e-08 - accuracy: 1.0000 - mse: 3.6398e-15\n",
      "Restoring best model weights.\n",
      "Best loss: 3.449123653354036e-08\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m1 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m1, x_dev_m1, y_dev_m1, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de513a-1019-4b7c-b919-054ff7b325f0",
   "metadata": {},
   "source": [
    "## Ensemble - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9436244f-e383-486e-a1f7-38b02bb9cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m1_preds_dev = svc_m1.predict(x_dev_m1)\n",
    "nn_sgd_m1_preds_dev = (np.rint(nn_sgd_m1.predict(x_dev_m1))).astype(int)\n",
    "nn_adam_m1_preds_dev = (np.rint(nn_adam_m1.predict(x_dev_m1))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m1_preds_dev = nn_sgd_m1.predict(x_dev_m1)\n",
    "#nn_adam_m1_preds_dev = nn_adam_m1.predict(x_dev_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c393712e-d64d-4882-b7a2-18d0a39ccb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0323 - accuracy: 1.0000 - mse: 0.0019\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.4498e-08 - accuracy: 1.0000 - mse: 3.6398e-15\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m1_dev = accuracy_score(y_dev_m1, svc_m1_preds_dev)\n",
    "acc_nn_sgd_m1_dev = nn_sgd_m1.evaluate(x_dev_m1, y_dev_m1)[1]\n",
    "acc_nn_adam_m1_dev = nn_adam_m1.evaluate(x_dev_m1, y_dev_m1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42799ad8-01e6-43de-94c2-02419f441d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m1), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev,\n",
    "                                          acc_svc_m1_dev, acc_nn_sgd_m1_dev, acc_nn_sgd_m1_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3896e0-9ec9-41d9-a223-a72d2dee5d8e",
   "metadata": {},
   "source": [
    "## Results Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79ac744c-68b2-412d-ae72-cc3126fd83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m1_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m1_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m1_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m1 = accuracy_score(y_dev_m1, en_maj_vot_dev)\n",
    "mse_dev_maj_m1 = mean_squared_error(y_dev_m1, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m1:.4f} - Accuracy: {acc_dev_maj_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m1 = accuracy_score(y_dev_m1, en_wei_vot_dev)\n",
    "mse_dev_wei_m1 = mean_squared_error(y_dev_m1, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m1:.4f} - Accuracy: {acc_dev_wei_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m1 = accuracy_score(y_dev_m1, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m1 = mean_squared_error(y_dev_m1, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m1:.4f} - Accuracy: {acc_dev_stack_m1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc6df2-8fb3-4ca2-ac7f-16ae27be5d33",
   "metadata": {},
   "source": [
    "## Ensemble - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43942a9b-6a3d-4632-980b-218318def3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m1_preds_test = svc_m1.predict(x_test_m1)\n",
    "nn_sgd_m1_preds_test = (np.rint(nn_sgd_m1.predict(x_test_m1))).astype(int)\n",
    "nn_adam_m1_preds_test = (np.rint(nn_adam_m1.predict(x_test_m1))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m1_preds_test = nn_sgd_m1.predict(x_test_m1)\n",
    "#nn_adam_m1_preds_test = nn_adam_m1.predict(x_test_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe94d7c-b02e-4f3b-aa57-452da7cb9c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9907 - mse: 0.0108\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.5582e-08 - accuracy: 1.0000 - mse: 3.8154e-15\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m1_test = accuracy_score(y_test_m1, svc_m1_preds_test)\n",
    "acc_nn_sgd_m1_test = nn_sgd_m1.evaluate(x_test_m1, y_test_m1)[1]\n",
    "acc_nn_adam_m1_test = nn_adam_m1.evaluate(x_test_m1, y_test_m1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce695a3d-1d2d-4dc1-85f8-a1eb008294e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema\n",
    "ensemble_test = np.zeros(len(x_test_m1), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test,\n",
    "                                          acc_svc_m1_test, acc_nn_sgd_m1_test, acc_nn_sgd_m1_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m1)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1f2e6-b6f9-47ed-b997-5ec19b9aa8fa",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e328d0-7a8e-463d-b9f3-0b2bdd3700c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 0.9907 - Accuracy NN-Adam: 1.0000\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m1_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m1_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m1_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m1 = accuracy_score(y_test_m1, en_maj_vot_test)\n",
    "mse_test_maj_m1 = mean_squared_error(y_test_m1, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m1:.4f} - Accuracy: {acc_test_maj_m1:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m1 = accuracy_score(y_test_m1, en_wei_vot_test)\n",
    "mse_test_wei_m1 = mean_squared_error(y_test_m1, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m1:.4f} - Accuracy: {acc_test_wei_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m1 = accuracy_score(y_test_m1, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m1 = mean_squared_error(y_test_m1, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m1:.4f} - Accuracy: {acc_test_stack_m1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a9e02-7de5-4fe0-8b53-5d7e98839b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523b49cf-3f01-496d-a99a-d7bded86f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m1 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m1, 'mse': mse_dev_maj_m1},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m1, 'mse': mse_test_maj_m1},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m1, 'mse': mse_dev_wei_m1},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m1, 'mse': mse_test_wei_m1},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m1, 'mse': mse_dev_stack_m1},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m1, 'mse': mse_test_stack_m1}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK1/', en_stack_dev.get_params(), report_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216aed0-5ba0-4816-a889-a3be455e73c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MONK-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9efe875-d6ff-42c0-b719-85a47a5855b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-2\n",
    "x_dev_m2, y_dev_m2, x_test_m2, y_test_m2 = load_monk(m2_dev_path, m2_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd9659-b9c0-4412-8c1f-f93964735cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2099dfaa-54d5-46e9-b887-112af690e70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=50, degree=2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=50, degree=2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=50, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m2 = SVC(C=50, degree=2, kernel='poly')\n",
    "svc_m2.fit(x_dev_m2, y_dev_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5886e2a0-bc71-4c89-8b71-8f87283334e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6605 - accuracy: 0.6154 - mse: 0.2337\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6505 - accuracy: 0.6272 - mse: 0.2287\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6467 - accuracy: 0.6568 - mse: 0.2270\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6442 - accuracy: 0.6686 - mse: 0.2258\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.6627 - mse: 0.2249\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6400 - accuracy: 0.6686 - mse: 0.2240\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.6686 - mse: 0.2232\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6362 - accuracy: 0.6627 - mse: 0.2224\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6344 - accuracy: 0.6568 - mse: 0.2216\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6326 - accuracy: 0.6568 - mse: 0.2208\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6308 - accuracy: 0.6627 - mse: 0.2201\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6289 - accuracy: 0.6627 - mse: 0.2193\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6271 - accuracy: 0.6568 - mse: 0.2185\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6252 - accuracy: 0.6568 - mse: 0.2177\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6233 - accuracy: 0.6627 - mse: 0.2169\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6214 - accuracy: 0.6627 - mse: 0.2160\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6194 - accuracy: 0.6627 - mse: 0.2152\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6173 - accuracy: 0.6627 - mse: 0.2143\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.6627 - mse: 0.2134\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6130 - accuracy: 0.6746 - mse: 0.2125\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6108 - accuracy: 0.6746 - mse: 0.2115\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6085 - accuracy: 0.6805 - mse: 0.2105\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6061 - accuracy: 0.6864 - mse: 0.2095\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6805 - mse: 0.2085\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.6805 - mse: 0.2074\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5984 - accuracy: 0.6805 - mse: 0.2063\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.6746 - mse: 0.2052\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5929 - accuracy: 0.6864 - mse: 0.2040\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5900 - accuracy: 0.6864 - mse: 0.2028\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5871 - accuracy: 0.6864 - mse: 0.2016\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5841 - accuracy: 0.6805 - mse: 0.2004\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5810 - accuracy: 0.6746 - mse: 0.1991\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5779 - accuracy: 0.6686 - mse: 0.1978\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5747 - accuracy: 0.6686 - mse: 0.1965\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5714 - accuracy: 0.6746 - mse: 0.1952\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.6805 - mse: 0.1938\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5647 - accuracy: 0.6864 - mse: 0.1924\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5613 - accuracy: 0.6923 - mse: 0.1910\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5579 - accuracy: 0.6982 - mse: 0.1896\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5544 - accuracy: 0.6982 - mse: 0.1882\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5508 - accuracy: 0.6982 - mse: 0.1868\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5473 - accuracy: 0.6982 - mse: 0.1854\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5437 - accuracy: 0.6923 - mse: 0.1839\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5401 - accuracy: 0.6982 - mse: 0.1825\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.7041 - mse: 0.1810\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7101 - mse: 0.1796\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7160 - mse: 0.1781\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5257 - accuracy: 0.7160 - mse: 0.1767\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.7160 - mse: 0.1752\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5184 - accuracy: 0.7278 - mse: 0.1738\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.7278 - mse: 0.1723\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5113 - accuracy: 0.7456 - mse: 0.1709\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5077 - accuracy: 0.7515 - mse: 0.1695\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5042 - accuracy: 0.7515 - mse: 0.1680\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5007 - accuracy: 0.7515 - mse: 0.1666\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.7633 - mse: 0.1653\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4938 - accuracy: 0.7633 - mse: 0.1639\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4904 - accuracy: 0.7692 - mse: 0.1625\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4870 - accuracy: 0.7751 - mse: 0.1612\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4836 - accuracy: 0.7751 - mse: 0.1598\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4803 - accuracy: 0.7751 - mse: 0.1585\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4771 - accuracy: 0.7751 - mse: 0.1572\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4738 - accuracy: 0.7811 - mse: 0.1559\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.7811 - mse: 0.1547\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.7811 - mse: 0.1534\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.7870 - mse: 0.1522\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4613 - accuracy: 0.7988 - mse: 0.1510\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4583 - accuracy: 0.7988 - mse: 0.1498\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4553 - accuracy: 0.7988 - mse: 0.1486\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4524 - accuracy: 0.7929 - mse: 0.1474\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7929 - mse: 0.1463\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4466 - accuracy: 0.7929 - mse: 0.1452\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7929 - mse: 0.1440\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4410 - accuracy: 0.7988 - mse: 0.1429\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4382 - accuracy: 0.7988 - mse: 0.1419\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4355 - accuracy: 0.8047 - mse: 0.1408\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4328 - accuracy: 0.8107 - mse: 0.1397\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4301 - accuracy: 0.8107 - mse: 0.1387\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.8166 - mse: 0.1377\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.8166 - mse: 0.1367\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.8166 - mse: 0.1357\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8166 - mse: 0.1347\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4173 - accuracy: 0.8166 - mse: 0.1337\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4148 - accuracy: 0.8225 - mse: 0.1327\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4124 - accuracy: 0.8343 - mse: 0.1318\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8343 - mse: 0.1308\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.8462 - mse: 0.1299\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8521 - mse: 0.1290\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8521 - mse: 0.1281\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4004 - accuracy: 0.8521 - mse: 0.1271\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8580 - mse: 0.1262\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8580 - mse: 0.1253\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3935 - accuracy: 0.8580 - mse: 0.1244\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8580 - mse: 0.1235\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3889 - accuracy: 0.8639 - mse: 0.1227\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3866 - accuracy: 0.8698 - mse: 0.1218\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8698 - mse: 0.1209\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3821 - accuracy: 0.8698 - mse: 0.1200\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3798 - accuracy: 0.8698 - mse: 0.1191\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3775 - accuracy: 0.8698 - mse: 0.1182\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3753 - accuracy: 0.8698 - mse: 0.1174\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.8698 - mse: 0.1165\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - accuracy: 0.8698 - mse: 0.1156\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3684 - accuracy: 0.8698 - mse: 0.1147\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.8698 - mse: 0.1138\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.8698 - mse: 0.1129\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3616 - accuracy: 0.8757 - mse: 0.1120\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3592 - accuracy: 0.8757 - mse: 0.1111\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3569 - accuracy: 0.8757 - mse: 0.1102\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3546 - accuracy: 0.8817 - mse: 0.1092\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3522 - accuracy: 0.8817 - mse: 0.1083\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3498 - accuracy: 0.8817 - mse: 0.1074\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8757 - mse: 0.1064\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3450 - accuracy: 0.8757 - mse: 0.1055\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8757 - mse: 0.1045\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.8757 - mse: 0.1035\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3375 - accuracy: 0.8757 - mse: 0.1025\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.8757 - mse: 0.1015\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3324 - accuracy: 0.8757 - mse: 0.1005\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8757 - mse: 0.0994\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8757 - mse: 0.0984\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8757 - mse: 0.0973\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3219 - accuracy: 0.8757 - mse: 0.0963\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.8757 - mse: 0.0952\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8757 - mse: 0.0941\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8757 - mse: 0.0930\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3108 - accuracy: 0.8757 - mse: 0.0918\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.8757 - mse: 0.0907\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3050 - accuracy: 0.8757 - mse: 0.0895\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8757 - mse: 0.0883\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2991 - accuracy: 0.8757 - mse: 0.0872\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8817 - mse: 0.0859\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2930 - accuracy: 0.8817 - mse: 0.0847\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.8935 - mse: 0.0834\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2867 - accuracy: 0.8994 - mse: 0.0822\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2835 - accuracy: 0.9053 - mse: 0.0809\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.9053 - mse: 0.0795\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2768 - accuracy: 0.9053 - mse: 0.0781\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.9112 - mse: 0.0767\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2697 - accuracy: 0.9172 - mse: 0.0753\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2660 - accuracy: 0.9172 - mse: 0.0738\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2622 - accuracy: 0.9172 - mse: 0.0722\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2583 - accuracy: 0.9172 - mse: 0.0706\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.9172 - mse: 0.0689\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.9290 - mse: 0.0672\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.9290 - mse: 0.0653\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9349 - mse: 0.0634\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9349 - mse: 0.0613\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 0.9349 - mse: 0.0592\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2251 - accuracy: 0.9408 - mse: 0.0569\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2196 - accuracy: 0.9527 - mse: 0.0546\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2138 - accuracy: 0.9586 - mse: 0.0522\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2080 - accuracy: 0.9586 - mse: 0.0497\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2021 - accuracy: 0.9704 - mse: 0.0472\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9763 - mse: 0.0448\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1904 - accuracy: 0.9763 - mse: 0.0424\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9763 - mse: 0.0401\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1793 - accuracy: 0.9941 - mse: 0.0379\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1740 - accuracy: 0.9941 - mse: 0.0358\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1689 - accuracy: 0.9941 - mse: 0.0339\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1640 - accuracy: 0.9941 - mse: 0.0321\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1593 - accuracy: 0.9941 - mse: 0.0303\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9941 - mse: 0.0287\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9941 - mse: 0.0272\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.9941 - mse: 0.0258\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.9941 - mse: 0.0245\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 1.0000 - mse: 0.0233\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 1.0000 - mse: 0.0221\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 1.0000 - mse: 0.0211\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 1.0000 - mse: 0.0200\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 1.0000 - mse: 0.0191\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1218 - accuracy: 1.0000 - mse: 0.0182\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 1.0000 - mse: 0.0173\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1159 - accuracy: 1.0000 - mse: 0.0165\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 1.0000 - mse: 0.0158\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1105 - accuracy: 1.0000 - mse: 0.0151\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 1.0000 - mse: 0.0144\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1055 - accuracy: 1.0000 - mse: 0.0138\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1032 - accuracy: 1.0000 - mse: 0.0132\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 1.0000 - mse: 0.0126\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0987 - accuracy: 1.0000 - mse: 0.0121\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0966 - accuracy: 1.0000 - mse: 0.0116\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 1.0000 - mse: 0.0111\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0925 - accuracy: 1.0000 - mse: 0.0106\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0906 - accuracy: 1.0000 - mse: 0.0102\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0888 - accuracy: 1.0000 - mse: 0.0098\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 1.0000 - mse: 0.0094\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 1.0000 - mse: 0.0091\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 1.0000 - mse: 0.0087\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 1.0000 - mse: 0.0084\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 1.0000 - mse: 0.0081\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 1.0000 - mse: 0.0078\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0775 - accuracy: 1.0000 - mse: 0.0075\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 1.0000 - mse: 0.0072\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0734 - accuracy: 1.0000 - mse: 0.0067\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 1.0000 - mse: 0.0065\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0709 - accuracy: 1.0000 - mse: 0.0063\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 1.0000 - mse: 0.0061\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0685 - accuracy: 1.0000 - mse: 0.0059\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 1.0000 - mse: 0.0057\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 1.0000 - mse: 0.0055\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 1.0000 - mse: 0.0053\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0641 - accuracy: 1.0000 - mse: 0.0051\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 1.0000 - mse: 0.0050\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 1.0000 - mse: 0.0047\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 1.0000 - mse: 0.0045\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 1.0000 - mse: 0.0043\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 1.0000 - mse: 0.0038\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 1.0000 - mse: 0.0033\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0493 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0451 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0435 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0430 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0425 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0420 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0406 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 1.0000 - mse: 9.9419e-04\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 1.0000 - mse: 9.7787e-04\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 1.0000 - mse: 9.6194e-04\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 1.0000 - mse: 9.4637e-04\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 1.0000 - mse: 9.3117e-04\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 1.0000 - mse: 9.1630e-04\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 1.0000 - mse: 9.0178e-04\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - mse: 8.8758e-04\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - mse: 8.7370e-04\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 1.0000 - mse: 8.6013e-04\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 1.0000 - mse: 8.4686e-04\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 1.0000 - mse: 8.3388e-04\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 1.0000 - mse: 8.2119e-04\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 1.0000 - mse: 8.0877e-04\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 1.0000 - mse: 7.9661e-04\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 1.0000 - mse: 7.8472e-04\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 1.0000 - mse: 7.7308e-04\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 1.0000 - mse: 7.6169e-04\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 1.0000 - mse: 7.5053e-04\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 1.0000 - mse: 7.3961e-04\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 1.0000 - mse: 7.2892e-04\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 1.0000 - mse: 7.1844e-04\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 1.0000 - mse: 7.0819e-04\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 1.0000 - mse: 6.9814e-04\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 1.0000 - mse: 6.8829e-04\n",
      "Restoring best model weights.\n",
      "Best loss: 0.023355450481176376\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.8, 'h_dim': 4, 'reg': 0}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m2 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m2, x_dev_m2, y_dev_m2, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb58a4ea-352b-43b8-b829-2681b07069e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.8006 - accuracy: 0.4024 - mse: 0.3004\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6655 - accuracy: 0.6213 - mse: 0.2363\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7250 - accuracy: 0.3787 - mse: 0.2658\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.6213 - mse: 0.2364\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6887 - accuracy: 0.6213 - mse: 0.2460\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7009 - accuracy: 0.6213 - mse: 0.2508\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6739 - accuracy: 0.6213 - mse: 0.2399\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6653 - accuracy: 0.6213 - mse: 0.2362\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6856 - accuracy: 0.6213 - mse: 0.2462\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6836 - accuracy: 0.6213 - mse: 0.2452\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2367\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6666 - accuracy: 0.6213 - mse: 0.2367\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6787 - accuracy: 0.6213 - mse: 0.2419\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6772 - accuracy: 0.6213 - mse: 0.2413\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.6213 - mse: 0.2365\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6649 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.6213 - mse: 0.2403\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6729 - accuracy: 0.6213 - mse: 0.2399\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6650 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6710 - accuracy: 0.6213 - mse: 0.2387\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6697 - accuracy: 0.6213 - mse: 0.2381\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6641 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6694 - accuracy: 0.6213 - mse: 0.2382\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.6213 - mse: 0.2369\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2366\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6676 - accuracy: 0.6213 - mse: 0.2372\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6641 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6668 - accuracy: 0.6213 - mse: 0.2369\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6650 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.6213 - mse: 0.2364\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2359\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6649 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2359\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6638 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354Restoring model weights from the end of the best epoch: 27.\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "\n",
      "Epoch 77: early stopping.\n",
      "Best loss: 0.6634232997894287\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m2 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m2, x_dev_m2, y_dev_m2, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbf914-d70e-4b69-be8f-737c7779d4ee",
   "metadata": {},
   "source": [
    "## Ensemble - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4723375-3d8a-4ab4-9ffc-4b200a8d9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m2_preds_dev = svc_m2.predict(x_dev_m2)\n",
    "nn_sgd_m2_preds_dev = (np.rint(nn_sgd_m2.predict(x_dev_m2))).astype(int)\n",
    "nn_adam_m2_preds_dev = (np.rint(nn_adam_m2.predict(x_dev_m2))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m2_preds_dev = nn_sgd_m2.predict(x_dev_m2)\n",
    "#nn_adam_m2_preds_dev = nn_adam_m2.predict(x_dev_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2366af5b-9db8-463f-b7f0-4a9d0971cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 1.0000 - mse: 6.7865e-04\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2366\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m2_dev = accuracy_score(y_dev_m2, svc_m2_preds_dev)\n",
    "acc_nn_sgd_m2_dev = nn_sgd_m2.evaluate(x_dev_m2, y_dev_m2)[1]\n",
    "acc_nn_adam_m2_dev = nn_adam_m2.evaluate(x_dev_m2, y_dev_m2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1361156e-0e28-4dca-b57e-e99104b7d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m2), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev,\n",
    "                                          acc_svc_m2_dev, acc_nn_sgd_m2_dev, acc_nn_sgd_m2_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m2)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcaddb-2d9a-4c04-ad07-c67574eb444d",
   "metadata": {},
   "source": [
    "## Results Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9bc7730-ce5d-42c6-84fc-2348ba2adead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 0.6213\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m2_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m2_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m2_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m2 = accuracy_score(y_dev_m2, en_maj_vot_dev)\n",
    "mse_dev_maj_m2 = mean_squared_error(y_dev_m2, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m2:.4f} - Accuracy: {acc_dev_maj_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m2 = accuracy_score(y_dev_m2, en_wei_vot_dev)\n",
    "mse_dev_wei_m2 = mean_squared_error(y_dev_m2, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m2:.4f} - Accuracy: {acc_dev_wei_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m2 = accuracy_score(y_dev_m2, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m2 = mean_squared_error(y_dev_m2, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m2:.4f} - Accuracy: {acc_dev_stack_m2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e770d-0fd9-4ea5-b60c-28101d3e4275",
   "metadata": {},
   "source": [
    "## Ensemble - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46ed0440-ed1d-4052-956c-e54183d293a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m2_preds_test = svc_m2.predict(x_test_m2)\n",
    "nn_sgd_m2_preds_test = (np.rint(nn_sgd_m2.predict(x_test_m2))).astype(int)\n",
    "nn_adam_m2_preds_test = (np.rint(nn_adam_m2.predict(x_test_m2))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m2_preds_test = nn_sgd_m2.predict(x_test_m2)\n",
    "#nn_adam_m2_preds_test = nn_adam_m2.predict(x_test_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afdd5e3f-3e76-4646-a6eb-7675b4f21632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - mse: 0.0012\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6713 - mse: 0.2208\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m2_test = accuracy_score(y_test_m2, svc_m2_preds_test)\n",
    "acc_nn_sgd_m2_test = nn_sgd_m2.evaluate(x_test_m2, y_test_m2)[1]\n",
    "acc_nn_adam_m2_test = nn_adam_m2.evaluate(x_test_m2, y_test_m2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c456953f-d5e5-4614-895b-33f7e8831390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema\n",
    "ensemble_test = np.zeros(len(x_test_m2), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test,\n",
    "                                          acc_svc_m2_test, acc_nn_sgd_m2_test, acc_nn_sgd_m2_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m2)                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921dd99a-cb67-4b69-9922-2bd678eac91d",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0932bbe8-665d-4647-8771-9a9c53e489db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 0.6713\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m2_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m2_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m2_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m2 = accuracy_score(y_test_m2, en_maj_vot_test)\n",
    "mse_test_maj_m2 = mean_squared_error(y_test_m2, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m2:.4f} - Accuracy: {acc_test_maj_m2:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m2 = accuracy_score(y_test_m2, en_wei_vot_test)\n",
    "mse_test_wei_m2 = mean_squared_error(y_test_m2, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m2:.4f} - Accuracy: {acc_test_wei_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m2 = accuracy_score(y_test_m2, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m2 = mean_squared_error(y_test_m2, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m2:.4f} - Accuracy: {acc_test_stack_m2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ca457-cb8a-48d7-9c9e-4e9d473efe3a",
   "metadata": {},
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "569ead2f-5368-4648-b36c-73f9aa69b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m2 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m2, 'mse': mse_dev_maj_m2},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m2, 'mse': mse_test_maj_m2},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m2, 'mse': mse_dev_wei_m2},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m2, 'mse': mse_test_wei_m2},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m2, 'mse': mse_dev_stack_m2},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m2, 'mse': mse_test_stack_m2}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK2/', en_stack_dev.get_params(), report_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2e408-6d1b-4c43-b70b-c4fec0da831d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MONK-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f02aae1-f31b-4403-9d85-fbfaf144d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-3\n",
    "x_dev_m3, y_dev_m3, x_test_m3, y_test_m3 = load_monk(m3_dev_path, m3_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef02d30-2efb-4f50-9f4c-c097cb021264",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5461f5ae-6536-4b50-ab54-f1f81e4444bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, gamma='auto', kernel='poly')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m3 = SVC(C=10, degree=2, gamma='auto', kernel='poly')\n",
    "svc_m3.fit(x_dev_m3, y_dev_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e89050a9-a2d0-4a50-9ba1-8839be3bc549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.6720 - accuracy: 0.6557 - mse: 0.2392\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6583 - accuracy: 0.6721 - mse: 0.2324\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6444 - accuracy: 0.7295 - mse: 0.2255\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6298 - accuracy: 0.7951 - mse: 0.2183\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6143 - accuracy: 0.8033 - mse: 0.2106\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5975 - accuracy: 0.8115 - mse: 0.2024\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5796 - accuracy: 0.8197 - mse: 0.1938\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.8361 - mse: 0.1846\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5406 - accuracy: 0.8607 - mse: 0.1752\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5200 - accuracy: 0.8607 - mse: 0.1656\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.9016 - mse: 0.1559\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.9098 - mse: 0.1464\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.9262 - mse: 0.1371\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.9262 - mse: 0.1283\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.9262 - mse: 0.1200\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3987 - accuracy: 0.9262 - mse: 0.1123\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3813 - accuracy: 0.9344 - mse: 0.1052\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3652 - accuracy: 0.9344 - mse: 0.0988\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3503 - accuracy: 0.9344 - mse: 0.0931\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.9344 - mse: 0.0880\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3241 - accuracy: 0.9344 - mse: 0.0834\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3129 - accuracy: 0.9344 - mse: 0.0794\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.9344 - mse: 0.0760\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2934 - accuracy: 0.9344 - mse: 0.0729\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2851 - accuracy: 0.9344 - mse: 0.0702\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2776 - accuracy: 0.9344 - mse: 0.0679\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2708 - accuracy: 0.9344 - mse: 0.0658\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2647 - accuracy: 0.9344 - mse: 0.0641\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2591 - accuracy: 0.9344 - mse: 0.0625\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2541 - accuracy: 0.9344 - mse: 0.0611\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9344 - mse: 0.0598\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9344 - mse: 0.0587\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2414 - accuracy: 0.9344 - mse: 0.0577\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2378 - accuracy: 0.9344 - mse: 0.0568\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2345 - accuracy: 0.9344 - mse: 0.0560\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2314 - accuracy: 0.9344 - mse: 0.0552\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2285 - accuracy: 0.9344 - mse: 0.0545\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2258 - accuracy: 0.9344 - mse: 0.0539\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2233 - accuracy: 0.9344 - mse: 0.0532\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2209 - accuracy: 0.9344 - mse: 0.0527\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9344 - mse: 0.0522\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2165 - accuracy: 0.9344 - mse: 0.0517\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2145 - accuracy: 0.9344 - mse: 0.0512\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2126 - accuracy: 0.9344 - mse: 0.0507\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2108 - accuracy: 0.9344 - mse: 0.0503\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2090 - accuracy: 0.9344 - mse: 0.0499\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2073 - accuracy: 0.9344 - mse: 0.0495\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2057 - accuracy: 0.9344 - mse: 0.0491\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2042 - accuracy: 0.9344 - mse: 0.0488\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2027 - accuracy: 0.9344 - mse: 0.0484\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2013 - accuracy: 0.9344 - mse: 0.0481\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1999 - accuracy: 0.9344 - mse: 0.0478\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1986 - accuracy: 0.9344 - mse: 0.0475\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1973 - accuracy: 0.9344 - mse: 0.0472\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1961 - accuracy: 0.9344 - mse: 0.0469\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1949 - accuracy: 0.9344 - mse: 0.0466\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9344 - mse: 0.0463\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.9344 - mse: 0.0461\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1915 - accuracy: 0.9344 - mse: 0.0458\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1905 - accuracy: 0.9344 - mse: 0.0455\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1894 - accuracy: 0.9344 - mse: 0.0453\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1884 - accuracy: 0.9344 - mse: 0.0450\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1874 - accuracy: 0.9344 - mse: 0.0448\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1865 - accuracy: 0.9344 - mse: 0.0446\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9344 - mse: 0.0443\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1847 - accuracy: 0.9344 - mse: 0.0441\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1838 - accuracy: 0.9344 - mse: 0.0439\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1829 - accuracy: 0.9344 - mse: 0.0437\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1821 - accuracy: 0.9344 - mse: 0.0435\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1813 - accuracy: 0.9344 - mse: 0.0433\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1805 - accuracy: 0.9344 - mse: 0.0431\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 0.9344 - mse: 0.0429\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1790 - accuracy: 0.9344 - mse: 0.0427\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1782 - accuracy: 0.9344 - mse: 0.0425\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1775 - accuracy: 0.9344 - mse: 0.0423\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1768 - accuracy: 0.9344 - mse: 0.0421\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1761 - accuracy: 0.9344 - mse: 0.0419\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1754 - accuracy: 0.9344 - mse: 0.0417\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1747 - accuracy: 0.9344 - mse: 0.0415\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1741 - accuracy: 0.9344 - mse: 0.0414\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1734 - accuracy: 0.9344 - mse: 0.0412\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1728 - accuracy: 0.9344 - mse: 0.0410\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1722 - accuracy: 0.9426 - mse: 0.0409\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1716 - accuracy: 0.9426 - mse: 0.0407\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1710 - accuracy: 0.9426 - mse: 0.0405\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1704 - accuracy: 0.9426 - mse: 0.0404\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1698 - accuracy: 0.9426 - mse: 0.0402\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1693 - accuracy: 0.9426 - mse: 0.0400\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1687 - accuracy: 0.9426 - mse: 0.0399\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1682 - accuracy: 0.9426 - mse: 0.0397\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1676 - accuracy: 0.9426 - mse: 0.0396\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1671 - accuracy: 0.9426 - mse: 0.0394\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1666 - accuracy: 0.9426 - mse: 0.0393\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1661 - accuracy: 0.9426 - mse: 0.0391\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1655 - accuracy: 0.9426 - mse: 0.0390\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1650 - accuracy: 0.9426 - mse: 0.0388\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1646 - accuracy: 0.9426 - mse: 0.0387\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1641 - accuracy: 0.9426 - mse: 0.0386\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9426 - mse: 0.0384\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.9426 - mse: 0.0383\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1626 - accuracy: 0.9426 - mse: 0.0381\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1622 - accuracy: 0.9426 - mse: 0.0380\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1617 - accuracy: 0.9426 - mse: 0.0379\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9426 - mse: 0.0377\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1608 - accuracy: 0.9426 - mse: 0.0376\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 0.9426 - mse: 0.0375\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1600 - accuracy: 0.9426 - mse: 0.0373\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1595 - accuracy: 0.9426 - mse: 0.0372\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 0.9426 - mse: 0.0371\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1587 - accuracy: 0.9426 - mse: 0.0369\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9426 - mse: 0.0368\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 0.9426 - mse: 0.0367\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1574 - accuracy: 0.9426 - mse: 0.0366\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1570 - accuracy: 0.9426 - mse: 0.0364\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9426 - mse: 0.0363\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1562 - accuracy: 0.9426 - mse: 0.0362\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1558 - accuracy: 0.9426 - mse: 0.0361\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1554 - accuracy: 0.9426 - mse: 0.0359\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1550 - accuracy: 0.9426 - mse: 0.0358\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1547 - accuracy: 0.9426 - mse: 0.0357\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1543 - accuracy: 0.9426 - mse: 0.0356\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1539 - accuracy: 0.9426 - mse: 0.0355\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1535 - accuracy: 0.9426 - mse: 0.0353\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1531 - accuracy: 0.9426 - mse: 0.0352\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1528 - accuracy: 0.9426 - mse: 0.0351\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1524 - accuracy: 0.9426 - mse: 0.0350\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1520 - accuracy: 0.9426 - mse: 0.0349\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9426 - mse: 0.0348\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1513 - accuracy: 0.9426 - mse: 0.0346\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9426 - mse: 0.0345\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1506 - accuracy: 0.9426 - mse: 0.0344\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1503 - accuracy: 0.9426 - mse: 0.0343\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1499 - accuracy: 0.9426 - mse: 0.0342\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1496 - accuracy: 0.9426 - mse: 0.0341\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1492 - accuracy: 0.9426 - mse: 0.0340\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1489 - accuracy: 0.9426 - mse: 0.0338\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1485 - accuracy: 0.9426 - mse: 0.0337\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1482 - accuracy: 0.9426 - mse: 0.0336\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1479 - accuracy: 0.9426 - mse: 0.0335\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 0.9426 - mse: 0.0334\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1472 - accuracy: 0.9426 - mse: 0.0333\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1469 - accuracy: 0.9426 - mse: 0.0332\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1465 - accuracy: 0.9426 - mse: 0.0331\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1462 - accuracy: 0.9426 - mse: 0.0330\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1459 - accuracy: 0.9426 - mse: 0.0329\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 0.9426 - mse: 0.0328\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1452 - accuracy: 0.9426 - mse: 0.0327\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1449 - accuracy: 0.9426 - mse: 0.0325\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1446 - accuracy: 0.9426 - mse: 0.0324\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1443 - accuracy: 0.9508 - mse: 0.0323\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1440 - accuracy: 0.9590 - mse: 0.0322\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1437 - accuracy: 0.9590 - mse: 0.0321\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1434 - accuracy: 0.9590 - mse: 0.0320\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1431 - accuracy: 0.9590 - mse: 0.0319\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1427 - accuracy: 0.9590 - mse: 0.0318\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1424 - accuracy: 0.9590 - mse: 0.0317\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1421 - accuracy: 0.9590 - mse: 0.0316\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1418 - accuracy: 0.9590 - mse: 0.0315\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1415 - accuracy: 0.9590 - mse: 0.0314\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9590 - mse: 0.0313\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9590 - mse: 0.0312\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1407 - accuracy: 0.9590 - mse: 0.0311\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9590 - mse: 0.0310\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9590 - mse: 0.0309\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1398 - accuracy: 0.9590 - mse: 0.0308\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1395 - accuracy: 0.9590 - mse: 0.0307\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1392 - accuracy: 0.9590 - mse: 0.0307\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1389 - accuracy: 0.9590 - mse: 0.0306\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1386 - accuracy: 0.9590 - mse: 0.0305\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1384 - accuracy: 0.9590 - mse: 0.0304\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1381 - accuracy: 0.9590 - mse: 0.0303\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1378 - accuracy: 0.9590 - mse: 0.0302\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1375 - accuracy: 0.9590 - mse: 0.0301\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1372 - accuracy: 0.9590 - mse: 0.0300\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1370 - accuracy: 0.9672 - mse: 0.0299\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9672 - mse: 0.0298\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9672 - mse: 0.0297\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1362 - accuracy: 0.9672 - mse: 0.0296\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1359 - accuracy: 0.9672 - mse: 0.0296\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1356 - accuracy: 0.9672 - mse: 0.0295\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1353 - accuracy: 0.9672 - mse: 0.0294\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9672 - mse: 0.0293\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1348 - accuracy: 0.9672 - mse: 0.0292\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1346 - accuracy: 0.9672 - mse: 0.0291\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1343 - accuracy: 0.9672 - mse: 0.0290\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1340 - accuracy: 0.9672 - mse: 0.0289\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 0.9672 - mse: 0.0289\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1335 - accuracy: 0.9672 - mse: 0.0288\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9672 - mse: 0.0286\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.9672 - mse: 0.0285\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1325 - accuracy: 0.9672 - mse: 0.0284\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 0.9672 - mse: 0.0284\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.9672 - mse: 0.0283\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1317 - accuracy: 0.9672 - mse: 0.0282\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.9672 - mse: 0.0281\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1312 - accuracy: 0.9672 - mse: 0.0280\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1310 - accuracy: 0.9672 - mse: 0.0280\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1308 - accuracy: 0.9672 - mse: 0.0279\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1305 - accuracy: 0.9672 - mse: 0.0278\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1303 - accuracy: 0.9672 - mse: 0.0277\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1300 - accuracy: 0.9672 - mse: 0.0276\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1298 - accuracy: 0.9672 - mse: 0.0276\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1295 - accuracy: 0.9672 - mse: 0.0275\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1293 - accuracy: 0.9672 - mse: 0.0274\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1291 - accuracy: 0.9672 - mse: 0.0273\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9672 - mse: 0.0273\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1286 - accuracy: 0.9672 - mse: 0.0272\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1284 - accuracy: 0.9672 - mse: 0.0271\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1281 - accuracy: 0.9672 - mse: 0.0270\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9672 - mse: 0.0270\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9672 - mse: 0.0269\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1274 - accuracy: 0.9672 - mse: 0.0268\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1272 - accuracy: 0.9672 - mse: 0.0267\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1270 - accuracy: 0.9672 - mse: 0.0267\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9754 - mse: 0.0266\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1265 - accuracy: 0.9754 - mse: 0.0265\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1263 - accuracy: 0.9754 - mse: 0.0264\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1261 - accuracy: 0.9754 - mse: 0.0264\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1258 - accuracy: 0.9754 - mse: 0.0263\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1256 - accuracy: 0.9754 - mse: 0.0262\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1254 - accuracy: 0.9754 - mse: 0.0262\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1252 - accuracy: 0.9754 - mse: 0.0261\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.9754 - mse: 0.0260\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9754 - mse: 0.0260\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1245 - accuracy: 0.9754 - mse: 0.0259\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1243 - accuracy: 0.9754 - mse: 0.0258\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1241 - accuracy: 0.9754 - mse: 0.0258\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9754 - mse: 0.0257\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1236 - accuracy: 0.9754 - mse: 0.0256\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1234 - accuracy: 0.9754 - mse: 0.0255\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1232 - accuracy: 0.9754 - mse: 0.0255\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1230 - accuracy: 0.9754 - mse: 0.0254\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1228 - accuracy: 0.9754 - mse: 0.0253\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1225 - accuracy: 0.9754 - mse: 0.0253\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1223 - accuracy: 0.9754 - mse: 0.0252\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.9754 - mse: 0.0251\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1219 - accuracy: 0.9754 - mse: 0.0251\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1217 - accuracy: 0.9754 - mse: 0.0250\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1215 - accuracy: 0.9754 - mse: 0.0250\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1213 - accuracy: 0.9754 - mse: 0.0249\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1211 - accuracy: 0.9754 - mse: 0.0248\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1209 - accuracy: 0.9754 - mse: 0.0248\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1206 - accuracy: 0.9754 - mse: 0.0247\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9754 - mse: 0.0246\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1202 - accuracy: 0.9754 - mse: 0.0246\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1200 - accuracy: 0.9754 - mse: 0.0245\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9754 - mse: 0.0244\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1196 - accuracy: 0.9754 - mse: 0.0244\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1194 - accuracy: 0.9754 - mse: 0.0243\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1192 - accuracy: 0.9754 - mse: 0.0243\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9754 - mse: 0.0242\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1188 - accuracy: 0.9754 - mse: 0.0241\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1186 - accuracy: 0.9754 - mse: 0.0241\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1184 - accuracy: 0.9754 - mse: 0.0240\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9754 - mse: 0.0240\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1180 - accuracy: 0.9754 - mse: 0.0239\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.9754 - mse: 0.0238\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1176 - accuracy: 0.9754 - mse: 0.0238\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1174 - accuracy: 0.9754 - mse: 0.0237\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9754 - mse: 0.0237\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1170 - accuracy: 0.9754 - mse: 0.0236\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1168 - accuracy: 0.9754 - mse: 0.0235\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1166 - accuracy: 0.9754 - mse: 0.0235\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9754 - mse: 0.0234\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1162 - accuracy: 0.9754 - mse: 0.0234\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9754 - mse: 0.0233\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9754 - mse: 0.0232\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9754 - mse: 0.0232\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.9754 - mse: 0.0231\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1152 - accuracy: 0.9754 - mse: 0.0231\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1150 - accuracy: 0.9754 - mse: 0.0230\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.9754 - mse: 0.0229\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1146 - accuracy: 0.9754 - mse: 0.0229\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9754 - mse: 0.0228\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1143 - accuracy: 0.9754 - mse: 0.0228\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1139 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9754 - mse: 0.0226\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1135 - accuracy: 0.9754 - mse: 0.0225\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1133 - accuracy: 0.9754 - mse: 0.0225\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1131 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1129 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1127 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9754 - mse: 0.0222\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1122 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1120 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1118 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1116 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1114 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1112 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1110 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1108 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1106 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1105 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1101 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1099 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9754 - mse: 0.0214\n",
      "Restoring best model weights.\n",
      "Best loss: 0.1097170040011406\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.6, 'h_dim': 4, 'reg': 0.001}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m3 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m3, x_dev_m3, y_dev_m3, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47b7771d-67c6-433f-b0ef-da8f41c7fc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.6830 - accuracy: 0.6230 - mse: 0.2300\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6561 - accuracy: 0.5902 - mse: 0.2252\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5538 - accuracy: 0.7377 - mse: 0.1761\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5137 - accuracy: 0.7459 - mse: 0.1609\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4058 - accuracy: 0.8689 - mse: 0.1125\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.9344 - mse: 0.0764\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3068 - accuracy: 0.9262 - mse: 0.0683\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2996 - accuracy: 0.9262 - mse: 0.0610\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.9426 - mse: 0.0529\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2872 - accuracy: 0.9344 - mse: 0.0493\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.9344 - mse: 0.0453\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9508 - mse: 0.0430\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2722 - accuracy: 0.9508 - mse: 0.0423\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9508 - mse: 0.0419\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2512 - accuracy: 0.9426 - mse: 0.0424\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2448 - accuracy: 0.9426 - mse: 0.0438\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2407 - accuracy: 0.9426 - mse: 0.0443\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9426 - mse: 0.0437\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.9590 - mse: 0.0428\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2290 - accuracy: 0.9590 - mse: 0.0414\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2209 - accuracy: 0.9590 - mse: 0.0398\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2137 - accuracy: 0.9590 - mse: 0.0385\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2091 - accuracy: 0.9426 - mse: 0.0378\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9426 - mse: 0.0373\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2089 - accuracy: 0.9344 - mse: 0.0369\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2105 - accuracy: 0.9344 - mse: 0.0365\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2102 - accuracy: 0.9344 - mse: 0.0357\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9344 - mse: 0.0348\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2039 - accuracy: 0.9426 - mse: 0.0341\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2007 - accuracy: 0.9426 - mse: 0.0340\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1993 - accuracy: 0.9508 - mse: 0.0344\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1987 - accuracy: 0.9508 - mse: 0.0348\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.9508 - mse: 0.0346\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9508 - mse: 0.0337\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.9590 - mse: 0.0325\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9590 - mse: 0.0313\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.9590 - mse: 0.0305\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1892 - accuracy: 0.9590 - mse: 0.0300\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9590 - mse: 0.0298\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1899 - accuracy: 0.9590 - mse: 0.0294\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1887 - accuracy: 0.9672 - mse: 0.0290\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1873 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1865 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1861 - accuracy: 0.9754 - mse: 0.0287\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1856 - accuracy: 0.9754 - mse: 0.0289\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1849 - accuracy: 0.9590 - mse: 0.0289\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1842 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1838 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9672 - mse: 0.0286\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1830 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.9672 - mse: 0.0288\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9590 - mse: 0.0290\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.9590 - mse: 0.0290\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1814 - accuracy: 0.9754 - mse: 0.0281\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1808 - accuracy: 0.9754 - mse: 0.0276\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1804 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9836 - mse: 0.0269\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1798 - accuracy: 0.9836 - mse: 0.0269\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1797 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1795 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1790 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1781 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1779 - accuracy: 0.9836 - mse: 0.0273\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.9836 - mse: 0.0274\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1773 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1770 - accuracy: 0.9836 - mse: 0.0266\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1769 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1767 - accuracy: 0.9836 - mse: 0.0261\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1762 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1760 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1759 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1757 - accuracy: 0.9836 - mse: 0.0263\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1754 - accuracy: 0.9836 - mse: 0.0264\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1752 - accuracy: 0.9836 - mse: 0.0263\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1750 - accuracy: 0.9836 - mse: 0.0261\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1748 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1746 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1743 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1742 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1740 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1738 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1736 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1735 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1732 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1729 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1728 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1727 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1726 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1724 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1722 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1721 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1720 - accuracy: 0.9836 - mse: 0.0253\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1717 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1715 - accuracy: 0.9836 - mse: 0.0250\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1715 - accuracy: 0.9836 - mse: 0.0253\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1714 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1713 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1713 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1711 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9836 - mse: 0.0250\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1710 - accuracy: 0.9836 - mse: 0.0251\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1709 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1708 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1708 - accuracy: 0.9836 - mse: 0.0251\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1705 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1704 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1704 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1702 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 0.9836 - mse: 0.0245\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1676 - accuracy: 0.9836 - mse: 0.0234\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.9836 - mse: 0.0229\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.9754 - mse: 0.0230\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1651 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1618 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 0.9836 - mse: 0.0226\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1624 - accuracy: 0.9836 - mse: 0.0225\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1618 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1612 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1606 - accuracy: 0.9754 - mse: 0.0222\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1601 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1599 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1597 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1595 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1589 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1582 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1580 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1577 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Restoring best model weights.\n",
      "Best loss: 0.15661567449569702\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0.02, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m3 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m3, x_dev_m3, y_dev_m3, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc6223-3887-4dc6-a8c4-ef3be5bb5f6f",
   "metadata": {},
   "source": [
    "## Ensamble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "283bd661-8ec6-4ad3-8a4b-ba2b9528c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m3_preds_dev = svc_m3.predict(x_dev_m3)\n",
    "nn_sgd_m3_preds_dev = (np.rint(nn_sgd_m3.predict(x_dev_m3))).astype(int)\n",
    "nn_adam_m3_preds_dev = (np.rint(nn_adam_m3.predict(x_dev_m3))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m3_preds_dev = nn_sgd_m3.predict(x_dev_m3)\n",
    "#nn_adam_m3_preds_dev = nn_adam_m3.predict(x_dev_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee8351ac-616e-447e-af38-df77294e0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1095 - accuracy: 0.9754 - mse: 0.0214\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m3_dev = accuracy_score(y_dev_m3, svc_m3_preds_dev)\n",
    "acc_nn_sgd_m3_dev = nn_sgd_m3.evaluate(x_dev_m3, y_dev_m3)[1]\n",
    "acc_nn_adam_m3_dev = nn_adam_m3.evaluate(x_dev_m3, y_dev_m3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a1981a7-7abb-46c2-8cf3-3d56319425b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m3), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev,\n",
    "                                          acc_svc_m3_dev, acc_nn_sgd_m3_dev, acc_nn_sgd_m3_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m3)\n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477543b-56cb-4e3b-b2d5-fe631eb411a6",
   "metadata": {},
   "source": [
    "## Result Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b9d834e-67e2-4797-8cff-1add6d7a233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 0.9344 - Accuracy NN-SGD: 0.9754 - Accuracy NN-Adam: 0.9754\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m3_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m3_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m3_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m3 = accuracy_score(y_dev_m3, en_maj_vot_dev)\n",
    "mse_dev_maj_m3 = mean_squared_error(y_dev_m3, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m3:.4f} - Accuracy: {acc_dev_maj_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m3 = accuracy_score(y_dev_m3, en_wei_vot_dev)\n",
    "mse_dev_wei_m3 = mean_squared_error(y_dev_m3, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m3:.4f} - Accuracy: {acc_dev_wei_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m3 = accuracy_score(y_dev_m3, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m3 = mean_squared_error(y_dev_m3, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m3:.4f} - Accuracy: {acc_dev_stack_m3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b54f4c-5040-4fdf-b31d-f612f95376c9",
   "metadata": {},
   "source": [
    "## Ensamble Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89d2f28c-83be-4229-ab0d-675d86bb99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m3_preds_test = svc_m3.predict(x_test_m3)\n",
    "nn_sgd_m3_preds_test = (np.rint(nn_sgd_m3.predict(x_test_m3))).astype(int)\n",
    "nn_adam_m3_preds_test = (np.rint(nn_adam_m3.predict(x_test_m3))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m3_preds_test = nn_sgd_m3.predict(x_test_m3)\n",
    "#nn_adam_m3_preds_test = nn_adam_m3.predict(x_test_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d73ddb0e-4f44-4c91-91c7-b4ebad218738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9630 - mse: 0.0250\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9491 - mse: 0.0341\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m3_test = accuracy_score(y_test_m3, svc_m3_preds_test)\n",
    "acc_nn_sgd_m3_test = nn_sgd_m3.evaluate(x_test_m3, y_test_m3)[1]\n",
    "acc_nn_adam_m3_test = nn_adam_m3.evaluate(x_test_m3, y_test_m3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4da56bc-b2de-4a86-8f8d-aeebc6262916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schemaR\n",
    "ensemble_test = np.zeros(len(x_test_m3), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test,\n",
    "                                          acc_svc_m3_test, acc_nn_sgd_m3_test, acc_nn_sgd_m3_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m3)                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0b1c4-031a-43d1-ab61-cc749109f1d8",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f0c4840-309f-4086-bc5a-df31d33dc756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 0.9722 - Accuracy NN-SGD: 0.9630 - Accuracy NN-Adam: 0.9491\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m3_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m3_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m3_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m3 = accuracy_score(y_test_m3, en_maj_vot_test)\n",
    "mse_test_maj_m3 = mean_squared_error(y_test_m3, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m3:.4f} - Accuracy: {acc_test_maj_m3:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m3 = accuracy_score(y_test_m3, en_wei_vot_test)\n",
    "mse_test_wei_m3 = mean_squared_error(y_test_m3, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m3:.4f} - Accuracy: {acc_test_wei_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m3 = accuracy_score(y_test_m3, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m3 = mean_squared_error(y_test_m3, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m3:.4f} - Accuracy: {acc_test_stack_m3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb110c7d-e148-4c70-9be3-e43803d20f10",
   "metadata": {},
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f77e7d4-97a9-4ceb-87d0-a4a2a0f0f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m3 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m3, 'mse': mse_dev_maj_m3},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m3, 'mse': mse_test_maj_m3},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m3, 'mse': mse_dev_wei_m3},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m3, 'mse': mse_test_wei_m3},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m3, 'mse': mse_dev_stack_m3},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m3, 'mse': mse_test_stack_m3}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK3/', en_stack_dev.get_params(), report_m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f6603-97eb-4bf3-ae71-b1a62be020bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ec7e3ff-908a-480a-bc16-bd7a020f41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CUP\n",
    "x_dev_cup, y_dev_cup, x_test_cup = load_cup(cup_dev_path, cup_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1274b55b-f97f-48d0-8d4c-8afa1c001b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_euclidean_error(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Utility function to compute the Mean Euclidean Error (MEE) between \n",
    "    true and predicted values for a tensorflow model. \n",
    "    Return the MEE score as a tensor.\n",
    "\n",
    "    Required arguments:\n",
    "    - y_true: array containing true values (ground truth).\n",
    "    - y_pred: array containing predicted values.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(y_pred - y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ae8aa-990f-4b6d-a301-186c83d60e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train-Val + Internal Test Split \n",
    "First, the development data is split between training and internal test ($90-10$). Then, the training data is further split between training and validation so that the final split is exactly $80-10-10$, for training, validation and internal test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "371a0d14-f694-4424-a2f8-f497f42203e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dev data into train - internal test\n",
    "x_train_cup, x_internal_test_cup, y_train_cup, y_internal_test_cup = train_test_split(\n",
    "    x_dev_cup, \n",
    "    y_dev_cup, \n",
    "    test_size=INTERNAL_TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a5958-8ecf-487d-95a3-de87a52ec0e3",
   "metadata": {},
   "source": [
    "## Models and Ensemles - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7eb6f38-bf75-4e8e-b2be-ffbe854bd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_regressor(optimizer, hparams):\n",
    "    if hparams['activation'] == 'tanh':\n",
    "        initializer = GlorotUniform(seed=RANDOM_STATE) # Glorot (Xavier)\n",
    "        bias_initializer = Zeros()\n",
    "    elif hparams['activation'] == 'ReLU':\n",
    "        initializer = HeNormal(seed=RANDOM_STATE) # He (Kaiming)\n",
    "        bias_initializer = Constant(0.1)\n",
    "        \n",
    "    reg = l2(hparams['reg'])\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        hparams['h_dim'], \n",
    "        activation=hparams['activation'], \n",
    "        input_shape=(10,), \n",
    "        kernel_regularizer=l2(hparams['reg']),\n",
    "        kernel_initializer=initializer,\n",
    "        bias_initializer=bias_initializer))\n",
    "\n",
    "    h_dim = hparams['h_dim']\n",
    "    for i in range(hparams['n_layers'] - 1):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                h_dim, \n",
    "                activation=hparams['activation'],\n",
    "                kernel_regularizer=l2(hparams['reg']),\n",
    "                kernel_initializer=initializer,\n",
    "                bias_initializer=bias_initializer))\n",
    "        h_dim //= 2\n",
    "\n",
    "    model.add(Dense(\n",
    "        3, \n",
    "        activation='linear', \n",
    "        kernel_regularizer=l2(hparams['reg']), \n",
    "        kernel_initializer=initializer,\n",
    "        bias_initializer=bias_initializer))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[mean_euclidean_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d98a38-c495-4396-90fd-b28eaf9b7f37",
   "metadata": {},
   "source": [
    "## Ensemble Arithmetic Averange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a32250c6-31dd-493c-b074-6bd413052825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_arithmetic_averange(ensemble, svr_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    #for i, j in ensemble.shape:\n",
    "        #ensemble[i][j] = (svr_preds[i][j] + nn_sgd_preds[i][j]+ nn_adam_preds[i][j])/3 \n",
    "            \n",
    "    return (svr_preds + nn_sgd_preds + nn_adam_preds)/3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ac349-f4c6-4801-8989-a6a661ac4b7c",
   "metadata": {},
   "source": [
    "## Ensemble Weighted Averange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2661372c-0a21-4245-a443-aab90a47cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weight used is (N - mee)\n",
    "def ensemble_weighted_averange(ensemble, N, svr_preds, nn_sgd_preds, nn_adam_preds, mee_svr, mee_nn_sgd, mee_nn_adam):\n",
    "    \n",
    "    if (N < mee_svr or N < mee_nn_sgd or N < mee_nn_adam):\n",
    "        raise ValueError(\"N must be greater than mee\")\n",
    "        \n",
    "    #for i in range(len(ensemble)):\n",
    "    #    ensemble[i] = svc_preds[i]*(N-mee_svr) + nn_sgd_preds[i]*(N-mee_nn_sgd) + nn_adam_preds[i]*(N-mee_nn_adam)/(3*N - (mee_svr + mee_nn_sgd + mee_nn_adam))\n",
    "            \n",
    "    return (svr_preds*(N-mee_svr) + nn_sgd_preds*(N-mee_nn_sgd) + nn_adam_preds*(N-mee_nn_adam))/(3*N - (mee_svr + mee_nn_sgd + mee_nn_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c7aac-b3dc-4f08-ae15-58c7c9c564b1",
   "metadata": {},
   "source": [
    "## Ensemble Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27960dce-1ce8-4c03-b9c5-a3e5389c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_stacking_cup(estimator):\n",
    "    if(estimator == 'LinearRegression'): ensemble = LinearRegression()\n",
    "    elif(estimator == 'Ridge'): ensemble = Ridge()\n",
    "    elif(estimator == 'Lasso'): ensemble = Lasso(alpha=0.035)\n",
    "    else: raise ValueError(\"Estimator not valid\")\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8734a58-90f9-4155-aee9-eadaf1d6c8b4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82eb0ba7-fed8-4d33-bdc0-fdeaaf91b540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=2000, epsilon=0.07)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=2000, epsilon=0.07)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR Traning\n",
    "multi_svr = MultiOutputRegressor(SVR(C=2000, epsilon=0.07, kernel='rbf', gamma='scale'))\n",
    "multi_svr.fit(x_train_cup, y_train_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ee3a6c5-cc26-4afe-9018-441fba2b2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 577.8656 - mean_euclidean_error: 35.6047 - val_loss: 202.2309 - val_mean_euclidean_error: 21.1916\n",
      "Epoch 2/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 128.0997 - mean_euclidean_error: 16.1848 - val_loss: 42.0022 - val_mean_euclidean_error: 10.1072\n",
      "Epoch 3/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 39.2071 - mean_euclidean_error: 9.5955 - val_loss: 31.9535 - val_mean_euclidean_error: 8.4416\n",
      "Epoch 4/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 29.3954 - mean_euclidean_error: 8.1727 - val_loss: 25.7736 - val_mean_euclidean_error: 7.3632\n",
      "Epoch 5/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 26.5311 - mean_euclidean_error: 7.7006 - val_loss: 23.2906 - val_mean_euclidean_error: 7.0476\n",
      "Epoch 6/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 24.2456 - mean_euclidean_error: 7.2521 - val_loss: 22.0122 - val_mean_euclidean_error: 6.8350\n",
      "Epoch 7/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 22.7663 - mean_euclidean_error: 7.0718 - val_loss: 20.8102 - val_mean_euclidean_error: 6.6472\n",
      "Epoch 8/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 21.0469 - mean_euclidean_error: 6.7575 - val_loss: 19.5913 - val_mean_euclidean_error: 6.3904\n",
      "Epoch 9/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 19.3593 - mean_euclidean_error: 6.4400 - val_loss: 18.1134 - val_mean_euclidean_error: 6.0902\n",
      "Epoch 10/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 17.3460 - mean_euclidean_error: 6.0281 - val_loss: 15.7411 - val_mean_euclidean_error: 5.7587\n",
      "Epoch 11/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 14.4508 - mean_euclidean_error: 5.5531 - val_loss: 12.4024 - val_mean_euclidean_error: 5.1555\n",
      "Epoch 12/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 10.9962 - mean_euclidean_error: 4.7233 - val_loss: 9.2006 - val_mean_euclidean_error: 4.2549\n",
      "Epoch 13/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 9.0144 - mean_euclidean_error: 4.2353 - val_loss: 8.4315 - val_mean_euclidean_error: 4.4772\n",
      "Epoch 14/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 7.3353 - mean_euclidean_error: 3.7250 - val_loss: 6.4353 - val_mean_euclidean_error: 3.5353\n",
      "Epoch 15/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 6.0961 - mean_euclidean_error: 3.2876 - val_loss: 5.2085 - val_mean_euclidean_error: 2.9136\n",
      "Epoch 16/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 5.1511 - mean_euclidean_error: 2.9186 - val_loss: 4.4444 - val_mean_euclidean_error: 2.5546\n",
      "Epoch 17/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 4.5504 - mean_euclidean_error: 2.6858 - val_loss: 3.7864 - val_mean_euclidean_error: 2.3910\n",
      "Epoch 18/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 4.1168 - mean_euclidean_error: 2.5354 - val_loss: 3.4538 - val_mean_euclidean_error: 2.2989\n",
      "Epoch 19/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 3.6491 - mean_euclidean_error: 2.3089 - val_loss: 3.1689 - val_mean_euclidean_error: 2.0974\n",
      "Epoch 20/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 3.3610 - mean_euclidean_error: 2.2195 - val_loss: 2.8511 - val_mean_euclidean_error: 2.0683\n",
      "Epoch 21/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.1052 - mean_euclidean_error: 2.0456 - val_loss: 2.6557 - val_mean_euclidean_error: 1.8988\n",
      "Epoch 22/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 2.9392 - mean_euclidean_error: 1.9430 - val_loss: 2.3816 - val_mean_euclidean_error: 1.7659\n",
      "Epoch 23/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 2.7806 - mean_euclidean_error: 1.8473 - val_loss: 2.3063 - val_mean_euclidean_error: 1.7397\n",
      "Epoch 24/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.6265 - mean_euclidean_error: 1.7741 - val_loss: 2.1481 - val_mean_euclidean_error: 1.5842\n",
      "Epoch 25/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.5042 - mean_euclidean_error: 1.6831 - val_loss: 2.0699 - val_mean_euclidean_error: 1.6115\n",
      "Epoch 26/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 2.4398 - mean_euclidean_error: 1.6588 - val_loss: 2.0620 - val_mean_euclidean_error: 1.5097\n",
      "Epoch 27/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 2.2968 - mean_euclidean_error: 1.5574 - val_loss: 1.9302 - val_mean_euclidean_error: 1.4876\n",
      "Epoch 28/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 2.2178 - mean_euclidean_error: 1.5701 - val_loss: 1.9121 - val_mean_euclidean_error: 1.4562\n",
      "Epoch 29/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 2.1538 - mean_euclidean_error: 1.4939 - val_loss: 1.8710 - val_mean_euclidean_error: 1.3354\n",
      "Epoch 30/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 2.0911 - mean_euclidean_error: 1.4506 - val_loss: 1.7920 - val_mean_euclidean_error: 1.3594\n",
      "Epoch 31/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.0348 - mean_euclidean_error: 1.4404 - val_loss: 1.7240 - val_mean_euclidean_error: 1.3344\n",
      "Epoch 32/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.9989 - mean_euclidean_error: 1.5009 - val_loss: 1.7262 - val_mean_euclidean_error: 1.2679\n",
      "Epoch 33/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.9370 - mean_euclidean_error: 1.3875 - val_loss: 1.6930 - val_mean_euclidean_error: 1.2899\n",
      "Epoch 34/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.8613 - mean_euclidean_error: 1.3439 - val_loss: 1.6977 - val_mean_euclidean_error: 1.3610\n",
      "Epoch 35/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.7783 - mean_euclidean_error: 1.3227 - val_loss: 1.6176 - val_mean_euclidean_error: 1.2685\n",
      "Epoch 36/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.6441 - mean_euclidean_error: 1.2606 - val_loss: 1.5944 - val_mean_euclidean_error: 1.2427\n",
      "Epoch 37/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.6193 - mean_euclidean_error: 1.2756 - val_loss: 1.6274 - val_mean_euclidean_error: 1.2688\n",
      "Epoch 38/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.6391 - mean_euclidean_error: 1.3257 - val_loss: 1.6658 - val_mean_euclidean_error: 1.3282\n",
      "Epoch 39/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.5089 - mean_euclidean_error: 1.2214 - val_loss: 1.6053 - val_mean_euclidean_error: 1.3097\n",
      "Epoch 40/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.4735 - mean_euclidean_error: 1.2017 - val_loss: 1.5422 - val_mean_euclidean_error: 1.2279\n",
      "Epoch 41/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.4663 - mean_euclidean_error: 1.1820 - val_loss: 1.4288 - val_mean_euclidean_error: 1.1836\n",
      "Epoch 42/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.4015 - mean_euclidean_error: 1.1243 - val_loss: 1.4638 - val_mean_euclidean_error: 1.1927\n",
      "Epoch 43/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.3886 - mean_euclidean_error: 1.1168 - val_loss: 1.4163 - val_mean_euclidean_error: 1.1646\n",
      "Epoch 44/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.3684 - mean_euclidean_error: 1.1132 - val_loss: 1.4354 - val_mean_euclidean_error: 1.1379\n",
      "Epoch 45/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.3654 - mean_euclidean_error: 1.1094 - val_loss: 1.4558 - val_mean_euclidean_error: 1.1670\n",
      "Epoch 46/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.4560 - mean_euclidean_error: 1.2149 - val_loss: 1.3813 - val_mean_euclidean_error: 1.1530\n",
      "Epoch 47/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.3926 - mean_euclidean_error: 1.1515 - val_loss: 1.3970 - val_mean_euclidean_error: 1.1230\n",
      "Epoch 48/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.3629 - mean_euclidean_error: 1.1283 - val_loss: 1.3951 - val_mean_euclidean_error: 1.1990\n",
      "Epoch 49/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.3204 - mean_euclidean_error: 1.0629 - val_loss: 1.3519 - val_mean_euclidean_error: 1.0705\n",
      "Epoch 50/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.2887 - mean_euclidean_error: 1.0297 - val_loss: 1.3462 - val_mean_euclidean_error: 1.1246\n",
      "Epoch 51/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.2973 - mean_euclidean_error: 1.0564 - val_loss: 1.3310 - val_mean_euclidean_error: 1.0770\n",
      "Epoch 52/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.3007 - mean_euclidean_error: 1.0498 - val_loss: 1.3378 - val_mean_euclidean_error: 1.0820\n",
      "Epoch 53/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.3007 - mean_euclidean_error: 1.0318 - val_loss: 1.3615 - val_mean_euclidean_error: 1.1824\n",
      "Epoch 54/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.2668 - mean_euclidean_error: 1.0151 - val_loss: 1.3166 - val_mean_euclidean_error: 1.1223\n",
      "Epoch 55/1500\n",
      "29/29 [==============================] - 1s 16ms/step - loss: 1.2325 - mean_euclidean_error: 0.9890 - val_loss: 1.3328 - val_mean_euclidean_error: 1.1259\n",
      "Epoch 56/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.3034 - mean_euclidean_error: 1.0787 - val_loss: 1.3376 - val_mean_euclidean_error: 1.1249\n",
      "Epoch 57/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.2409 - mean_euclidean_error: 1.0016 - val_loss: 1.2870 - val_mean_euclidean_error: 1.0306\n",
      "Epoch 58/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 1.2232 - mean_euclidean_error: 0.9699 - val_loss: 1.2596 - val_mean_euclidean_error: 1.0513\n",
      "Epoch 59/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.2123 - mean_euclidean_error: 0.9450 - val_loss: 1.2524 - val_mean_euclidean_error: 1.0554\n",
      "Epoch 60/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1954 - mean_euclidean_error: 0.9293 - val_loss: 1.2486 - val_mean_euclidean_error: 0.9919\n",
      "Epoch 61/1500\n",
      "29/29 [==============================] - 1s 16ms/step - loss: 1.2029 - mean_euclidean_error: 0.9593 - val_loss: 1.2681 - val_mean_euclidean_error: 1.0440\n",
      "Epoch 62/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.2094 - mean_euclidean_error: 0.9670 - val_loss: 1.2599 - val_mean_euclidean_error: 1.0652\n",
      "Epoch 63/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.2316 - mean_euclidean_error: 0.9918 - val_loss: 1.2702 - val_mean_euclidean_error: 1.1114\n",
      "Epoch 64/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.1756 - mean_euclidean_error: 0.9268 - val_loss: 1.2171 - val_mean_euclidean_error: 0.9795\n",
      "Epoch 65/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1940 - mean_euclidean_error: 0.9534 - val_loss: 1.3122 - val_mean_euclidean_error: 1.1319\n",
      "Epoch 66/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1620 - mean_euclidean_error: 0.8989 - val_loss: 1.1991 - val_mean_euclidean_error: 0.9457\n",
      "Epoch 67/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1443 - mean_euclidean_error: 0.8728 - val_loss: 1.1976 - val_mean_euclidean_error: 0.9619\n",
      "Epoch 68/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1418 - mean_euclidean_error: 0.8870 - val_loss: 1.1667 - val_mean_euclidean_error: 0.9263\n",
      "Epoch 69/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1395 - mean_euclidean_error: 0.8874 - val_loss: 1.1763 - val_mean_euclidean_error: 0.9860\n",
      "Epoch 70/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.1329 - mean_euclidean_error: 0.8710 - val_loss: 1.2011 - val_mean_euclidean_error: 1.0075\n",
      "Epoch 71/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.1284 - mean_euclidean_error: 0.8801 - val_loss: 1.2393 - val_mean_euclidean_error: 1.0380\n",
      "Epoch 72/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1660 - mean_euclidean_error: 0.9492 - val_loss: 1.2229 - val_mean_euclidean_error: 1.0308\n",
      "Epoch 73/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1676 - mean_euclidean_error: 0.9338 - val_loss: 1.2024 - val_mean_euclidean_error: 1.0611\n",
      "Epoch 74/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.1277 - mean_euclidean_error: 0.8678 - val_loss: 1.1527 - val_mean_euclidean_error: 0.9377\n",
      "Epoch 75/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1224 - mean_euclidean_error: 0.8779 - val_loss: 1.1570 - val_mean_euclidean_error: 0.9455\n",
      "Epoch 76/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1213 - mean_euclidean_error: 0.8821 - val_loss: 1.1243 - val_mean_euclidean_error: 0.8819\n",
      "Epoch 77/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0932 - mean_euclidean_error: 0.8370 - val_loss: 1.1570 - val_mean_euclidean_error: 0.9436\n",
      "Epoch 78/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1065 - mean_euclidean_error: 0.8496 - val_loss: 1.1708 - val_mean_euclidean_error: 0.9646\n",
      "Epoch 79/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0885 - mean_euclidean_error: 0.8177 - val_loss: 1.1661 - val_mean_euclidean_error: 0.9596\n",
      "Epoch 80/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0765 - mean_euclidean_error: 0.7963 - val_loss: 1.1437 - val_mean_euclidean_error: 0.9546\n",
      "Epoch 81/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0841 - mean_euclidean_error: 0.8154 - val_loss: 1.2010 - val_mean_euclidean_error: 1.0028\n",
      "Epoch 82/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0990 - mean_euclidean_error: 0.8373 - val_loss: 1.1457 - val_mean_euclidean_error: 0.9719\n",
      "Epoch 83/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0860 - mean_euclidean_error: 0.8390 - val_loss: 1.1385 - val_mean_euclidean_error: 0.9817\n",
      "Epoch 84/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0827 - mean_euclidean_error: 0.8423 - val_loss: 1.1393 - val_mean_euclidean_error: 0.9282\n",
      "Epoch 85/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0972 - mean_euclidean_error: 0.8491 - val_loss: 1.1450 - val_mean_euclidean_error: 0.9804\n",
      "Epoch 86/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 1.0867 - mean_euclidean_error: 0.8301 - val_loss: 1.1403 - val_mean_euclidean_error: 0.9573\n",
      "Epoch 87/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0659 - mean_euclidean_error: 0.8174 - val_loss: 1.0917 - val_mean_euclidean_error: 0.8784\n",
      "Epoch 88/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0641 - mean_euclidean_error: 0.8047 - val_loss: 1.1049 - val_mean_euclidean_error: 0.9209\n",
      "Epoch 89/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0580 - mean_euclidean_error: 0.8001 - val_loss: 1.1103 - val_mean_euclidean_error: 0.8765\n",
      "Epoch 90/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0547 - mean_euclidean_error: 0.7951 - val_loss: 1.1027 - val_mean_euclidean_error: 0.8618\n",
      "Epoch 91/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 1.0425 - mean_euclidean_error: 0.7677 - val_loss: 1.0844 - val_mean_euclidean_error: 0.8792\n",
      "Epoch 92/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0342 - mean_euclidean_error: 0.7522 - val_loss: 1.0801 - val_mean_euclidean_error: 0.8657\n",
      "Epoch 93/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0283 - mean_euclidean_error: 0.7495 - val_loss: 1.1127 - val_mean_euclidean_error: 0.9003\n",
      "Epoch 94/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 1.0361 - mean_euclidean_error: 0.7704 - val_loss: 1.0884 - val_mean_euclidean_error: 0.8997\n",
      "Epoch 95/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0463 - mean_euclidean_error: 0.7883 - val_loss: 1.0822 - val_mean_euclidean_error: 0.9162\n",
      "Epoch 96/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0243 - mean_euclidean_error: 0.7505 - val_loss: 1.0982 - val_mean_euclidean_error: 0.9391\n",
      "Epoch 97/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.0299 - mean_euclidean_error: 0.7669 - val_loss: 1.0760 - val_mean_euclidean_error: 0.8332\n",
      "Epoch 98/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0458 - mean_euclidean_error: 0.7974 - val_loss: 1.0941 - val_mean_euclidean_error: 0.8639\n",
      "Epoch 99/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0406 - mean_euclidean_error: 0.7933 - val_loss: 1.0867 - val_mean_euclidean_error: 0.9372\n",
      "Epoch 100/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0311 - mean_euclidean_error: 0.8031 - val_loss: 1.0683 - val_mean_euclidean_error: 0.8913\n",
      "Epoch 101/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0199 - mean_euclidean_error: 0.7512 - val_loss: 1.0733 - val_mean_euclidean_error: 0.8756\n",
      "Epoch 102/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 1.0110 - mean_euclidean_error: 0.7393 - val_loss: 1.0846 - val_mean_euclidean_error: 0.8938\n",
      "Epoch 103/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.0138 - mean_euclidean_error: 0.7443 - val_loss: 1.0576 - val_mean_euclidean_error: 0.8585\n",
      "Epoch 104/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0061 - mean_euclidean_error: 0.7330 - val_loss: 1.0869 - val_mean_euclidean_error: 0.9054\n",
      "Epoch 105/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0111 - mean_euclidean_error: 0.7359 - val_loss: 1.0487 - val_mean_euclidean_error: 0.8410\n",
      "Epoch 106/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0046 - mean_euclidean_error: 0.7408 - val_loss: 1.0468 - val_mean_euclidean_error: 0.8618\n",
      "Epoch 107/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0026 - mean_euclidean_error: 0.7307 - val_loss: 1.0444 - val_mean_euclidean_error: 0.8449\n",
      "Epoch 108/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9975 - mean_euclidean_error: 0.7272 - val_loss: 1.0602 - val_mean_euclidean_error: 0.8748\n",
      "Epoch 109/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0144 - mean_euclidean_error: 0.7580 - val_loss: 1.1053 - val_mean_euclidean_error: 0.9583\n",
      "Epoch 110/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0145 - mean_euclidean_error: 0.7632 - val_loss: 1.0868 - val_mean_euclidean_error: 0.8952\n",
      "Epoch 111/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9931 - mean_euclidean_error: 0.7265 - val_loss: 1.0606 - val_mean_euclidean_error: 0.8793\n",
      "Epoch 112/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9971 - mean_euclidean_error: 0.7514 - val_loss: 1.0945 - val_mean_euclidean_error: 0.9154\n",
      "Epoch 113/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0074 - mean_euclidean_error: 0.7534 - val_loss: 1.0494 - val_mean_euclidean_error: 0.8832\n",
      "Epoch 114/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0004 - mean_euclidean_error: 0.7395 - val_loss: 1.0321 - val_mean_euclidean_error: 0.8458\n",
      "Epoch 115/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9909 - mean_euclidean_error: 0.7283 - val_loss: 1.1204 - val_mean_euclidean_error: 1.0328\n",
      "Epoch 116/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.9886 - mean_euclidean_error: 0.7221 - val_loss: 1.0241 - val_mean_euclidean_error: 0.7823\n",
      "Epoch 117/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9947 - mean_euclidean_error: 0.7281 - val_loss: 1.0253 - val_mean_euclidean_error: 0.8268\n",
      "Epoch 118/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9726 - mean_euclidean_error: 0.6953 - val_loss: 1.0166 - val_mean_euclidean_error: 0.7875\n",
      "Epoch 119/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9705 - mean_euclidean_error: 0.7033 - val_loss: 1.0251 - val_mean_euclidean_error: 0.8221\n",
      "Epoch 120/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9734 - mean_euclidean_error: 0.7064 - val_loss: 1.0191 - val_mean_euclidean_error: 0.8080\n",
      "Epoch 121/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9709 - mean_euclidean_error: 0.7095 - val_loss: 1.0256 - val_mean_euclidean_error: 0.8515\n",
      "Epoch 122/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9829 - mean_euclidean_error: 0.7292 - val_loss: 1.0589 - val_mean_euclidean_error: 0.9052\n",
      "Epoch 123/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9919 - mean_euclidean_error: 0.7482 - val_loss: 1.0360 - val_mean_euclidean_error: 0.8802\n",
      "Epoch 124/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9666 - mean_euclidean_error: 0.7007 - val_loss: 1.0064 - val_mean_euclidean_error: 0.8175\n",
      "Epoch 125/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9586 - mean_euclidean_error: 0.6793 - val_loss: 1.0308 - val_mean_euclidean_error: 0.8272\n",
      "Epoch 126/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.9571 - mean_euclidean_error: 0.6999 - val_loss: 1.0110 - val_mean_euclidean_error: 0.8162\n",
      "Epoch 127/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9699 - mean_euclidean_error: 0.6947 - val_loss: 1.0211 - val_mean_euclidean_error: 0.8281\n",
      "Epoch 128/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.9604 - mean_euclidean_error: 0.6879 - val_loss: 1.0204 - val_mean_euclidean_error: 0.8661\n",
      "Epoch 129/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9567 - mean_euclidean_error: 0.6848 - val_loss: 1.0028 - val_mean_euclidean_error: 0.8189\n",
      "Epoch 130/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9506 - mean_euclidean_error: 0.6721 - val_loss: 1.0122 - val_mean_euclidean_error: 0.8410\n",
      "Epoch 131/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9491 - mean_euclidean_error: 0.6731 - val_loss: 0.9973 - val_mean_euclidean_error: 0.7782\n",
      "Epoch 132/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9436 - mean_euclidean_error: 0.6643 - val_loss: 0.9844 - val_mean_euclidean_error: 0.7959\n",
      "Epoch 133/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9430 - mean_euclidean_error: 0.6636 - val_loss: 1.0077 - val_mean_euclidean_error: 0.8274\n",
      "Epoch 134/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9377 - mean_euclidean_error: 0.6517 - val_loss: 0.9971 - val_mean_euclidean_error: 0.8129\n",
      "Epoch 135/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9472 - mean_euclidean_error: 0.6782 - val_loss: 1.0082 - val_mean_euclidean_error: 0.7906\n",
      "Epoch 136/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9513 - mean_euclidean_error: 0.6877 - val_loss: 1.0030 - val_mean_euclidean_error: 0.8017\n",
      "Epoch 137/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9478 - mean_euclidean_error: 0.6759 - val_loss: 1.0058 - val_mean_euclidean_error: 0.8502\n",
      "Epoch 138/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9354 - mean_euclidean_error: 0.6582 - val_loss: 0.9911 - val_mean_euclidean_error: 0.8229\n",
      "Epoch 139/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.9364 - mean_euclidean_error: 0.6651 - val_loss: 1.0036 - val_mean_euclidean_error: 0.8284\n",
      "Epoch 140/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.9336 - mean_euclidean_error: 0.6461 - val_loss: 0.9854 - val_mean_euclidean_error: 0.8014\n",
      "Epoch 141/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9259 - mean_euclidean_error: 0.6443 - val_loss: 0.9836 - val_mean_euclidean_error: 0.7765\n",
      "Epoch 142/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.9241 - mean_euclidean_error: 0.6382 - val_loss: 0.9956 - val_mean_euclidean_error: 0.8171\n",
      "Epoch 143/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.9288 - mean_euclidean_error: 0.6426 - val_loss: 0.9843 - val_mean_euclidean_error: 0.7349\n",
      "Epoch 144/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9414 - mean_euclidean_error: 0.6898 - val_loss: 1.0034 - val_mean_euclidean_error: 0.8484\n",
      "Epoch 145/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9318 - mean_euclidean_error: 0.6601 - val_loss: 0.9822 - val_mean_euclidean_error: 0.7741\n",
      "Epoch 146/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9220 - mean_euclidean_error: 0.6450 - val_loss: 0.9945 - val_mean_euclidean_error: 0.8276\n",
      "Epoch 147/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9220 - mean_euclidean_error: 0.6634 - val_loss: 0.9787 - val_mean_euclidean_error: 0.8019\n",
      "Epoch 148/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9655 - mean_euclidean_error: 0.7177 - val_loss: 0.9868 - val_mean_euclidean_error: 0.7764\n",
      "Epoch 149/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9341 - mean_euclidean_error: 0.6642 - val_loss: 0.9947 - val_mean_euclidean_error: 0.8060\n",
      "Epoch 150/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9470 - mean_euclidean_error: 0.7056 - val_loss: 1.0030 - val_mean_euclidean_error: 0.8001\n",
      "Epoch 151/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9429 - mean_euclidean_error: 0.6937 - val_loss: 0.9910 - val_mean_euclidean_error: 0.8079\n",
      "Epoch 152/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9161 - mean_euclidean_error: 0.6308 - val_loss: 0.9629 - val_mean_euclidean_error: 0.7385\n",
      "Epoch 153/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9118 - mean_euclidean_error: 0.6268 - val_loss: 0.9789 - val_mean_euclidean_error: 0.8173\n",
      "Epoch 154/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.9210 - mean_euclidean_error: 0.6373 - val_loss: 0.9908 - val_mean_euclidean_error: 0.7430\n",
      "Epoch 155/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9268 - mean_euclidean_error: 0.6965 - val_loss: 0.9736 - val_mean_euclidean_error: 0.7834\n",
      "Epoch 156/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.9129 - mean_euclidean_error: 0.6284 - val_loss: 0.9753 - val_mean_euclidean_error: 0.7941\n",
      "Epoch 157/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.9035 - mean_euclidean_error: 0.6244 - val_loss: 0.9658 - val_mean_euclidean_error: 0.7725\n",
      "Epoch 158/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9022 - mean_euclidean_error: 0.6315 - val_loss: 0.9453 - val_mean_euclidean_error: 0.7056\n",
      "Epoch 159/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8952 - mean_euclidean_error: 0.6096 - val_loss: 0.9730 - val_mean_euclidean_error: 0.7661\n",
      "Epoch 160/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8985 - mean_euclidean_error: 0.6205 - val_loss: 0.9556 - val_mean_euclidean_error: 0.7223\n",
      "Epoch 161/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8968 - mean_euclidean_error: 0.6187 - val_loss: 0.9630 - val_mean_euclidean_error: 0.7718\n",
      "Epoch 162/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9009 - mean_euclidean_error: 0.6220 - val_loss: 0.9607 - val_mean_euclidean_error: 0.7124\n",
      "Epoch 163/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8870 - mean_euclidean_error: 0.5959 - val_loss: 0.9731 - val_mean_euclidean_error: 0.7627\n",
      "Epoch 164/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8856 - mean_euclidean_error: 0.5996 - val_loss: 0.9655 - val_mean_euclidean_error: 0.7333\n",
      "Epoch 165/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8899 - mean_euclidean_error: 0.6075 - val_loss: 0.9956 - val_mean_euclidean_error: 0.8255\n",
      "Epoch 166/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9029 - mean_euclidean_error: 0.6387 - val_loss: 0.9949 - val_mean_euclidean_error: 0.7998\n",
      "Epoch 167/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.8900 - mean_euclidean_error: 0.6278 - val_loss: 0.9597 - val_mean_euclidean_error: 0.7556\n",
      "Epoch 168/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8875 - mean_euclidean_error: 0.6154 - val_loss: 0.9668 - val_mean_euclidean_error: 0.7445\n",
      "Epoch 169/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.8969 - mean_euclidean_error: 0.6424 - val_loss: 0.9678 - val_mean_euclidean_error: 0.7560\n",
      "Epoch 170/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8881 - mean_euclidean_error: 0.6141 - val_loss: 0.9611 - val_mean_euclidean_error: 0.7109\n",
      "Epoch 171/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8828 - mean_euclidean_error: 0.6128 - val_loss: 0.9476 - val_mean_euclidean_error: 0.6991\n",
      "Epoch 172/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8901 - mean_euclidean_error: 0.6326 - val_loss: 0.9515 - val_mean_euclidean_error: 0.7627\n",
      "Epoch 173/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8841 - mean_euclidean_error: 0.6164 - val_loss: 0.9516 - val_mean_euclidean_error: 0.7089\n",
      "Epoch 174/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8818 - mean_euclidean_error: 0.6150 - val_loss: 0.9534 - val_mean_euclidean_error: 0.7278\n",
      "Epoch 175/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8906 - mean_euclidean_error: 0.6371 - val_loss: 0.9708 - val_mean_euclidean_error: 0.7909\n",
      "Epoch 176/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8786 - mean_euclidean_error: 0.6084 - val_loss: 0.9510 - val_mean_euclidean_error: 0.7538\n",
      "Epoch 177/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8802 - mean_euclidean_error: 0.6106 - val_loss: 0.9478 - val_mean_euclidean_error: 0.7336\n",
      "Epoch 178/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8769 - mean_euclidean_error: 0.6024 - val_loss: 0.9523 - val_mean_euclidean_error: 0.7539\n",
      "Epoch 179/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8843 - mean_euclidean_error: 0.6173 - val_loss: 0.9413 - val_mean_euclidean_error: 0.6921\n",
      "Epoch 180/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8694 - mean_euclidean_error: 0.5828 - val_loss: 0.9418 - val_mean_euclidean_error: 0.7211\n",
      "Epoch 181/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8741 - mean_euclidean_error: 0.6025 - val_loss: 0.9586 - val_mean_euclidean_error: 0.7626\n",
      "Epoch 182/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8770 - mean_euclidean_error: 0.6096 - val_loss: 0.9380 - val_mean_euclidean_error: 0.7265\n",
      "Epoch 183/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9004 - mean_euclidean_error: 0.6668 - val_loss: 0.9718 - val_mean_euclidean_error: 0.7930\n",
      "Epoch 184/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8786 - mean_euclidean_error: 0.6150 - val_loss: 0.9557 - val_mean_euclidean_error: 0.7298\n",
      "Epoch 185/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8763 - mean_euclidean_error: 0.6050 - val_loss: 0.9744 - val_mean_euclidean_error: 0.8048\n",
      "Epoch 186/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8639 - mean_euclidean_error: 0.5824 - val_loss: 0.9458 - val_mean_euclidean_error: 0.7187\n",
      "Epoch 187/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8577 - mean_euclidean_error: 0.5653 - val_loss: 0.9441 - val_mean_euclidean_error: 0.7245\n",
      "Epoch 188/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8628 - mean_euclidean_error: 0.5919 - val_loss: 0.9410 - val_mean_euclidean_error: 0.7426\n",
      "Epoch 189/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8606 - mean_euclidean_error: 0.5845 - val_loss: 0.9525 - val_mean_euclidean_error: 0.7381\n",
      "Epoch 190/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8833 - mean_euclidean_error: 0.6261 - val_loss: 0.9613 - val_mean_euclidean_error: 0.7293\n",
      "Epoch 191/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8676 - mean_euclidean_error: 0.5946 - val_loss: 0.9382 - val_mean_euclidean_error: 0.7156\n",
      "Epoch 192/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8667 - mean_euclidean_error: 0.5853 - val_loss: 0.9532 - val_mean_euclidean_error: 0.7353\n",
      "Epoch 193/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8614 - mean_euclidean_error: 0.5834 - val_loss: 0.9692 - val_mean_euclidean_error: 0.7818\n",
      "Epoch 194/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8569 - mean_euclidean_error: 0.5728 - val_loss: 0.9400 - val_mean_euclidean_error: 0.7211\n",
      "Epoch 195/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8554 - mean_euclidean_error: 0.5676 - val_loss: 0.9288 - val_mean_euclidean_error: 0.6921\n",
      "Epoch 196/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.8521 - mean_euclidean_error: 0.5685 - val_loss: 0.9301 - val_mean_euclidean_error: 0.7126\n",
      "Epoch 197/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8611 - mean_euclidean_error: 0.5914 - val_loss: 0.9538 - val_mean_euclidean_error: 0.7492\n",
      "Epoch 198/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8644 - mean_euclidean_error: 0.5980 - val_loss: 0.9692 - val_mean_euclidean_error: 0.7874\n",
      "Epoch 199/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8732 - mean_euclidean_error: 0.6179 - val_loss: 0.9814 - val_mean_euclidean_error: 0.8242\n",
      "Epoch 200/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8639 - mean_euclidean_error: 0.5907 - val_loss: 0.9397 - val_mean_euclidean_error: 0.6963\n",
      "Epoch 201/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8493 - mean_euclidean_error: 0.5570 - val_loss: 0.9221 - val_mean_euclidean_error: 0.6889\n",
      "Epoch 202/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.8512 - mean_euclidean_error: 0.5702 - val_loss: 0.9269 - val_mean_euclidean_error: 0.6739\n",
      "Epoch 203/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8537 - mean_euclidean_error: 0.5664 - val_loss: 0.9412 - val_mean_euclidean_error: 0.7328\n",
      "Epoch 204/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8444 - mean_euclidean_error: 0.5587 - val_loss: 0.9454 - val_mean_euclidean_error: 0.7076\n",
      "Epoch 205/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8506 - mean_euclidean_error: 0.5644 - val_loss: 0.9517 - val_mean_euclidean_error: 0.7483\n",
      "Epoch 206/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8563 - mean_euclidean_error: 0.5769 - val_loss: 0.9670 - val_mean_euclidean_error: 0.7416\n",
      "Epoch 207/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8583 - mean_euclidean_error: 0.5970 - val_loss: 0.9326 - val_mean_euclidean_error: 0.7114\n",
      "Epoch 208/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8595 - mean_euclidean_error: 0.5949 - val_loss: 0.9683 - val_mean_euclidean_error: 0.7270\n",
      "Epoch 209/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8587 - mean_euclidean_error: 0.5888 - val_loss: 0.9416 - val_mean_euclidean_error: 0.7054\n",
      "Epoch 210/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8475 - mean_euclidean_error: 0.5655 - val_loss: 0.9399 - val_mean_euclidean_error: 0.6926\n",
      "Epoch 211/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8505 - mean_euclidean_error: 0.5786 - val_loss: 0.9309 - val_mean_euclidean_error: 0.7190\n",
      "Epoch 212/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8557 - mean_euclidean_error: 0.5838 - val_loss: 0.9244 - val_mean_euclidean_error: 0.6704\n",
      "Epoch 213/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8474 - mean_euclidean_error: 0.5642 - val_loss: 0.9246 - val_mean_euclidean_error: 0.6877\n",
      "Epoch 214/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8420 - mean_euclidean_error: 0.5599 - val_loss: 0.9374 - val_mean_euclidean_error: 0.6965\n",
      "Epoch 215/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8475 - mean_euclidean_error: 0.5708 - val_loss: 0.9348 - val_mean_euclidean_error: 0.6836\n",
      "Epoch 216/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8444 - mean_euclidean_error: 0.5664 - val_loss: 0.9249 - val_mean_euclidean_error: 0.6948\n",
      "Epoch 217/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8471 - mean_euclidean_error: 0.5701 - val_loss: 0.9469 - val_mean_euclidean_error: 0.7219\n",
      "Epoch 218/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8435 - mean_euclidean_error: 0.5585 - val_loss: 0.9440 - val_mean_euclidean_error: 0.7018\n",
      "Epoch 219/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8430 - mean_euclidean_error: 0.5549 - val_loss: 0.9203 - val_mean_euclidean_error: 0.6739\n",
      "Epoch 220/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8340 - mean_euclidean_error: 0.5290 - val_loss: 0.9154 - val_mean_euclidean_error: 0.6838\n",
      "Epoch 221/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8401 - mean_euclidean_error: 0.5471 - val_loss: 0.9335 - val_mean_euclidean_error: 0.6827\n",
      "Epoch 222/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8425 - mean_euclidean_error: 0.5516 - val_loss: 0.9407 - val_mean_euclidean_error: 0.7579\n",
      "Epoch 223/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8357 - mean_euclidean_error: 0.5457 - val_loss: 0.9420 - val_mean_euclidean_error: 0.7216\n",
      "Epoch 224/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8300 - mean_euclidean_error: 0.5241 - val_loss: 0.9363 - val_mean_euclidean_error: 0.7162\n",
      "Epoch 225/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8299 - mean_euclidean_error: 0.5433 - val_loss: 0.9188 - val_mean_euclidean_error: 0.6851\n",
      "Epoch 226/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.8372 - mean_euclidean_error: 0.5485 - val_loss: 0.9340 - val_mean_euclidean_error: 0.6987\n",
      "Epoch 227/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8406 - mean_euclidean_error: 0.5641 - val_loss: 0.9328 - val_mean_euclidean_error: 0.7018\n",
      "Epoch 228/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8382 - mean_euclidean_error: 0.5552 - val_loss: 0.9287 - val_mean_euclidean_error: 0.6725\n",
      "Epoch 229/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8331 - mean_euclidean_error: 0.5324 - val_loss: 0.9345 - val_mean_euclidean_error: 0.7328\n",
      "Epoch 230/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8353 - mean_euclidean_error: 0.5466 - val_loss: 0.9288 - val_mean_euclidean_error: 0.7029\n",
      "Epoch 231/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8327 - mean_euclidean_error: 0.5454 - val_loss: 0.9600 - val_mean_euclidean_error: 0.7652\n",
      "Epoch 232/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8437 - mean_euclidean_error: 0.5591 - val_loss: 0.9289 - val_mean_euclidean_error: 0.6988\n",
      "Epoch 233/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8327 - mean_euclidean_error: 0.5426 - val_loss: 0.9180 - val_mean_euclidean_error: 0.6789\n",
      "Epoch 234/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8362 - mean_euclidean_error: 0.5477 - val_loss: 0.9163 - val_mean_euclidean_error: 0.6632\n",
      "Epoch 235/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8327 - mean_euclidean_error: 0.5701 - val_loss: 0.9364 - val_mean_euclidean_error: 0.7256\n",
      "Epoch 236/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8296 - mean_euclidean_error: 0.5301 - val_loss: 0.9194 - val_mean_euclidean_error: 0.6728\n",
      "Epoch 237/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8311 - mean_euclidean_error: 0.5340 - val_loss: 0.9354 - val_mean_euclidean_error: 0.7304\n",
      "Epoch 238/1500\n",
      "29/29 [==============================] - 1s 16ms/step - loss: 0.8362 - mean_euclidean_error: 0.5447 - val_loss: 0.9434 - val_mean_euclidean_error: 0.7282\n",
      "Epoch 239/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8374 - mean_euclidean_error: 0.5605 - val_loss: 0.9253 - val_mean_euclidean_error: 0.6986\n",
      "Epoch 240/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8534 - mean_euclidean_error: 0.5965 - val_loss: 0.9239 - val_mean_euclidean_error: 0.6980\n",
      "Epoch 241/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8304 - mean_euclidean_error: 0.5434 - val_loss: 0.9218 - val_mean_euclidean_error: 0.6619\n",
      "Epoch 242/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.8295 - mean_euclidean_error: 0.5505 - val_loss: 0.9326 - val_mean_euclidean_error: 0.7327\n",
      "Epoch 243/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8337 - mean_euclidean_error: 0.5582 - val_loss: 0.9365 - val_mean_euclidean_error: 0.7151\n",
      "Epoch 244/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8354 - mean_euclidean_error: 0.5551 - val_loss: 0.9392 - val_mean_euclidean_error: 0.7110\n",
      "Epoch 245/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8303 - mean_euclidean_error: 0.5406 - val_loss: 0.9248 - val_mean_euclidean_error: 0.7094\n",
      "Epoch 246/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8317 - mean_euclidean_error: 0.5419 - val_loss: 0.9399 - val_mean_euclidean_error: 0.7401\n",
      "Epoch 247/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8358 - mean_euclidean_error: 0.5546 - val_loss: 0.9284 - val_mean_euclidean_error: 0.7272\n",
      "Epoch 248/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8304 - mean_euclidean_error: 0.5517 - val_loss: 0.9194 - val_mean_euclidean_error: 0.6811\n",
      "Epoch 249/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8354 - mean_euclidean_error: 0.5517 - val_loss: 0.9436 - val_mean_euclidean_error: 0.7449\n",
      "Epoch 250/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8236 - mean_euclidean_error: 0.5306 - val_loss: 0.9213 - val_mean_euclidean_error: 0.6916\n",
      "Epoch 251/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8292 - mean_euclidean_error: 0.5426 - val_loss: 0.9101 - val_mean_euclidean_error: 0.6575\n",
      "Epoch 252/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8199 - mean_euclidean_error: 0.5179 - val_loss: 0.9088 - val_mean_euclidean_error: 0.6792\n",
      "Epoch 253/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8235 - mean_euclidean_error: 0.5324 - val_loss: 0.9023 - val_mean_euclidean_error: 0.6542\n",
      "Epoch 254/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8213 - mean_euclidean_error: 0.5202 - val_loss: 0.9133 - val_mean_euclidean_error: 0.6571\n",
      "Epoch 255/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8183 - mean_euclidean_error: 0.5203 - val_loss: 0.9141 - val_mean_euclidean_error: 0.6852\n",
      "Epoch 256/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8198 - mean_euclidean_error: 0.5209 - val_loss: 0.9223 - val_mean_euclidean_error: 0.7004\n",
      "Epoch 257/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8270 - mean_euclidean_error: 0.5460 - val_loss: 0.9122 - val_mean_euclidean_error: 0.6607\n",
      "Epoch 258/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.8212 - mean_euclidean_error: 0.5250 - val_loss: 0.9092 - val_mean_euclidean_error: 0.6515\n",
      "Epoch 259/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8241 - mean_euclidean_error: 0.5377 - val_loss: 0.9219 - val_mean_euclidean_error: 0.6733\n",
      "Epoch 260/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8239 - mean_euclidean_error: 0.5299 - val_loss: 0.9372 - val_mean_euclidean_error: 0.7094\n",
      "Epoch 261/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8179 - mean_euclidean_error: 0.5384 - val_loss: 0.9268 - val_mean_euclidean_error: 0.6894\n",
      "Epoch 262/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8244 - mean_euclidean_error: 0.5378 - val_loss: 0.9200 - val_mean_euclidean_error: 0.6800\n",
      "Epoch 263/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8202 - mean_euclidean_error: 0.5326 - val_loss: 0.9201 - val_mean_euclidean_error: 0.6843\n",
      "Epoch 264/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8143 - mean_euclidean_error: 0.5118 - val_loss: 0.9375 - val_mean_euclidean_error: 0.7012\n",
      "Epoch 265/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8177 - mean_euclidean_error: 0.5191 - val_loss: 0.9212 - val_mean_euclidean_error: 0.6793\n",
      "Epoch 266/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8287 - mean_euclidean_error: 0.5423 - val_loss: 0.9330 - val_mean_euclidean_error: 0.7072\n",
      "Epoch 267/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8337 - mean_euclidean_error: 0.5614 - val_loss: 0.9558 - val_mean_euclidean_error: 0.7540\n",
      "Epoch 268/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8246 - mean_euclidean_error: 0.5620 - val_loss: 0.9293 - val_mean_euclidean_error: 0.7152\n",
      "Epoch 269/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8206 - mean_euclidean_error: 0.5329 - val_loss: 0.9090 - val_mean_euclidean_error: 0.6530\n",
      "Epoch 270/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8173 - mean_euclidean_error: 0.5226 - val_loss: 0.9223 - val_mean_euclidean_error: 0.6900\n",
      "Epoch 271/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8095 - mean_euclidean_error: 0.5033 - val_loss: 0.9031 - val_mean_euclidean_error: 0.6392\n",
      "Epoch 272/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8118 - mean_euclidean_error: 0.5130 - val_loss: 0.9042 - val_mean_euclidean_error: 0.6577\n",
      "Epoch 273/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8175 - mean_euclidean_error: 0.5255 - val_loss: 0.9093 - val_mean_euclidean_error: 0.6602\n",
      "Epoch 274/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8164 - mean_euclidean_error: 0.5197 - val_loss: 0.9263 - val_mean_euclidean_error: 0.7056\n",
      "Epoch 275/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8139 - mean_euclidean_error: 0.5202 - val_loss: 0.9071 - val_mean_euclidean_error: 0.6612\n",
      "Epoch 276/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8142 - mean_euclidean_error: 0.5210 - val_loss: 0.9183 - val_mean_euclidean_error: 0.6855\n",
      "Epoch 277/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8167 - mean_euclidean_error: 0.5289 - val_loss: 0.9165 - val_mean_euclidean_error: 0.6604\n",
      "Epoch 278/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8219 - mean_euclidean_error: 0.5389 - val_loss: 0.9206 - val_mean_euclidean_error: 0.7056\n",
      "Epoch 279/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8171 - mean_euclidean_error: 0.5395 - val_loss: 0.9353 - val_mean_euclidean_error: 0.7243\n",
      "Epoch 280/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8267 - mean_euclidean_error: 0.5455 - val_loss: 0.9133 - val_mean_euclidean_error: 0.6426\n",
      "Epoch 281/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8158 - mean_euclidean_error: 0.5230 - val_loss: 0.9322 - val_mean_euclidean_error: 0.7122\n",
      "Epoch 282/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8151 - mean_euclidean_error: 0.5185 - val_loss: 0.9066 - val_mean_euclidean_error: 0.6622\n",
      "Epoch 283/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8048 - mean_euclidean_error: 0.5016 - val_loss: 0.9049 - val_mean_euclidean_error: 0.6727\n",
      "Epoch 284/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8045 - mean_euclidean_error: 0.4933 - val_loss: 0.8994 - val_mean_euclidean_error: 0.6258\n",
      "Epoch 285/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8048 - mean_euclidean_error: 0.5075 - val_loss: 0.9152 - val_mean_euclidean_error: 0.6752\n",
      "Epoch 286/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8149 - mean_euclidean_error: 0.5236 - val_loss: 0.9517 - val_mean_euclidean_error: 0.7733\n",
      "Epoch 287/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8175 - mean_euclidean_error: 0.5328 - val_loss: 0.9221 - val_mean_euclidean_error: 0.7008\n",
      "Epoch 288/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8089 - mean_euclidean_error: 0.5053 - val_loss: 0.8991 - val_mean_euclidean_error: 0.6324\n",
      "Epoch 289/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8081 - mean_euclidean_error: 0.5064 - val_loss: 0.8997 - val_mean_euclidean_error: 0.6586\n",
      "Epoch 290/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8114 - mean_euclidean_error: 0.5209 - val_loss: 0.9241 - val_mean_euclidean_error: 0.6938\n",
      "Epoch 291/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8090 - mean_euclidean_error: 0.5119 - val_loss: 0.9093 - val_mean_euclidean_error: 0.6662\n",
      "Epoch 292/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8067 - mean_euclidean_error: 0.5022 - val_loss: 0.9102 - val_mean_euclidean_error: 0.6816\n",
      "Epoch 293/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8083 - mean_euclidean_error: 0.5109 - val_loss: 0.9031 - val_mean_euclidean_error: 0.6539\n",
      "Epoch 294/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7997 - mean_euclidean_error: 0.4959 - val_loss: 0.9040 - val_mean_euclidean_error: 0.6753\n",
      "Epoch 295/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.8068 - mean_euclidean_error: 0.5090 - val_loss: 0.9165 - val_mean_euclidean_error: 0.6905\n",
      "Epoch 296/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8153 - mean_euclidean_error: 0.5296 - val_loss: 0.9075 - val_mean_euclidean_error: 0.6713\n",
      "Epoch 297/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8067 - mean_euclidean_error: 0.5075 - val_loss: 0.9182 - val_mean_euclidean_error: 0.6844\n",
      "Epoch 298/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7996 - mean_euclidean_error: 0.4894 - val_loss: 0.8988 - val_mean_euclidean_error: 0.6637\n",
      "Epoch 299/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7994 - mean_euclidean_error: 0.4970 - val_loss: 0.9052 - val_mean_euclidean_error: 0.6706\n",
      "Epoch 300/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8020 - mean_euclidean_error: 0.4975 - val_loss: 0.9084 - val_mean_euclidean_error: 0.6603\n",
      "Epoch 301/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7980 - mean_euclidean_error: 0.4811 - val_loss: 0.8904 - val_mean_euclidean_error: 0.6331\n",
      "Epoch 302/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7974 - mean_euclidean_error: 0.4874 - val_loss: 0.8982 - val_mean_euclidean_error: 0.6695\n",
      "Epoch 303/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7958 - mean_euclidean_error: 0.4846 - val_loss: 0.8928 - val_mean_euclidean_error: 0.6360\n",
      "Epoch 304/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8067 - mean_euclidean_error: 0.5070 - val_loss: 0.9088 - val_mean_euclidean_error: 0.6854\n",
      "Epoch 305/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8025 - mean_euclidean_error: 0.4979 - val_loss: 0.8936 - val_mean_euclidean_error: 0.6252\n",
      "Epoch 306/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7958 - mean_euclidean_error: 0.4824 - val_loss: 0.8887 - val_mean_euclidean_error: 0.6452\n",
      "Epoch 307/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7944 - mean_euclidean_error: 0.4816 - val_loss: 0.8943 - val_mean_euclidean_error: 0.6510\n",
      "Epoch 308/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7980 - mean_euclidean_error: 0.4875 - val_loss: 0.8837 - val_mean_euclidean_error: 0.6355\n",
      "Epoch 309/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7942 - mean_euclidean_error: 0.4896 - val_loss: 0.9056 - val_mean_euclidean_error: 0.6428\n",
      "Epoch 310/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8016 - mean_euclidean_error: 0.5036 - val_loss: 0.8972 - val_mean_euclidean_error: 0.6438\n",
      "Epoch 311/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8086 - mean_euclidean_error: 0.5105 - val_loss: 0.8892 - val_mean_euclidean_error: 0.6387\n",
      "Epoch 312/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7994 - mean_euclidean_error: 0.5032 - val_loss: 0.8957 - val_mean_euclidean_error: 0.6755\n",
      "Epoch 313/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7989 - mean_euclidean_error: 0.4970 - val_loss: 0.9128 - val_mean_euclidean_error: 0.6558\n",
      "Epoch 314/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7980 - mean_euclidean_error: 0.4869 - val_loss: 0.8933 - val_mean_euclidean_error: 0.6329\n",
      "Epoch 315/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7934 - mean_euclidean_error: 0.4831 - val_loss: 0.8972 - val_mean_euclidean_error: 0.6240\n",
      "Epoch 316/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7935 - mean_euclidean_error: 0.4839 - val_loss: 0.8954 - val_mean_euclidean_error: 0.6373\n",
      "Epoch 317/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7941 - mean_euclidean_error: 0.4755 - val_loss: 0.8871 - val_mean_euclidean_error: 0.6216\n",
      "Epoch 318/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7943 - mean_euclidean_error: 0.4778 - val_loss: 0.8982 - val_mean_euclidean_error: 0.6440\n",
      "Epoch 319/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7953 - mean_euclidean_error: 0.4871 - val_loss: 0.9019 - val_mean_euclidean_error: 0.6214\n",
      "Epoch 320/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8010 - mean_euclidean_error: 0.5111 - val_loss: 0.9036 - val_mean_euclidean_error: 0.6600\n",
      "Epoch 321/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8068 - mean_euclidean_error: 0.5192 - val_loss: 0.9148 - val_mean_euclidean_error: 0.7123\n",
      "Epoch 322/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8056 - mean_euclidean_error: 0.5159 - val_loss: 0.8995 - val_mean_euclidean_error: 0.6511\n",
      "Epoch 323/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7900 - mean_euclidean_error: 0.4725 - val_loss: 0.8994 - val_mean_euclidean_error: 0.6689\n",
      "Epoch 324/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7910 - mean_euclidean_error: 0.4786 - val_loss: 0.8975 - val_mean_euclidean_error: 0.6543\n",
      "Epoch 325/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7927 - mean_euclidean_error: 0.4791 - val_loss: 0.9041 - val_mean_euclidean_error: 0.6600\n",
      "Epoch 326/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7919 - mean_euclidean_error: 0.4803 - val_loss: 0.9010 - val_mean_euclidean_error: 0.6463\n",
      "Epoch 327/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7915 - mean_euclidean_error: 0.4859 - val_loss: 0.9057 - val_mean_euclidean_error: 0.6663\n",
      "Epoch 328/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7933 - mean_euclidean_error: 0.4829 - val_loss: 0.9231 - val_mean_euclidean_error: 0.6996\n",
      "Epoch 329/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7965 - mean_euclidean_error: 0.4942 - val_loss: 0.9056 - val_mean_euclidean_error: 0.7032\n",
      "Epoch 330/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7965 - mean_euclidean_error: 0.5056 - val_loss: 0.8942 - val_mean_euclidean_error: 0.6354\n",
      "Epoch 331/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7939 - mean_euclidean_error: 0.4926 - val_loss: 0.8874 - val_mean_euclidean_error: 0.6460\n",
      "Epoch 332/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7940 - mean_euclidean_error: 0.4888 - val_loss: 0.9033 - val_mean_euclidean_error: 0.6735\n",
      "Epoch 333/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7926 - mean_euclidean_error: 0.4888 - val_loss: 0.9174 - val_mean_euclidean_error: 0.7131\n",
      "Epoch 334/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7953 - mean_euclidean_error: 0.4966 - val_loss: 0.8996 - val_mean_euclidean_error: 0.6763\n",
      "Epoch 335/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7904 - mean_euclidean_error: 0.4850 - val_loss: 0.8919 - val_mean_euclidean_error: 0.6292\n",
      "Epoch 336/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7893 - mean_euclidean_error: 0.4768 - val_loss: 0.8722 - val_mean_euclidean_error: 0.5920\n",
      "Epoch 337/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7857 - mean_euclidean_error: 0.4639 - val_loss: 0.8824 - val_mean_euclidean_error: 0.6253\n",
      "Epoch 338/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7851 - mean_euclidean_error: 0.4638 - val_loss: 0.8786 - val_mean_euclidean_error: 0.6153\n",
      "Epoch 339/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7869 - mean_euclidean_error: 0.4786 - val_loss: 0.8805 - val_mean_euclidean_error: 0.6136\n",
      "Epoch 340/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7912 - mean_euclidean_error: 0.4846 - val_loss: 0.8974 - val_mean_euclidean_error: 0.6609\n",
      "Epoch 341/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7962 - mean_euclidean_error: 0.4966 - val_loss: 0.8866 - val_mean_euclidean_error: 0.6315\n",
      "Epoch 342/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7885 - mean_euclidean_error: 0.4785 - val_loss: 0.8993 - val_mean_euclidean_error: 0.6761\n",
      "Epoch 343/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7925 - mean_euclidean_error: 0.5001 - val_loss: 0.8822 - val_mean_euclidean_error: 0.6251\n",
      "Epoch 344/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7899 - mean_euclidean_error: 0.4792 - val_loss: 0.8904 - val_mean_euclidean_error: 0.6451\n",
      "Epoch 345/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7890 - mean_euclidean_error: 0.4802 - val_loss: 0.8862 - val_mean_euclidean_error: 0.6280\n",
      "Epoch 346/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7991 - mean_euclidean_error: 0.5095 - val_loss: 0.8913 - val_mean_euclidean_error: 0.6276\n",
      "Epoch 347/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7950 - mean_euclidean_error: 0.4999 - val_loss: 0.9003 - val_mean_euclidean_error: 0.6617\n",
      "Epoch 348/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7891 - mean_euclidean_error: 0.4862 - val_loss: 0.8815 - val_mean_euclidean_error: 0.6300\n",
      "Epoch 349/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7904 - mean_euclidean_error: 0.4886 - val_loss: 0.8978 - val_mean_euclidean_error: 0.6627\n",
      "Epoch 350/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7851 - mean_euclidean_error: 0.4736 - val_loss: 0.8934 - val_mean_euclidean_error: 0.6263\n",
      "Epoch 351/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7830 - mean_euclidean_error: 0.4649 - val_loss: 0.8995 - val_mean_euclidean_error: 0.6592\n",
      "Epoch 352/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7943 - mean_euclidean_error: 0.4974 - val_loss: 0.8944 - val_mean_euclidean_error: 0.6864\n",
      "Epoch 353/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7854 - mean_euclidean_error: 0.4798 - val_loss: 0.8951 - val_mean_euclidean_error: 0.6711\n",
      "Epoch 354/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7899 - mean_euclidean_error: 0.4852 - val_loss: 0.9090 - val_mean_euclidean_error: 0.6509\n",
      "Epoch 355/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7876 - mean_euclidean_error: 0.4828 - val_loss: 0.8949 - val_mean_euclidean_error: 0.6960\n",
      "Epoch 356/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7923 - mean_euclidean_error: 0.4949 - val_loss: 0.8846 - val_mean_euclidean_error: 0.6256\n",
      "Epoch 357/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7853 - mean_euclidean_error: 0.4682 - val_loss: 0.8813 - val_mean_euclidean_error: 0.6234\n",
      "Epoch 358/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7884 - mean_euclidean_error: 0.4863 - val_loss: 0.8902 - val_mean_euclidean_error: 0.6362\n",
      "Epoch 359/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7863 - mean_euclidean_error: 0.4779 - val_loss: 0.8729 - val_mean_euclidean_error: 0.5864\n",
      "Epoch 360/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7767 - mean_euclidean_error: 0.4556 - val_loss: 0.8756 - val_mean_euclidean_error: 0.6128\n",
      "Epoch 361/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7801 - mean_euclidean_error: 0.4609 - val_loss: 0.8777 - val_mean_euclidean_error: 0.6025\n",
      "Epoch 362/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7789 - mean_euclidean_error: 0.4601 - val_loss: 0.8813 - val_mean_euclidean_error: 0.6242\n",
      "Epoch 363/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7807 - mean_euclidean_error: 0.4789 - val_loss: 0.8815 - val_mean_euclidean_error: 0.6293\n",
      "Epoch 364/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7811 - mean_euclidean_error: 0.4659 - val_loss: 0.8845 - val_mean_euclidean_error: 0.6209\n",
      "Epoch 365/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7816 - mean_euclidean_error: 0.4724 - val_loss: 0.8765 - val_mean_euclidean_error: 0.6031\n",
      "Epoch 366/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7808 - mean_euclidean_error: 0.4637 - val_loss: 0.8937 - val_mean_euclidean_error: 0.6521\n",
      "Epoch 367/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7786 - mean_euclidean_error: 0.4560 - val_loss: 0.8788 - val_mean_euclidean_error: 0.6127\n",
      "Epoch 368/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7782 - mean_euclidean_error: 0.4565 - val_loss: 0.8826 - val_mean_euclidean_error: 0.6462\n",
      "Epoch 369/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7763 - mean_euclidean_error: 0.4683 - val_loss: 0.8781 - val_mean_euclidean_error: 0.6335\n",
      "Epoch 370/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7783 - mean_euclidean_error: 0.4735 - val_loss: 0.8783 - val_mean_euclidean_error: 0.6356\n",
      "Epoch 371/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7826 - mean_euclidean_error: 0.4771 - val_loss: 0.8866 - val_mean_euclidean_error: 0.6223\n",
      "Epoch 372/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7806 - mean_euclidean_error: 0.4664 - val_loss: 0.8736 - val_mean_euclidean_error: 0.6234\n",
      "Epoch 373/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7784 - mean_euclidean_error: 0.4670 - val_loss: 0.8728 - val_mean_euclidean_error: 0.6287\n",
      "Epoch 374/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7783 - mean_euclidean_error: 0.4605 - val_loss: 0.8751 - val_mean_euclidean_error: 0.6285\n",
      "Epoch 375/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7830 - mean_euclidean_error: 0.4768 - val_loss: 0.8832 - val_mean_euclidean_error: 0.6280\n",
      "Epoch 376/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7879 - mean_euclidean_error: 0.4955 - val_loss: 0.8812 - val_mean_euclidean_error: 0.6502\n",
      "Epoch 377/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7900 - mean_euclidean_error: 0.5176 - val_loss: 0.8911 - val_mean_euclidean_error: 0.6369\n",
      "Epoch 378/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7786 - mean_euclidean_error: 0.4823 - val_loss: 0.8760 - val_mean_euclidean_error: 0.6170\n",
      "Epoch 379/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7810 - mean_euclidean_error: 0.4763 - val_loss: 0.8833 - val_mean_euclidean_error: 0.6276\n",
      "Epoch 380/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7903 - mean_euclidean_error: 0.5042 - val_loss: 0.8804 - val_mean_euclidean_error: 0.6583\n",
      "Epoch 381/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7858 - mean_euclidean_error: 0.4863 - val_loss: 0.8907 - val_mean_euclidean_error: 0.6385\n",
      "Epoch 382/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7821 - mean_euclidean_error: 0.4772 - val_loss: 0.8844 - val_mean_euclidean_error: 0.6421\n",
      "Epoch 383/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7777 - mean_euclidean_error: 0.4626 - val_loss: 0.8921 - val_mean_euclidean_error: 0.6724\n",
      "Epoch 384/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7763 - mean_euclidean_error: 0.4686 - val_loss: 0.8828 - val_mean_euclidean_error: 0.6192\n",
      "Epoch 385/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7705 - mean_euclidean_error: 0.4436 - val_loss: 0.8679 - val_mean_euclidean_error: 0.6087\n",
      "Epoch 386/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7697 - mean_euclidean_error: 0.4468 - val_loss: 0.8791 - val_mean_euclidean_error: 0.6342\n",
      "Epoch 387/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7812 - mean_euclidean_error: 0.4828 - val_loss: 0.8891 - val_mean_euclidean_error: 0.6759\n",
      "Epoch 388/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7915 - mean_euclidean_error: 0.5014 - val_loss: 0.8903 - val_mean_euclidean_error: 0.6688\n",
      "Epoch 389/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7785 - mean_euclidean_error: 0.4738 - val_loss: 0.8826 - val_mean_euclidean_error: 0.6305\n",
      "Epoch 390/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7782 - mean_euclidean_error: 0.4616 - val_loss: 0.8784 - val_mean_euclidean_error: 0.6333\n",
      "Epoch 391/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7798 - mean_euclidean_error: 0.4694 - val_loss: 0.8819 - val_mean_euclidean_error: 0.6397\n",
      "Epoch 392/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7722 - mean_euclidean_error: 0.4565 - val_loss: 0.8770 - val_mean_euclidean_error: 0.6278\n",
      "Epoch 393/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7757 - mean_euclidean_error: 0.4722 - val_loss: 0.8761 - val_mean_euclidean_error: 0.6332\n",
      "Epoch 394/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7843 - mean_euclidean_error: 0.4858 - val_loss: 0.8692 - val_mean_euclidean_error: 0.6140\n",
      "Epoch 395/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7810 - mean_euclidean_error: 0.4777 - val_loss: 0.8923 - val_mean_euclidean_error: 0.6595\n",
      "Epoch 396/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7885 - mean_euclidean_error: 0.4995 - val_loss: 0.8878 - val_mean_euclidean_error: 0.6387\n",
      "Epoch 397/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7806 - mean_euclidean_error: 0.4843 - val_loss: 0.8716 - val_mean_euclidean_error: 0.6413\n",
      "Epoch 398/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7752 - mean_euclidean_error: 0.4620 - val_loss: 0.8726 - val_mean_euclidean_error: 0.6105\n",
      "Epoch 399/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7773 - mean_euclidean_error: 0.4837 - val_loss: 0.8889 - val_mean_euclidean_error: 0.6521\n",
      "Epoch 400/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7861 - mean_euclidean_error: 0.4941 - val_loss: 0.8739 - val_mean_euclidean_error: 0.6049\n",
      "Epoch 401/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7772 - mean_euclidean_error: 0.4767 - val_loss: 0.8846 - val_mean_euclidean_error: 0.6682\n",
      "Epoch 402/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7729 - mean_euclidean_error: 0.4627 - val_loss: 0.8664 - val_mean_euclidean_error: 0.6003\n",
      "Epoch 403/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7783 - mean_euclidean_error: 0.4766 - val_loss: 0.8869 - val_mean_euclidean_error: 0.6601\n",
      "Epoch 404/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7687 - mean_euclidean_error: 0.4466 - val_loss: 0.8750 - val_mean_euclidean_error: 0.6044\n",
      "Epoch 405/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7699 - mean_euclidean_error: 0.4549 - val_loss: 0.8811 - val_mean_euclidean_error: 0.6409\n",
      "Epoch 406/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7696 - mean_euclidean_error: 0.4729 - val_loss: 0.8929 - val_mean_euclidean_error: 0.6489\n",
      "Epoch 407/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7687 - mean_euclidean_error: 0.4651 - val_loss: 0.8790 - val_mean_euclidean_error: 0.6514\n",
      "Epoch 408/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7867 - mean_euclidean_error: 0.4955 - val_loss: 0.8969 - val_mean_euclidean_error: 0.6355\n",
      "Epoch 409/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7927 - mean_euclidean_error: 0.5157 - val_loss: 0.8751 - val_mean_euclidean_error: 0.6235\n",
      "Epoch 410/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7886 - mean_euclidean_error: 0.4894 - val_loss: 0.8840 - val_mean_euclidean_error: 0.6673\n",
      "Epoch 411/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7814 - mean_euclidean_error: 0.4812 - val_loss: 0.8885 - val_mean_euclidean_error: 0.6234\n",
      "Epoch 412/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7781 - mean_euclidean_error: 0.4913 - val_loss: 0.8746 - val_mean_euclidean_error: 0.6358\n",
      "Epoch 413/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7713 - mean_euclidean_error: 0.4566 - val_loss: 0.8818 - val_mean_euclidean_error: 0.6319\n",
      "Epoch 414/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7837 - mean_euclidean_error: 0.4894 - val_loss: 0.9073 - val_mean_euclidean_error: 0.6879\n",
      "Epoch 415/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7841 - mean_euclidean_error: 0.4924 - val_loss: 0.8655 - val_mean_euclidean_error: 0.5838\n",
      "Epoch 416/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7722 - mean_euclidean_error: 0.4616 - val_loss: 0.8728 - val_mean_euclidean_error: 0.6544\n",
      "Epoch 417/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7792 - mean_euclidean_error: 0.4860 - val_loss: 0.8884 - val_mean_euclidean_error: 0.6197\n",
      "Epoch 418/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7760 - mean_euclidean_error: 0.4781 - val_loss: 0.8812 - val_mean_euclidean_error: 0.6685\n",
      "Epoch 419/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7759 - mean_euclidean_error: 0.4810 - val_loss: 0.8710 - val_mean_euclidean_error: 0.6263\n",
      "Epoch 420/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7714 - mean_euclidean_error: 0.4761 - val_loss: 0.8603 - val_mean_euclidean_error: 0.6177\n",
      "Epoch 421/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7666 - mean_euclidean_error: 0.4524 - val_loss: 0.8828 - val_mean_euclidean_error: 0.6543\n",
      "Epoch 422/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7712 - mean_euclidean_error: 0.4657 - val_loss: 0.8635 - val_mean_euclidean_error: 0.6014\n",
      "Epoch 423/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7710 - mean_euclidean_error: 0.4554 - val_loss: 0.8665 - val_mean_euclidean_error: 0.6342\n",
      "Epoch 424/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.7698 - mean_euclidean_error: 0.4533 - val_loss: 0.8722 - val_mean_euclidean_error: 0.6422\n",
      "Epoch 425/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7681 - mean_euclidean_error: 0.4605 - val_loss: 0.8860 - val_mean_euclidean_error: 0.6490\n",
      "Epoch 426/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7739 - mean_euclidean_error: 0.4834 - val_loss: 0.8668 - val_mean_euclidean_error: 0.6179\n",
      "Epoch 427/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7688 - mean_euclidean_error: 0.4606 - val_loss: 0.8630 - val_mean_euclidean_error: 0.6067\n",
      "Epoch 428/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7702 - mean_euclidean_error: 0.4593 - val_loss: 0.8708 - val_mean_euclidean_error: 0.6235\n",
      "Epoch 429/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7632 - mean_euclidean_error: 0.4425 - val_loss: 0.8652 - val_mean_euclidean_error: 0.5928\n",
      "Epoch 430/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7680 - mean_euclidean_error: 0.4622 - val_loss: 0.8747 - val_mean_euclidean_error: 0.6818\n",
      "Epoch 431/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7687 - mean_euclidean_error: 0.4586 - val_loss: 0.8679 - val_mean_euclidean_error: 0.6089\n",
      "Epoch 432/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7648 - mean_euclidean_error: 0.4493 - val_loss: 0.8687 - val_mean_euclidean_error: 0.6179\n",
      "Epoch 433/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7653 - mean_euclidean_error: 0.4630 - val_loss: 0.8690 - val_mean_euclidean_error: 0.6162\n",
      "Epoch 434/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7702 - mean_euclidean_error: 0.4684 - val_loss: 0.8700 - val_mean_euclidean_error: 0.6164\n",
      "Epoch 435/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7682 - mean_euclidean_error: 0.4512 - val_loss: 0.8700 - val_mean_euclidean_error: 0.6034\n",
      "Epoch 436/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7631 - mean_euclidean_error: 0.4425 - val_loss: 0.8724 - val_mean_euclidean_error: 0.6195\n",
      "Epoch 437/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7678 - mean_euclidean_error: 0.4590 - val_loss: 0.8651 - val_mean_euclidean_error: 0.6289\n",
      "Epoch 438/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7650 - mean_euclidean_error: 0.4482 - val_loss: 0.8663 - val_mean_euclidean_error: 0.6139\n",
      "Epoch 439/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7588 - mean_euclidean_error: 0.4338 - val_loss: 0.8732 - val_mean_euclidean_error: 0.6195\n",
      "Epoch 440/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7609 - mean_euclidean_error: 0.4380 - val_loss: 0.8630 - val_mean_euclidean_error: 0.5965\n",
      "Epoch 441/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7587 - mean_euclidean_error: 0.4432 - val_loss: 0.8793 - val_mean_euclidean_error: 0.6269\n",
      "Epoch 442/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7643 - mean_euclidean_error: 0.4537 - val_loss: 0.8683 - val_mean_euclidean_error: 0.6128\n",
      "Epoch 443/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7673 - mean_euclidean_error: 0.4647 - val_loss: 0.8710 - val_mean_euclidean_error: 0.6357\n",
      "Epoch 444/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7644 - mean_euclidean_error: 0.4594 - val_loss: 0.8716 - val_mean_euclidean_error: 0.6091\n",
      "Epoch 445/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7705 - mean_euclidean_error: 0.4686 - val_loss: 0.8748 - val_mean_euclidean_error: 0.6383\n",
      "Epoch 446/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7653 - mean_euclidean_error: 0.4522 - val_loss: 0.8707 - val_mean_euclidean_error: 0.6027\n",
      "Epoch 447/1500\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.7609 - mean_euclidean_error: 0.4422 - val_loss: 0.8615 - val_mean_euclidean_error: 0.5897\n",
      "Epoch 448/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7595 - mean_euclidean_error: 0.4410 - val_loss: 0.8562 - val_mean_euclidean_error: 0.5959\n",
      "Epoch 449/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7653 - mean_euclidean_error: 0.4554 - val_loss: 0.8570 - val_mean_euclidean_error: 0.6034\n",
      "Epoch 450/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7704 - mean_euclidean_error: 0.4774 - val_loss: 0.8664 - val_mean_euclidean_error: 0.6065\n",
      "Epoch 451/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7609 - mean_euclidean_error: 0.4525 - val_loss: 0.8526 - val_mean_euclidean_error: 0.5918\n",
      "Epoch 452/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7572 - mean_euclidean_error: 0.4264 - val_loss: 0.8660 - val_mean_euclidean_error: 0.5871\n",
      "Epoch 453/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7559 - mean_euclidean_error: 0.4291 - val_loss: 0.8545 - val_mean_euclidean_error: 0.5967\n",
      "Epoch 454/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7619 - mean_euclidean_error: 0.4485 - val_loss: 0.8670 - val_mean_euclidean_error: 0.6134\n",
      "Epoch 455/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7621 - mean_euclidean_error: 0.4456 - val_loss: 0.8594 - val_mean_euclidean_error: 0.5950\n",
      "Epoch 456/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7663 - mean_euclidean_error: 0.4581 - val_loss: 0.8564 - val_mean_euclidean_error: 0.5991\n",
      "Epoch 457/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7646 - mean_euclidean_error: 0.4592 - val_loss: 0.8661 - val_mean_euclidean_error: 0.6036\n",
      "Epoch 458/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7638 - mean_euclidean_error: 0.4638 - val_loss: 0.8545 - val_mean_euclidean_error: 0.5809\n",
      "Epoch 459/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7714 - mean_euclidean_error: 0.4640 - val_loss: 0.8825 - val_mean_euclidean_error: 0.6252\n",
      "Epoch 460/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7612 - mean_euclidean_error: 0.4441 - val_loss: 0.8645 - val_mean_euclidean_error: 0.6079\n",
      "Epoch 461/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7580 - mean_euclidean_error: 0.4386 - val_loss: 0.8572 - val_mean_euclidean_error: 0.6036\n",
      "Epoch 462/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7605 - mean_euclidean_error: 0.4510 - val_loss: 0.8627 - val_mean_euclidean_error: 0.5972\n",
      "Epoch 463/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7562 - mean_euclidean_error: 0.4456 - val_loss: 0.8597 - val_mean_euclidean_error: 0.5990\n",
      "Epoch 464/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7635 - mean_euclidean_error: 0.4740 - val_loss: 0.8596 - val_mean_euclidean_error: 0.6000\n",
      "Epoch 465/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7596 - mean_euclidean_error: 0.4464 - val_loss: 0.8623 - val_mean_euclidean_error: 0.5961\n",
      "Epoch 466/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7600 - mean_euclidean_error: 0.4474 - val_loss: 0.8547 - val_mean_euclidean_error: 0.5946\n",
      "Epoch 467/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7715 - mean_euclidean_error: 0.4807 - val_loss: 0.8569 - val_mean_euclidean_error: 0.5985\n",
      "Epoch 468/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7598 - mean_euclidean_error: 0.4466 - val_loss: 0.8654 - val_mean_euclidean_error: 0.6053\n",
      "Epoch 469/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7580 - mean_euclidean_error: 0.4446 - val_loss: 0.8678 - val_mean_euclidean_error: 0.5991\n",
      "Epoch 470/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7591 - mean_euclidean_error: 0.4427 - val_loss: 0.8612 - val_mean_euclidean_error: 0.6417\n",
      "Epoch 471/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7575 - mean_euclidean_error: 0.4440 - val_loss: 0.8578 - val_mean_euclidean_error: 0.5866\n",
      "Epoch 472/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7599 - mean_euclidean_error: 0.4493 - val_loss: 0.8651 - val_mean_euclidean_error: 0.6393\n",
      "Epoch 473/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7632 - mean_euclidean_error: 0.4658 - val_loss: 0.8595 - val_mean_euclidean_error: 0.6076\n",
      "Epoch 474/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7578 - mean_euclidean_error: 0.4427 - val_loss: 0.8667 - val_mean_euclidean_error: 0.6391\n",
      "Epoch 475/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7564 - mean_euclidean_error: 0.4365 - val_loss: 0.8511 - val_mean_euclidean_error: 0.5917\n",
      "Epoch 476/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7651 - mean_euclidean_error: 0.4622 - val_loss: 0.8695 - val_mean_euclidean_error: 0.6460\n",
      "Epoch 477/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7593 - mean_euclidean_error: 0.4471 - val_loss: 0.8553 - val_mean_euclidean_error: 0.6108\n",
      "Epoch 478/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7528 - mean_euclidean_error: 0.4337 - val_loss: 0.8556 - val_mean_euclidean_error: 0.6036\n",
      "Epoch 479/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7552 - mean_euclidean_error: 0.4393 - val_loss: 0.8598 - val_mean_euclidean_error: 0.6131\n",
      "Epoch 480/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7546 - mean_euclidean_error: 0.4409 - val_loss: 0.8531 - val_mean_euclidean_error: 0.6113\n",
      "Epoch 481/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7527 - mean_euclidean_error: 0.4306 - val_loss: 0.8590 - val_mean_euclidean_error: 0.6136\n",
      "Epoch 482/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7510 - mean_euclidean_error: 0.4269 - val_loss: 0.8513 - val_mean_euclidean_error: 0.5797\n",
      "Epoch 483/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7536 - mean_euclidean_error: 0.4371 - val_loss: 0.8512 - val_mean_euclidean_error: 0.5983\n",
      "Epoch 484/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7516 - mean_euclidean_error: 0.4248 - val_loss: 0.8599 - val_mean_euclidean_error: 0.5974\n",
      "Epoch 485/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7564 - mean_euclidean_error: 0.4453 - val_loss: 0.8752 - val_mean_euclidean_error: 0.6681\n",
      "Epoch 486/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7597 - mean_euclidean_error: 0.4485 - val_loss: 0.8514 - val_mean_euclidean_error: 0.5875\n",
      "Epoch 487/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7527 - mean_euclidean_error: 0.4320 - val_loss: 0.8547 - val_mean_euclidean_error: 0.6054\n",
      "Epoch 488/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7510 - mean_euclidean_error: 0.4290 - val_loss: 0.8766 - val_mean_euclidean_error: 0.6165\n",
      "Epoch 489/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7587 - mean_euclidean_error: 0.4484 - val_loss: 0.8783 - val_mean_euclidean_error: 0.6412\n",
      "Epoch 490/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7608 - mean_euclidean_error: 0.4627 - val_loss: 0.8758 - val_mean_euclidean_error: 0.6110\n",
      "Epoch 491/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7583 - mean_euclidean_error: 0.4585 - val_loss: 0.8537 - val_mean_euclidean_error: 0.6049\n",
      "Epoch 492/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7562 - mean_euclidean_error: 0.4468 - val_loss: 0.8493 - val_mean_euclidean_error: 0.5789\n",
      "Epoch 493/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7677 - mean_euclidean_error: 0.4751 - val_loss: 0.8654 - val_mean_euclidean_error: 0.6251\n",
      "Epoch 494/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7701 - mean_euclidean_error: 0.4829 - val_loss: 0.8586 - val_mean_euclidean_error: 0.5876\n",
      "Epoch 495/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7529 - mean_euclidean_error: 0.4340 - val_loss: 0.8555 - val_mean_euclidean_error: 0.6202\n",
      "Epoch 496/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7512 - mean_euclidean_error: 0.4322 - val_loss: 0.8586 - val_mean_euclidean_error: 0.6061\n",
      "Epoch 497/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7507 - mean_euclidean_error: 0.4317 - val_loss: 0.8696 - val_mean_euclidean_error: 0.6329\n",
      "Epoch 498/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7532 - mean_euclidean_error: 0.4335 - val_loss: 0.8579 - val_mean_euclidean_error: 0.6081\n",
      "Epoch 499/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7521 - mean_euclidean_error: 0.4400 - val_loss: 0.8579 - val_mean_euclidean_error: 0.6220\n",
      "Epoch 500/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7609 - mean_euclidean_error: 0.4566 - val_loss: 0.8493 - val_mean_euclidean_error: 0.5986\n",
      "Epoch 501/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7563 - mean_euclidean_error: 0.4693 - val_loss: 0.8652 - val_mean_euclidean_error: 0.6209\n",
      "Epoch 502/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7551 - mean_euclidean_error: 0.4473 - val_loss: 0.8786 - val_mean_euclidean_error: 0.6409\n",
      "Epoch 503/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7599 - mean_euclidean_error: 0.4635 - val_loss: 0.8514 - val_mean_euclidean_error: 0.6089\n",
      "Epoch 504/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7502 - mean_euclidean_error: 0.4321 - val_loss: 0.8644 - val_mean_euclidean_error: 0.5914\n",
      "Epoch 505/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7553 - mean_euclidean_error: 0.4498 - val_loss: 0.8549 - val_mean_euclidean_error: 0.6034\n",
      "Epoch 506/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7475 - mean_euclidean_error: 0.4283 - val_loss: 0.8620 - val_mean_euclidean_error: 0.6311\n",
      "Epoch 507/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7459 - mean_euclidean_error: 0.4193 - val_loss: 0.8593 - val_mean_euclidean_error: 0.6342\n",
      "Epoch 508/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7506 - mean_euclidean_error: 0.4350 - val_loss: 0.8502 - val_mean_euclidean_error: 0.5727\n",
      "Epoch 509/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7469 - mean_euclidean_error: 0.4282 - val_loss: 0.8384 - val_mean_euclidean_error: 0.5738\n",
      "Epoch 510/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7490 - mean_euclidean_error: 0.4262 - val_loss: 0.8485 - val_mean_euclidean_error: 0.5895\n",
      "Epoch 511/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7462 - mean_euclidean_error: 0.4264 - val_loss: 0.8390 - val_mean_euclidean_error: 0.5911\n",
      "Epoch 512/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7474 - mean_euclidean_error: 0.4225 - val_loss: 0.8467 - val_mean_euclidean_error: 0.5680\n",
      "Epoch 513/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7498 - mean_euclidean_error: 0.4384 - val_loss: 0.8645 - val_mean_euclidean_error: 0.6084\n",
      "Epoch 514/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7479 - mean_euclidean_error: 0.4299 - val_loss: 0.8484 - val_mean_euclidean_error: 0.5755\n",
      "Epoch 515/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7467 - mean_euclidean_error: 0.4295 - val_loss: 0.8451 - val_mean_euclidean_error: 0.5814\n",
      "Epoch 516/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7425 - mean_euclidean_error: 0.4144 - val_loss: 0.8483 - val_mean_euclidean_error: 0.5985\n",
      "Epoch 517/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7447 - mean_euclidean_error: 0.4240 - val_loss: 0.8485 - val_mean_euclidean_error: 0.5779\n",
      "Epoch 518/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7444 - mean_euclidean_error: 0.4269 - val_loss: 0.8483 - val_mean_euclidean_error: 0.5939\n",
      "Epoch 519/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7516 - mean_euclidean_error: 0.4451 - val_loss: 0.8515 - val_mean_euclidean_error: 0.6338\n",
      "Epoch 520/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7512 - mean_euclidean_error: 0.4477 - val_loss: 0.8463 - val_mean_euclidean_error: 0.6036\n",
      "Epoch 521/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7513 - mean_euclidean_error: 0.4455 - val_loss: 0.8616 - val_mean_euclidean_error: 0.6299\n",
      "Epoch 522/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7561 - mean_euclidean_error: 0.4607 - val_loss: 0.8549 - val_mean_euclidean_error: 0.6033\n",
      "Epoch 523/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7466 - mean_euclidean_error: 0.4302 - val_loss: 0.8465 - val_mean_euclidean_error: 0.5845\n",
      "Epoch 524/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7483 - mean_euclidean_error: 0.4380 - val_loss: 0.8419 - val_mean_euclidean_error: 0.5959\n",
      "Epoch 525/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7487 - mean_euclidean_error: 0.4374 - val_loss: 0.8357 - val_mean_euclidean_error: 0.5873\n",
      "Epoch 526/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7576 - mean_euclidean_error: 0.4587 - val_loss: 0.8433 - val_mean_euclidean_error: 0.5989\n",
      "Epoch 527/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7508 - mean_euclidean_error: 0.4375 - val_loss: 0.8561 - val_mean_euclidean_error: 0.6527\n",
      "Epoch 528/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7522 - mean_euclidean_error: 0.4509 - val_loss: 0.8440 - val_mean_euclidean_error: 0.5635\n",
      "Epoch 529/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7474 - mean_euclidean_error: 0.4326 - val_loss: 0.8438 - val_mean_euclidean_error: 0.5893\n",
      "Epoch 530/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7469 - mean_euclidean_error: 0.4466 - val_loss: 0.8717 - val_mean_euclidean_error: 0.6513\n",
      "Epoch 531/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7590 - mean_euclidean_error: 0.4874 - val_loss: 0.8531 - val_mean_euclidean_error: 0.6273\n",
      "Epoch 532/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7490 - mean_euclidean_error: 0.4469 - val_loss: 0.8480 - val_mean_euclidean_error: 0.6047\n",
      "Epoch 533/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7514 - mean_euclidean_error: 0.4528 - val_loss: 0.8625 - val_mean_euclidean_error: 0.6297\n",
      "Epoch 534/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7519 - mean_euclidean_error: 0.4498 - val_loss: 0.8594 - val_mean_euclidean_error: 0.6312\n",
      "Epoch 535/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7461 - mean_euclidean_error: 0.4275 - val_loss: 0.8429 - val_mean_euclidean_error: 0.5806\n",
      "Epoch 536/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7443 - mean_euclidean_error: 0.4231 - val_loss: 0.8551 - val_mean_euclidean_error: 0.6060\n",
      "Epoch 537/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7424 - mean_euclidean_error: 0.4206 - val_loss: 0.8477 - val_mean_euclidean_error: 0.5829\n",
      "Epoch 538/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7449 - mean_euclidean_error: 0.4257 - val_loss: 0.8373 - val_mean_euclidean_error: 0.5873\n",
      "Epoch 539/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7428 - mean_euclidean_error: 0.4238 - val_loss: 0.8378 - val_mean_euclidean_error: 0.5647\n",
      "Epoch 540/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7414 - mean_euclidean_error: 0.4181 - val_loss: 0.8389 - val_mean_euclidean_error: 0.5748\n",
      "Epoch 541/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7388 - mean_euclidean_error: 0.4075 - val_loss: 0.8319 - val_mean_euclidean_error: 0.5587\n",
      "Epoch 542/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7372 - mean_euclidean_error: 0.4063 - val_loss: 0.8373 - val_mean_euclidean_error: 0.5842\n",
      "Epoch 543/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7456 - mean_euclidean_error: 0.4299 - val_loss: 0.8483 - val_mean_euclidean_error: 0.6115\n",
      "Epoch 544/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7416 - mean_euclidean_error: 0.4179 - val_loss: 0.8418 - val_mean_euclidean_error: 0.6000\n",
      "Epoch 545/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7407 - mean_euclidean_error: 0.4197 - val_loss: 0.8529 - val_mean_euclidean_error: 0.5986\n",
      "Epoch 546/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7452 - mean_euclidean_error: 0.4306 - val_loss: 0.8438 - val_mean_euclidean_error: 0.5964\n",
      "Epoch 547/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7402 - mean_euclidean_error: 0.4177 - val_loss: 0.8321 - val_mean_euclidean_error: 0.5707\n",
      "Epoch 548/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7406 - mean_euclidean_error: 0.4151 - val_loss: 0.8474 - val_mean_euclidean_error: 0.5860\n",
      "Epoch 549/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7409 - mean_euclidean_error: 0.4272 - val_loss: 0.8403 - val_mean_euclidean_error: 0.5759\n",
      "Epoch 550/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7535 - mean_euclidean_error: 0.4542 - val_loss: 0.8633 - val_mean_euclidean_error: 0.6124\n",
      "Epoch 551/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7565 - mean_euclidean_error: 0.4713 - val_loss: 0.8548 - val_mean_euclidean_error: 0.5971\n",
      "Epoch 552/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7426 - mean_euclidean_error: 0.4350 - val_loss: 0.8383 - val_mean_euclidean_error: 0.5821\n",
      "Epoch 553/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7434 - mean_euclidean_error: 0.4323 - val_loss: 0.8471 - val_mean_euclidean_error: 0.6039\n",
      "Epoch 554/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7537 - mean_euclidean_error: 0.4733 - val_loss: 0.8399 - val_mean_euclidean_error: 0.5826\n",
      "Epoch 555/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7471 - mean_euclidean_error: 0.4380 - val_loss: 0.8422 - val_mean_euclidean_error: 0.5852\n",
      "Epoch 556/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7420 - mean_euclidean_error: 0.4229 - val_loss: 0.8418 - val_mean_euclidean_error: 0.5804\n",
      "Epoch 557/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7482 - mean_euclidean_error: 0.4407 - val_loss: 0.8429 - val_mean_euclidean_error: 0.5834\n",
      "Epoch 558/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7440 - mean_euclidean_error: 0.4357 - val_loss: 0.8353 - val_mean_euclidean_error: 0.5632\n",
      "Epoch 559/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7424 - mean_euclidean_error: 0.4356 - val_loss: 0.8506 - val_mean_euclidean_error: 0.5986\n",
      "Epoch 560/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7480 - mean_euclidean_error: 0.4594 - val_loss: 0.8559 - val_mean_euclidean_error: 0.6076\n",
      "Epoch 561/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7463 - mean_euclidean_error: 0.4473 - val_loss: 0.8430 - val_mean_euclidean_error: 0.6074\n",
      "Epoch 562/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7466 - mean_euclidean_error: 0.4412 - val_loss: 0.8342 - val_mean_euclidean_error: 0.5764\n",
      "Epoch 563/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7373 - mean_euclidean_error: 0.4185 - val_loss: 0.8391 - val_mean_euclidean_error: 0.5934\n",
      "Epoch 564/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7370 - mean_euclidean_error: 0.4136 - val_loss: 0.8406 - val_mean_euclidean_error: 0.5912\n",
      "Epoch 565/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7366 - mean_euclidean_error: 0.4187 - val_loss: 0.8360 - val_mean_euclidean_error: 0.5701\n",
      "Epoch 566/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7380 - mean_euclidean_error: 0.4262 - val_loss: 0.8390 - val_mean_euclidean_error: 0.5727\n",
      "Epoch 567/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7395 - mean_euclidean_error: 0.4269 - val_loss: 0.8583 - val_mean_euclidean_error: 0.6376\n",
      "Epoch 568/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7428 - mean_euclidean_error: 0.4350 - val_loss: 0.8424 - val_mean_euclidean_error: 0.5876\n",
      "Epoch 569/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7468 - mean_euclidean_error: 0.4446 - val_loss: 0.8482 - val_mean_euclidean_error: 0.6141\n",
      "Epoch 570/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7432 - mean_euclidean_error: 0.4323 - val_loss: 0.8365 - val_mean_euclidean_error: 0.5637\n",
      "Epoch 571/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7442 - mean_euclidean_error: 0.4419 - val_loss: 0.8486 - val_mean_euclidean_error: 0.6229\n",
      "Epoch 572/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7528 - mean_euclidean_error: 0.4551 - val_loss: 0.8489 - val_mean_euclidean_error: 0.6059\n",
      "Epoch 573/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7448 - mean_euclidean_error: 0.4423 - val_loss: 0.8418 - val_mean_euclidean_error: 0.6176\n",
      "Epoch 574/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7417 - mean_euclidean_error: 0.4372 - val_loss: 0.8337 - val_mean_euclidean_error: 0.5671\n",
      "Epoch 575/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7368 - mean_euclidean_error: 0.4188 - val_loss: 0.8429 - val_mean_euclidean_error: 0.6017\n",
      "Epoch 576/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7377 - mean_euclidean_error: 0.4246 - val_loss: 0.8323 - val_mean_euclidean_error: 0.5880\n",
      "Epoch 577/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7368 - mean_euclidean_error: 0.4220 - val_loss: 0.8421 - val_mean_euclidean_error: 0.5816\n",
      "Epoch 578/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7453 - mean_euclidean_error: 0.4454 - val_loss: 0.8284 - val_mean_euclidean_error: 0.5772\n",
      "Epoch 579/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7373 - mean_euclidean_error: 0.4194 - val_loss: 0.8433 - val_mean_euclidean_error: 0.6192\n",
      "Epoch 580/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7521 - mean_euclidean_error: 0.4555 - val_loss: 0.8431 - val_mean_euclidean_error: 0.5998\n",
      "Epoch 581/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7482 - mean_euclidean_error: 0.4485 - val_loss: 0.8324 - val_mean_euclidean_error: 0.5723\n",
      "Epoch 582/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7445 - mean_euclidean_error: 0.4409 - val_loss: 0.8475 - val_mean_euclidean_error: 0.6234\n",
      "Epoch 583/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7474 - mean_euclidean_error: 0.4526 - val_loss: 0.8467 - val_mean_euclidean_error: 0.5860\n",
      "Epoch 584/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7571 - mean_euclidean_error: 0.4783 - val_loss: 0.8355 - val_mean_euclidean_error: 0.5981\n",
      "Epoch 585/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7482 - mean_euclidean_error: 0.4591 - val_loss: 0.8391 - val_mean_euclidean_error: 0.5964\n",
      "Epoch 586/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7405 - mean_euclidean_error: 0.4316 - val_loss: 0.8316 - val_mean_euclidean_error: 0.5776\n",
      "Epoch 587/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7393 - mean_euclidean_error: 0.4309 - val_loss: 0.8299 - val_mean_euclidean_error: 0.5928\n",
      "Epoch 588/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.7341 - mean_euclidean_error: 0.4177 - val_loss: 0.8542 - val_mean_euclidean_error: 0.5808\n",
      "Epoch 589/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7480 - mean_euclidean_error: 0.4495 - val_loss: 0.8742 - val_mean_euclidean_error: 0.6958\n",
      "Epoch 590/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7428 - mean_euclidean_error: 0.4482 - val_loss: 0.8473 - val_mean_euclidean_error: 0.5611\n",
      "Epoch 591/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7367 - mean_euclidean_error: 0.4273 - val_loss: 0.8402 - val_mean_euclidean_error: 0.6195\n",
      "Epoch 592/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7352 - mean_euclidean_error: 0.4178 - val_loss: 0.8320 - val_mean_euclidean_error: 0.5831\n",
      "Epoch 593/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7321 - mean_euclidean_error: 0.4116 - val_loss: 0.8260 - val_mean_euclidean_error: 0.5626\n",
      "Epoch 594/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7349 - mean_euclidean_error: 0.4193 - val_loss: 0.8267 - val_mean_euclidean_error: 0.5697\n",
      "Epoch 595/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7396 - mean_euclidean_error: 0.4264 - val_loss: 0.8379 - val_mean_euclidean_error: 0.5771\n",
      "Epoch 596/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7312 - mean_euclidean_error: 0.4072 - val_loss: 0.8316 - val_mean_euclidean_error: 0.5828\n",
      "Epoch 597/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7326 - mean_euclidean_error: 0.4145 - val_loss: 0.8347 - val_mean_euclidean_error: 0.5831\n",
      "Epoch 598/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7311 - mean_euclidean_error: 0.4082 - val_loss: 0.8368 - val_mean_euclidean_error: 0.5801\n",
      "Epoch 599/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7294 - mean_euclidean_error: 0.4194 - val_loss: 0.8275 - val_mean_euclidean_error: 0.5621\n",
      "Epoch 600/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7342 - mean_euclidean_error: 0.4237 - val_loss: 0.8313 - val_mean_euclidean_error: 0.5565\n",
      "Epoch 601/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7334 - mean_euclidean_error: 0.4193 - val_loss: 0.8355 - val_mean_euclidean_error: 0.5867\n",
      "Epoch 602/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7324 - mean_euclidean_error: 0.4156 - val_loss: 0.8440 - val_mean_euclidean_error: 0.5981\n",
      "Epoch 603/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7371 - mean_euclidean_error: 0.4252 - val_loss: 0.8393 - val_mean_euclidean_error: 0.6045\n",
      "Epoch 604/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7327 - mean_euclidean_error: 0.4173 - val_loss: 0.8294 - val_mean_euclidean_error: 0.5872\n",
      "Epoch 605/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7326 - mean_euclidean_error: 0.4240 - val_loss: 0.8318 - val_mean_euclidean_error: 0.5830\n",
      "Epoch 606/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7305 - mean_euclidean_error: 0.4094 - val_loss: 0.8347 - val_mean_euclidean_error: 0.5904\n",
      "Epoch 607/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7321 - mean_euclidean_error: 0.4093 - val_loss: 0.8386 - val_mean_euclidean_error: 0.5925\n",
      "Epoch 608/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7329 - mean_euclidean_error: 0.4183 - val_loss: 0.8260 - val_mean_euclidean_error: 0.5805\n",
      "Epoch 609/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7360 - mean_euclidean_error: 0.4216 - val_loss: 0.8363 - val_mean_euclidean_error: 0.5926\n",
      "Epoch 610/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7310 - mean_euclidean_error: 0.4165 - val_loss: 0.8279 - val_mean_euclidean_error: 0.5724\n",
      "Epoch 611/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7357 - mean_euclidean_error: 0.4336 - val_loss: 0.8497 - val_mean_euclidean_error: 0.6148\n",
      "Epoch 612/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7347 - mean_euclidean_error: 0.4265 - val_loss: 0.8284 - val_mean_euclidean_error: 0.5630\n",
      "Epoch 613/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7357 - mean_euclidean_error: 0.4363 - val_loss: 0.8292 - val_mean_euclidean_error: 0.5843\n",
      "Epoch 614/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7357 - mean_euclidean_error: 0.4326 - val_loss: 0.8358 - val_mean_euclidean_error: 0.5598\n",
      "Epoch 615/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7371 - mean_euclidean_error: 0.4338 - val_loss: 0.8516 - val_mean_euclidean_error: 0.6260\n",
      "Epoch 616/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7392 - mean_euclidean_error: 0.4397 - val_loss: 0.8399 - val_mean_euclidean_error: 0.5825\n",
      "Epoch 617/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7351 - mean_euclidean_error: 0.4307 - val_loss: 0.8288 - val_mean_euclidean_error: 0.5888\n",
      "Epoch 618/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7294 - mean_euclidean_error: 0.4010 - val_loss: 0.8220 - val_mean_euclidean_error: 0.5542\n",
      "Epoch 619/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7278 - mean_euclidean_error: 0.4033 - val_loss: 0.8285 - val_mean_euclidean_error: 0.5708\n",
      "Epoch 620/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7340 - mean_euclidean_error: 0.4269 - val_loss: 0.8337 - val_mean_euclidean_error: 0.5716\n",
      "Epoch 621/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7332 - mean_euclidean_error: 0.4210 - val_loss: 0.8386 - val_mean_euclidean_error: 0.5748\n",
      "Epoch 622/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7303 - mean_euclidean_error: 0.4155 - val_loss: 0.8394 - val_mean_euclidean_error: 0.5894\n",
      "Epoch 623/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7356 - mean_euclidean_error: 0.4284 - val_loss: 0.8219 - val_mean_euclidean_error: 0.5648\n",
      "Epoch 624/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7322 - mean_euclidean_error: 0.4288 - val_loss: 0.8417 - val_mean_euclidean_error: 0.6172\n",
      "Epoch 625/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7397 - mean_euclidean_error: 0.4425 - val_loss: 0.8387 - val_mean_euclidean_error: 0.5697\n",
      "Epoch 626/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7317 - mean_euclidean_error: 0.4205 - val_loss: 0.8252 - val_mean_euclidean_error: 0.5769\n",
      "Epoch 627/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7283 - mean_euclidean_error: 0.4068 - val_loss: 0.8255 - val_mean_euclidean_error: 0.5668\n",
      "Epoch 628/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7254 - mean_euclidean_error: 0.3939 - val_loss: 0.8458 - val_mean_euclidean_error: 0.6069\n",
      "Epoch 629/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7289 - mean_euclidean_error: 0.4120 - val_loss: 0.8227 - val_mean_euclidean_error: 0.5627\n",
      "Epoch 630/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7326 - mean_euclidean_error: 0.4199 - val_loss: 0.8283 - val_mean_euclidean_error: 0.5579\n",
      "Epoch 631/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7299 - mean_euclidean_error: 0.4184 - val_loss: 0.8467 - val_mean_euclidean_error: 0.6199\n",
      "Epoch 632/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7345 - mean_euclidean_error: 0.4272 - val_loss: 0.8329 - val_mean_euclidean_error: 0.5942\n",
      "Epoch 633/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7239 - mean_euclidean_error: 0.3967 - val_loss: 0.8323 - val_mean_euclidean_error: 0.5804\n",
      "Epoch 634/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7264 - mean_euclidean_error: 0.4101 - val_loss: 0.8209 - val_mean_euclidean_error: 0.5872\n",
      "Epoch 635/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7283 - mean_euclidean_error: 0.4154 - val_loss: 0.8193 - val_mean_euclidean_error: 0.5664\n",
      "Epoch 636/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7239 - mean_euclidean_error: 0.4016 - val_loss: 0.8194 - val_mean_euclidean_error: 0.5504\n",
      "Epoch 637/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7229 - mean_euclidean_error: 0.3933 - val_loss: 0.8211 - val_mean_euclidean_error: 0.5671\n",
      "Epoch 638/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7248 - mean_euclidean_error: 0.4027 - val_loss: 0.8243 - val_mean_euclidean_error: 0.5649\n",
      "Epoch 639/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7307 - mean_euclidean_error: 0.4264 - val_loss: 0.8286 - val_mean_euclidean_error: 0.5858\n",
      "Epoch 640/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7292 - mean_euclidean_error: 0.4220 - val_loss: 0.8284 - val_mean_euclidean_error: 0.5812\n",
      "Epoch 641/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7250 - mean_euclidean_error: 0.4063 - val_loss: 0.8215 - val_mean_euclidean_error: 0.5456\n",
      "Epoch 642/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7283 - mean_euclidean_error: 0.4131 - val_loss: 0.8386 - val_mean_euclidean_error: 0.5756\n",
      "Epoch 643/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7262 - mean_euclidean_error: 0.4049 - val_loss: 0.8328 - val_mean_euclidean_error: 0.5703\n",
      "Epoch 644/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7244 - mean_euclidean_error: 0.4052 - val_loss: 0.8273 - val_mean_euclidean_error: 0.5826\n",
      "Epoch 645/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7233 - mean_euclidean_error: 0.3994 - val_loss: 0.8327 - val_mean_euclidean_error: 0.5926\n",
      "Epoch 646/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7250 - mean_euclidean_error: 0.4093 - val_loss: 0.8320 - val_mean_euclidean_error: 0.5743\n",
      "Epoch 647/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7292 - mean_euclidean_error: 0.4197 - val_loss: 0.8473 - val_mean_euclidean_error: 0.6437\n",
      "Epoch 648/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7301 - mean_euclidean_error: 0.4229 - val_loss: 0.8389 - val_mean_euclidean_error: 0.6442\n",
      "Epoch 649/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7279 - mean_euclidean_error: 0.4401 - val_loss: 0.8219 - val_mean_euclidean_error: 0.5662\n",
      "Epoch 650/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7338 - mean_euclidean_error: 0.4284 - val_loss: 0.8293 - val_mean_euclidean_error: 0.5853\n",
      "Epoch 651/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7257 - mean_euclidean_error: 0.4154 - val_loss: 0.8174 - val_mean_euclidean_error: 0.5790\n",
      "Epoch 652/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7236 - mean_euclidean_error: 0.4029 - val_loss: 0.8220 - val_mean_euclidean_error: 0.5678\n",
      "Epoch 653/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7228 - mean_euclidean_error: 0.4025 - val_loss: 0.8189 - val_mean_euclidean_error: 0.5618\n",
      "Epoch 654/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7305 - mean_euclidean_error: 0.4282 - val_loss: 0.8328 - val_mean_euclidean_error: 0.6226\n",
      "Epoch 655/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7243 - mean_euclidean_error: 0.4106 - val_loss: 0.8244 - val_mean_euclidean_error: 0.5840\n",
      "Epoch 656/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7229 - mean_euclidean_error: 0.3990 - val_loss: 0.8242 - val_mean_euclidean_error: 0.5781\n",
      "Epoch 657/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7269 - mean_euclidean_error: 0.4130 - val_loss: 0.8279 - val_mean_euclidean_error: 0.5645\n",
      "Epoch 658/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7284 - mean_euclidean_error: 0.4234 - val_loss: 0.8283 - val_mean_euclidean_error: 0.5794\n",
      "Epoch 659/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7235 - mean_euclidean_error: 0.4060 - val_loss: 0.8369 - val_mean_euclidean_error: 0.6106\n",
      "Epoch 660/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7278 - mean_euclidean_error: 0.4170 - val_loss: 0.8298 - val_mean_euclidean_error: 0.5935\n",
      "Epoch 661/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7256 - mean_euclidean_error: 0.4219 - val_loss: 0.8259 - val_mean_euclidean_error: 0.5701\n",
      "Epoch 662/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7329 - mean_euclidean_error: 0.4346 - val_loss: 0.8256 - val_mean_euclidean_error: 0.5703\n",
      "Epoch 663/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7309 - mean_euclidean_error: 0.4317 - val_loss: 0.8193 - val_mean_euclidean_error: 0.5814\n",
      "Epoch 664/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7223 - mean_euclidean_error: 0.4039 - val_loss: 0.8286 - val_mean_euclidean_error: 0.5920\n",
      "Epoch 665/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7239 - mean_euclidean_error: 0.4127 - val_loss: 0.8188 - val_mean_euclidean_error: 0.5394\n",
      "Epoch 666/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7233 - mean_euclidean_error: 0.4159 - val_loss: 0.8172 - val_mean_euclidean_error: 0.5650\n",
      "Epoch 667/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7213 - mean_euclidean_error: 0.4067 - val_loss: 0.8223 - val_mean_euclidean_error: 0.5787\n",
      "Epoch 668/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7285 - mean_euclidean_error: 0.4237 - val_loss: 0.8353 - val_mean_euclidean_error: 0.6153\n",
      "Epoch 669/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7271 - mean_euclidean_error: 0.4173 - val_loss: 0.8159 - val_mean_euclidean_error: 0.5643\n",
      "Epoch 670/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7216 - mean_euclidean_error: 0.3929 - val_loss: 0.8259 - val_mean_euclidean_error: 0.5582\n",
      "Epoch 671/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7246 - mean_euclidean_error: 0.4141 - val_loss: 0.8176 - val_mean_euclidean_error: 0.5525\n",
      "Epoch 672/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7259 - mean_euclidean_error: 0.4181 - val_loss: 0.8249 - val_mean_euclidean_error: 0.5964\n",
      "Epoch 673/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7309 - mean_euclidean_error: 0.4397 - val_loss: 0.8213 - val_mean_euclidean_error: 0.5713\n",
      "Epoch 674/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7271 - mean_euclidean_error: 0.4167 - val_loss: 0.8379 - val_mean_euclidean_error: 0.5857\n",
      "Epoch 675/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7237 - mean_euclidean_error: 0.4153 - val_loss: 0.8182 - val_mean_euclidean_error: 0.5510\n",
      "Epoch 676/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7240 - mean_euclidean_error: 0.4135 - val_loss: 0.8215 - val_mean_euclidean_error: 0.5853\n",
      "Epoch 677/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7229 - mean_euclidean_error: 0.4152 - val_loss: 0.8277 - val_mean_euclidean_error: 0.5642\n",
      "Epoch 678/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7186 - mean_euclidean_error: 0.3927 - val_loss: 0.8200 - val_mean_euclidean_error: 0.5487\n",
      "Epoch 679/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7190 - mean_euclidean_error: 0.3952 - val_loss: 0.8256 - val_mean_euclidean_error: 0.5756\n",
      "Epoch 680/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7186 - mean_euclidean_error: 0.3981 - val_loss: 0.8122 - val_mean_euclidean_error: 0.5319\n",
      "Epoch 681/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7197 - mean_euclidean_error: 0.4021 - val_loss: 0.8206 - val_mean_euclidean_error: 0.5539\n",
      "Epoch 682/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7217 - mean_euclidean_error: 0.4089 - val_loss: 0.8144 - val_mean_euclidean_error: 0.5588\n",
      "Epoch 683/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7267 - mean_euclidean_error: 0.4236 - val_loss: 0.8379 - val_mean_euclidean_error: 0.5843\n",
      "Epoch 684/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7239 - mean_euclidean_error: 0.4115 - val_loss: 0.8298 - val_mean_euclidean_error: 0.5947\n",
      "Epoch 685/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7250 - mean_euclidean_error: 0.4200 - val_loss: 0.8167 - val_mean_euclidean_error: 0.5442\n",
      "Epoch 686/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7233 - mean_euclidean_error: 0.4128 - val_loss: 0.8234 - val_mean_euclidean_error: 0.5543\n",
      "Epoch 687/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7261 - mean_euclidean_error: 0.4206 - val_loss: 0.8182 - val_mean_euclidean_error: 0.5613\n",
      "Epoch 688/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7224 - mean_euclidean_error: 0.4158 - val_loss: 0.8225 - val_mean_euclidean_error: 0.5522\n",
      "Epoch 689/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7201 - mean_euclidean_error: 0.4019 - val_loss: 0.8231 - val_mean_euclidean_error: 0.5949\n",
      "Epoch 690/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7173 - mean_euclidean_error: 0.3984 - val_loss: 0.8144 - val_mean_euclidean_error: 0.5530\n",
      "Epoch 691/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7197 - mean_euclidean_error: 0.4060 - val_loss: 0.8174 - val_mean_euclidean_error: 0.5756\n",
      "Epoch 692/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7265 - mean_euclidean_error: 0.4261 - val_loss: 0.8202 - val_mean_euclidean_error: 0.5697\n",
      "Epoch 693/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7247 - mean_euclidean_error: 0.4187 - val_loss: 0.8332 - val_mean_euclidean_error: 0.5740\n",
      "Epoch 694/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7285 - mean_euclidean_error: 0.4375 - val_loss: 0.8152 - val_mean_euclidean_error: 0.5592\n",
      "Epoch 695/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7210 - mean_euclidean_error: 0.4132 - val_loss: 0.8217 - val_mean_euclidean_error: 0.5791\n",
      "Epoch 696/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7210 - mean_euclidean_error: 0.4178 - val_loss: 0.8268 - val_mean_euclidean_error: 0.6074\n",
      "Epoch 697/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7217 - mean_euclidean_error: 0.4105 - val_loss: 0.8208 - val_mean_euclidean_error: 0.5983\n",
      "Epoch 698/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7270 - mean_euclidean_error: 0.4305 - val_loss: 0.8299 - val_mean_euclidean_error: 0.6026\n",
      "Epoch 699/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7245 - mean_euclidean_error: 0.4226 - val_loss: 0.8119 - val_mean_euclidean_error: 0.5527\n",
      "Epoch 700/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7194 - mean_euclidean_error: 0.4123 - val_loss: 0.8202 - val_mean_euclidean_error: 0.5759\n",
      "Epoch 701/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7231 - mean_euclidean_error: 0.4245 - val_loss: 0.8139 - val_mean_euclidean_error: 0.5705\n",
      "Epoch 702/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7219 - mean_euclidean_error: 0.4195 - val_loss: 0.8081 - val_mean_euclidean_error: 0.5333\n",
      "Epoch 703/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7202 - mean_euclidean_error: 0.4160 - val_loss: 0.8291 - val_mean_euclidean_error: 0.5913\n",
      "Epoch 704/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7215 - mean_euclidean_error: 0.4193 - val_loss: 0.8162 - val_mean_euclidean_error: 0.5536\n",
      "Epoch 705/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7182 - mean_euclidean_error: 0.4037 - val_loss: 0.8185 - val_mean_euclidean_error: 0.5876\n",
      "Epoch 706/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7154 - mean_euclidean_error: 0.3978 - val_loss: 0.8131 - val_mean_euclidean_error: 0.5544\n",
      "Epoch 707/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7188 - mean_euclidean_error: 0.4075 - val_loss: 0.8227 - val_mean_euclidean_error: 0.5801\n",
      "Epoch 708/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7144 - mean_euclidean_error: 0.3940 - val_loss: 0.8154 - val_mean_euclidean_error: 0.5608\n",
      "Epoch 709/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7155 - mean_euclidean_error: 0.4102 - val_loss: 0.8093 - val_mean_euclidean_error: 0.5419\n",
      "Epoch 710/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7233 - mean_euclidean_error: 0.4335 - val_loss: 0.8213 - val_mean_euclidean_error: 0.5640\n",
      "Epoch 711/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7202 - mean_euclidean_error: 0.4193 - val_loss: 0.8171 - val_mean_euclidean_error: 0.5358\n",
      "Epoch 712/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7183 - mean_euclidean_error: 0.4060 - val_loss: 0.8082 - val_mean_euclidean_error: 0.5614\n",
      "Epoch 713/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7158 - mean_euclidean_error: 0.4028 - val_loss: 0.8144 - val_mean_euclidean_error: 0.5583\n",
      "Epoch 714/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7143 - mean_euclidean_error: 0.4017 - val_loss: 0.8226 - val_mean_euclidean_error: 0.5805\n",
      "Epoch 715/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7182 - mean_euclidean_error: 0.4038 - val_loss: 0.8295 - val_mean_euclidean_error: 0.5917\n",
      "Epoch 716/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7170 - mean_euclidean_error: 0.4087 - val_loss: 0.8216 - val_mean_euclidean_error: 0.5995\n",
      "Epoch 717/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7230 - mean_euclidean_error: 0.4260 - val_loss: 0.8262 - val_mean_euclidean_error: 0.5936\n",
      "Epoch 718/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7234 - mean_euclidean_error: 0.4281 - val_loss: 0.8329 - val_mean_euclidean_error: 0.6549\n",
      "Epoch 719/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7187 - mean_euclidean_error: 0.4146 - val_loss: 0.8257 - val_mean_euclidean_error: 0.5847\n",
      "Epoch 720/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7140 - mean_euclidean_error: 0.3992 - val_loss: 0.8302 - val_mean_euclidean_error: 0.6120\n",
      "Epoch 721/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7207 - mean_euclidean_error: 0.4288 - val_loss: 0.8122 - val_mean_euclidean_error: 0.5712\n",
      "Epoch 722/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7260 - mean_euclidean_error: 0.4313 - val_loss: 0.8311 - val_mean_euclidean_error: 0.6285\n",
      "Epoch 723/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7216 - mean_euclidean_error: 0.4215 - val_loss: 0.8078 - val_mean_euclidean_error: 0.5582\n",
      "Epoch 724/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7306 - mean_euclidean_error: 0.4515 - val_loss: 0.8253 - val_mean_euclidean_error: 0.6214\n",
      "Epoch 725/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7224 - mean_euclidean_error: 0.4352 - val_loss: 0.8142 - val_mean_euclidean_error: 0.5557\n",
      "Epoch 726/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7187 - mean_euclidean_error: 0.4365 - val_loss: 0.8168 - val_mean_euclidean_error: 0.5819\n",
      "Epoch 727/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7351 - mean_euclidean_error: 0.4513 - val_loss: 0.8317 - val_mean_euclidean_error: 0.6341\n",
      "Epoch 728/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7165 - mean_euclidean_error: 0.4094 - val_loss: 0.8160 - val_mean_euclidean_error: 0.5719\n",
      "Epoch 729/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7133 - mean_euclidean_error: 0.3963 - val_loss: 0.8177 - val_mean_euclidean_error: 0.5602\n",
      "Epoch 730/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7145 - mean_euclidean_error: 0.3978 - val_loss: 0.8190 - val_mean_euclidean_error: 0.5750\n",
      "Epoch 731/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7183 - mean_euclidean_error: 0.4120 - val_loss: 0.8163 - val_mean_euclidean_error: 0.5569\n",
      "Epoch 732/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7140 - mean_euclidean_error: 0.3999 - val_loss: 0.8103 - val_mean_euclidean_error: 0.5636\n",
      "Epoch 733/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7164 - mean_euclidean_error: 0.4077 - val_loss: 0.8170 - val_mean_euclidean_error: 0.5608\n",
      "Epoch 734/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7153 - mean_euclidean_error: 0.4033 - val_loss: 0.8217 - val_mean_euclidean_error: 0.5934\n",
      "Epoch 735/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7123 - mean_euclidean_error: 0.3987 - val_loss: 0.8144 - val_mean_euclidean_error: 0.5653\n",
      "Epoch 736/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7150 - mean_euclidean_error: 0.4030 - val_loss: 0.8249 - val_mean_euclidean_error: 0.5692\n",
      "Epoch 737/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7158 - mean_euclidean_error: 0.4092 - val_loss: 0.8116 - val_mean_euclidean_error: 0.5646\n",
      "Epoch 738/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7167 - mean_euclidean_error: 0.4140 - val_loss: 0.8339 - val_mean_euclidean_error: 0.6266\n",
      "Epoch 739/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7101 - mean_euclidean_error: 0.3889 - val_loss: 0.8085 - val_mean_euclidean_error: 0.5464\n",
      "Epoch 740/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7114 - mean_euclidean_error: 0.3913 - val_loss: 0.8054 - val_mean_euclidean_error: 0.5434\n",
      "Epoch 741/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7098 - mean_euclidean_error: 0.3904 - val_loss: 0.8120 - val_mean_euclidean_error: 0.5628\n",
      "Epoch 742/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7108 - mean_euclidean_error: 0.3920 - val_loss: 0.8153 - val_mean_euclidean_error: 0.5606\n",
      "Epoch 743/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7182 - mean_euclidean_error: 0.4128 - val_loss: 0.8329 - val_mean_euclidean_error: 0.6366\n",
      "Epoch 744/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7232 - mean_euclidean_error: 0.4260 - val_loss: 0.8187 - val_mean_euclidean_error: 0.6039\n",
      "Epoch 745/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7107 - mean_euclidean_error: 0.3886 - val_loss: 0.8110 - val_mean_euclidean_error: 0.5624\n",
      "Epoch 746/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7087 - mean_euclidean_error: 0.3864 - val_loss: 0.8082 - val_mean_euclidean_error: 0.5354\n",
      "Epoch 747/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7097 - mean_euclidean_error: 0.3901 - val_loss: 0.8058 - val_mean_euclidean_error: 0.5426\n",
      "Epoch 748/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7077 - mean_euclidean_error: 0.3865 - val_loss: 0.8051 - val_mean_euclidean_error: 0.5499\n",
      "Epoch 749/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7153 - mean_euclidean_error: 0.4074 - val_loss: 0.8168 - val_mean_euclidean_error: 0.5729\n",
      "Epoch 750/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7174 - mean_euclidean_error: 0.4147 - val_loss: 0.8171 - val_mean_euclidean_error: 0.5464\n",
      "Epoch 751/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7167 - mean_euclidean_error: 0.4184 - val_loss: 0.8153 - val_mean_euclidean_error: 0.5637\n",
      "Epoch 752/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7196 - mean_euclidean_error: 0.4263 - val_loss: 0.8097 - val_mean_euclidean_error: 0.5378\n",
      "Epoch 753/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7117 - mean_euclidean_error: 0.4010 - val_loss: 0.8158 - val_mean_euclidean_error: 0.5701\n",
      "Epoch 754/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7133 - mean_euclidean_error: 0.4077 - val_loss: 0.8266 - val_mean_euclidean_error: 0.5646\n",
      "Epoch 755/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7170 - mean_euclidean_error: 0.4134 - val_loss: 0.8051 - val_mean_euclidean_error: 0.5735\n",
      "Epoch 756/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7119 - mean_euclidean_error: 0.3991 - val_loss: 0.8122 - val_mean_euclidean_error: 0.5529\n",
      "Epoch 757/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7123 - mean_euclidean_error: 0.4057 - val_loss: 0.8093 - val_mean_euclidean_error: 0.5367\n",
      "Epoch 758/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7136 - mean_euclidean_error: 0.4045 - val_loss: 0.8157 - val_mean_euclidean_error: 0.5632\n",
      "Epoch 759/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7073 - mean_euclidean_error: 0.3882 - val_loss: 0.8064 - val_mean_euclidean_error: 0.5309\n",
      "Epoch 760/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7112 - mean_euclidean_error: 0.3976 - val_loss: 0.8109 - val_mean_euclidean_error: 0.5637\n",
      "Epoch 761/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7115 - mean_euclidean_error: 0.4097 - val_loss: 0.8129 - val_mean_euclidean_error: 0.5631\n",
      "Epoch 762/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7188 - mean_euclidean_error: 0.4270 - val_loss: 0.8261 - val_mean_euclidean_error: 0.5945\n",
      "Epoch 763/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7125 - mean_euclidean_error: 0.4113 - val_loss: 0.8046 - val_mean_euclidean_error: 0.5561\n",
      "Epoch 764/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7078 - mean_euclidean_error: 0.3947 - val_loss: 0.8055 - val_mean_euclidean_error: 0.5157\n",
      "Epoch 765/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7100 - mean_euclidean_error: 0.3928 - val_loss: 0.8195 - val_mean_euclidean_error: 0.6021\n",
      "Epoch 766/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7091 - mean_euclidean_error: 0.3975 - val_loss: 0.8153 - val_mean_euclidean_error: 0.5768\n",
      "Epoch 767/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7092 - mean_euclidean_error: 0.3971 - val_loss: 0.8088 - val_mean_euclidean_error: 0.5628\n",
      "Epoch 768/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7134 - mean_euclidean_error: 0.4088 - val_loss: 0.8250 - val_mean_euclidean_error: 0.6438\n",
      "Epoch 769/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7145 - mean_euclidean_error: 0.4142 - val_loss: 0.8100 - val_mean_euclidean_error: 0.5540\n",
      "Epoch 770/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7120 - mean_euclidean_error: 0.4057 - val_loss: 0.8142 - val_mean_euclidean_error: 0.5879\n",
      "Epoch 771/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7117 - mean_euclidean_error: 0.4024 - val_loss: 0.8194 - val_mean_euclidean_error: 0.5672\n",
      "Epoch 772/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7071 - mean_euclidean_error: 0.3888 - val_loss: 0.8154 - val_mean_euclidean_error: 0.5724\n",
      "Epoch 773/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7088 - mean_euclidean_error: 0.3987 - val_loss: 0.8183 - val_mean_euclidean_error: 0.5743\n",
      "Epoch 774/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7099 - mean_euclidean_error: 0.4012 - val_loss: 0.8081 - val_mean_euclidean_error: 0.5758\n",
      "Epoch 775/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7066 - mean_euclidean_error: 0.3853 - val_loss: 0.8036 - val_mean_euclidean_error: 0.5465\n",
      "Epoch 776/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7043 - mean_euclidean_error: 0.3848 - val_loss: 0.8039 - val_mean_euclidean_error: 0.5662\n",
      "Epoch 777/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7063 - mean_euclidean_error: 0.3922 - val_loss: 0.8143 - val_mean_euclidean_error: 0.5508\n",
      "Epoch 778/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7107 - mean_euclidean_error: 0.4011 - val_loss: 0.8203 - val_mean_euclidean_error: 0.5757\n",
      "Epoch 779/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7155 - mean_euclidean_error: 0.4174 - val_loss: 0.8358 - val_mean_euclidean_error: 0.6253\n",
      "Epoch 780/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7220 - mean_euclidean_error: 0.4484 - val_loss: 0.8267 - val_mean_euclidean_error: 0.5878\n",
      "Epoch 781/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7165 - mean_euclidean_error: 0.4226 - val_loss: 0.8281 - val_mean_euclidean_error: 0.6131\n",
      "Epoch 782/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7066 - mean_euclidean_error: 0.3977 - val_loss: 0.8059 - val_mean_euclidean_error: 0.5442\n",
      "Epoch 783/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7081 - mean_euclidean_error: 0.3996 - val_loss: 0.8112 - val_mean_euclidean_error: 0.5713\n",
      "Epoch 784/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7082 - mean_euclidean_error: 0.3984 - val_loss: 0.8059 - val_mean_euclidean_error: 0.5630\n",
      "Epoch 785/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7072 - mean_euclidean_error: 0.3983 - val_loss: 0.8011 - val_mean_euclidean_error: 0.5497\n",
      "Epoch 786/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7115 - mean_euclidean_error: 0.4067 - val_loss: 0.8151 - val_mean_euclidean_error: 0.5999\n",
      "Epoch 787/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7051 - mean_euclidean_error: 0.3925 - val_loss: 0.8048 - val_mean_euclidean_error: 0.5342\n",
      "Epoch 788/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7041 - mean_euclidean_error: 0.3863 - val_loss: 0.7996 - val_mean_euclidean_error: 0.5573\n",
      "Epoch 789/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7092 - mean_euclidean_error: 0.4094 - val_loss: 0.8021 - val_mean_euclidean_error: 0.5373\n",
      "Epoch 790/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7081 - mean_euclidean_error: 0.4008 - val_loss: 0.8196 - val_mean_euclidean_error: 0.5947\n",
      "Epoch 791/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7175 - mean_euclidean_error: 0.4235 - val_loss: 0.8078 - val_mean_euclidean_error: 0.5740\n",
      "Epoch 792/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7158 - mean_euclidean_error: 0.4261 - val_loss: 0.8090 - val_mean_euclidean_error: 0.5891\n",
      "Epoch 793/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7103 - mean_euclidean_error: 0.4087 - val_loss: 0.8043 - val_mean_euclidean_error: 0.5776\n",
      "Epoch 794/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7064 - mean_euclidean_error: 0.4015 - val_loss: 0.8037 - val_mean_euclidean_error: 0.5377\n",
      "Epoch 795/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7089 - mean_euclidean_error: 0.4055 - val_loss: 0.7934 - val_mean_euclidean_error: 0.5353\n",
      "Epoch 796/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7054 - mean_euclidean_error: 0.3941 - val_loss: 0.7963 - val_mean_euclidean_error: 0.5500\n",
      "Epoch 797/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7079 - mean_euclidean_error: 0.4018 - val_loss: 0.8154 - val_mean_euclidean_error: 0.6015\n",
      "Epoch 798/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7062 - mean_euclidean_error: 0.3967 - val_loss: 0.7984 - val_mean_euclidean_error: 0.5479\n",
      "Epoch 799/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7042 - mean_euclidean_error: 0.3989 - val_loss: 0.8045 - val_mean_euclidean_error: 0.5524\n",
      "Epoch 800/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7302 - mean_euclidean_error: 0.4613 - val_loss: 0.8173 - val_mean_euclidean_error: 0.5562\n",
      "Epoch 801/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7338 - mean_euclidean_error: 0.4628 - val_loss: 0.8307 - val_mean_euclidean_error: 0.6068\n",
      "Epoch 802/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7097 - mean_euclidean_error: 0.4052 - val_loss: 0.8111 - val_mean_euclidean_error: 0.5411\n",
      "Epoch 803/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7077 - mean_euclidean_error: 0.4067 - val_loss: 0.8036 - val_mean_euclidean_error: 0.5617\n",
      "Epoch 804/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7051 - mean_euclidean_error: 0.3926 - val_loss: 0.8051 - val_mean_euclidean_error: 0.5529\n",
      "Epoch 805/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7079 - mean_euclidean_error: 0.4100 - val_loss: 0.8163 - val_mean_euclidean_error: 0.5988\n",
      "Epoch 806/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7105 - mean_euclidean_error: 0.4115 - val_loss: 0.8087 - val_mean_euclidean_error: 0.5655\n",
      "Epoch 807/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7084 - mean_euclidean_error: 0.4060 - val_loss: 0.8046 - val_mean_euclidean_error: 0.5600\n",
      "Epoch 808/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7072 - mean_euclidean_error: 0.4028 - val_loss: 0.8154 - val_mean_euclidean_error: 0.5574\n",
      "Epoch 809/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7055 - mean_euclidean_error: 0.3999 - val_loss: 0.8056 - val_mean_euclidean_error: 0.5675\n",
      "Epoch 810/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7045 - mean_euclidean_error: 0.3923 - val_loss: 0.8051 - val_mean_euclidean_error: 0.5533\n",
      "Epoch 811/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7053 - mean_euclidean_error: 0.3981 - val_loss: 0.8125 - val_mean_euclidean_error: 0.5898\n",
      "Epoch 812/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7024 - mean_euclidean_error: 0.3889 - val_loss: 0.8098 - val_mean_euclidean_error: 0.5521\n",
      "Epoch 813/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7004 - mean_euclidean_error: 0.3781 - val_loss: 0.8069 - val_mean_euclidean_error: 0.5645\n",
      "Epoch 814/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7063 - mean_euclidean_error: 0.4027 - val_loss: 0.8240 - val_mean_euclidean_error: 0.5935\n",
      "Epoch 815/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7088 - mean_euclidean_error: 0.4145 - val_loss: 0.8153 - val_mean_euclidean_error: 0.6002\n",
      "Epoch 816/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7036 - mean_euclidean_error: 0.3924 - val_loss: 0.8030 - val_mean_euclidean_error: 0.5333\n",
      "Epoch 817/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7016 - mean_euclidean_error: 0.3937 - val_loss: 0.8050 - val_mean_euclidean_error: 0.5578\n",
      "Epoch 818/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7086 - mean_euclidean_error: 0.4012 - val_loss: 0.8157 - val_mean_euclidean_error: 0.5631\n",
      "Epoch 819/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7045 - mean_euclidean_error: 0.3949 - val_loss: 0.8227 - val_mean_euclidean_error: 0.6074\n",
      "Epoch 820/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7036 - mean_euclidean_error: 0.3912 - val_loss: 0.8008 - val_mean_euclidean_error: 0.5572\n",
      "Epoch 821/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7060 - mean_euclidean_error: 0.4013 - val_loss: 0.8044 - val_mean_euclidean_error: 0.5671\n",
      "Epoch 822/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7017 - mean_euclidean_error: 0.3913 - val_loss: 0.8011 - val_mean_euclidean_error: 0.5522\n",
      "Epoch 823/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7042 - mean_euclidean_error: 0.3943 - val_loss: 0.8084 - val_mean_euclidean_error: 0.5619\n",
      "Epoch 824/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7138 - mean_euclidean_error: 0.4219 - val_loss: 0.7993 - val_mean_euclidean_error: 0.5385\n",
      "Epoch 825/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7051 - mean_euclidean_error: 0.4123 - val_loss: 0.8055 - val_mean_euclidean_error: 0.5553\n",
      "Epoch 826/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7087 - mean_euclidean_error: 0.4138 - val_loss: 0.8083 - val_mean_euclidean_error: 0.5757\n",
      "Epoch 827/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6999 - mean_euclidean_error: 0.3852 - val_loss: 0.8117 - val_mean_euclidean_error: 0.5698\n",
      "Epoch 828/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7016 - mean_euclidean_error: 0.3849 - val_loss: 0.8124 - val_mean_euclidean_error: 0.5725\n",
      "Epoch 829/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7050 - mean_euclidean_error: 0.4061 - val_loss: 0.8096 - val_mean_euclidean_error: 0.5538\n",
      "Epoch 830/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6990 - mean_euclidean_error: 0.3827 - val_loss: 0.7925 - val_mean_euclidean_error: 0.5390\n",
      "Epoch 831/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7005 - mean_euclidean_error: 0.3881 - val_loss: 0.7970 - val_mean_euclidean_error: 0.5618\n",
      "Epoch 832/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6988 - mean_euclidean_error: 0.3849 - val_loss: 0.8115 - val_mean_euclidean_error: 0.5775\n",
      "Epoch 833/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7069 - mean_euclidean_error: 0.4164 - val_loss: 0.8127 - val_mean_euclidean_error: 0.5895\n",
      "Epoch 834/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7080 - mean_euclidean_error: 0.4128 - val_loss: 0.8002 - val_mean_euclidean_error: 0.5745\n",
      "Epoch 835/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7022 - mean_euclidean_error: 0.3958 - val_loss: 0.7973 - val_mean_euclidean_error: 0.5539\n",
      "Epoch 836/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6986 - mean_euclidean_error: 0.3979 - val_loss: 0.7980 - val_mean_euclidean_error: 0.5717\n",
      "Epoch 837/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7028 - mean_euclidean_error: 0.3982 - val_loss: 0.8033 - val_mean_euclidean_error: 0.5606\n",
      "Epoch 838/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7035 - mean_euclidean_error: 0.3991 - val_loss: 0.8000 - val_mean_euclidean_error: 0.5656\n",
      "Epoch 839/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7072 - mean_euclidean_error: 0.4121 - val_loss: 0.8017 - val_mean_euclidean_error: 0.5548\n",
      "Epoch 840/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6973 - mean_euclidean_error: 0.3884 - val_loss: 0.7948 - val_mean_euclidean_error: 0.5508\n",
      "Epoch 841/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7017 - mean_euclidean_error: 0.3995 - val_loss: 0.7951 - val_mean_euclidean_error: 0.5568\n",
      "Epoch 842/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7016 - mean_euclidean_error: 0.4009 - val_loss: 0.8133 - val_mean_euclidean_error: 0.5927\n",
      "Epoch 843/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7048 - mean_euclidean_error: 0.4046 - val_loss: 0.8091 - val_mean_euclidean_error: 0.5611\n",
      "Epoch 844/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7026 - mean_euclidean_error: 0.4011 - val_loss: 0.8067 - val_mean_euclidean_error: 0.5658\n",
      "Epoch 845/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6991 - mean_euclidean_error: 0.3879 - val_loss: 0.8002 - val_mean_euclidean_error: 0.5609\n",
      "Epoch 846/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7005 - mean_euclidean_error: 0.3887 - val_loss: 0.7971 - val_mean_euclidean_error: 0.5697\n",
      "Epoch 847/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7058 - mean_euclidean_error: 0.4057 - val_loss: 0.7987 - val_mean_euclidean_error: 0.5509\n",
      "Epoch 848/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7022 - mean_euclidean_error: 0.3973 - val_loss: 0.8020 - val_mean_euclidean_error: 0.5508\n",
      "Epoch 849/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7018 - mean_euclidean_error: 0.4002 - val_loss: 0.8042 - val_mean_euclidean_error: 0.5629\n",
      "Epoch 850/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7007 - mean_euclidean_error: 0.4000 - val_loss: 0.7977 - val_mean_euclidean_error: 0.5662\n",
      "Epoch 851/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7074 - mean_euclidean_error: 0.4124 - val_loss: 0.7926 - val_mean_euclidean_error: 0.5377\n",
      "Epoch 852/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7033 - mean_euclidean_error: 0.4073 - val_loss: 0.7998 - val_mean_euclidean_error: 0.5684\n",
      "Epoch 853/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7010 - mean_euclidean_error: 0.3993 - val_loss: 0.8029 - val_mean_euclidean_error: 0.5266\n",
      "Epoch 854/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6961 - mean_euclidean_error: 0.3809 - val_loss: 0.7932 - val_mean_euclidean_error: 0.5537\n",
      "Epoch 855/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6976 - mean_euclidean_error: 0.3824 - val_loss: 0.8128 - val_mean_euclidean_error: 0.6268\n",
      "Epoch 856/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7005 - mean_euclidean_error: 0.3938 - val_loss: 0.8042 - val_mean_euclidean_error: 0.5397\n",
      "Epoch 857/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6996 - mean_euclidean_error: 0.3917 - val_loss: 0.8084 - val_mean_euclidean_error: 0.5680\n",
      "Epoch 858/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6980 - mean_euclidean_error: 0.3839 - val_loss: 0.7970 - val_mean_euclidean_error: 0.5454\n",
      "Epoch 859/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6951 - mean_euclidean_error: 0.3786 - val_loss: 0.7963 - val_mean_euclidean_error: 0.5586\n",
      "Epoch 860/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6953 - mean_euclidean_error: 0.3886 - val_loss: 0.8040 - val_mean_euclidean_error: 0.5577\n",
      "Epoch 861/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6967 - mean_euclidean_error: 0.3834 - val_loss: 0.7964 - val_mean_euclidean_error: 0.5440\n",
      "Epoch 862/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6959 - mean_euclidean_error: 0.3816 - val_loss: 0.7938 - val_mean_euclidean_error: 0.5201\n",
      "Epoch 863/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6979 - mean_euclidean_error: 0.3876 - val_loss: 0.7985 - val_mean_euclidean_error: 0.5367\n",
      "Epoch 864/1500\n",
      "18/29 [=================>............] - ETA: 0s - loss: 0.6980 - mean_euclidean_error: 0.3877Restoring model weights from the end of the best epoch: 764.\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6947 - mean_euclidean_error: 0.3814 - val_loss: 0.8002 - val_mean_euclidean_error: 0.5652\n",
      "\n",
      "Epoch 864: early stopping.\n",
      "Best validation mean_euclidean_error: 0.5156958699226379\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "best_config_sgd_cup = {\n",
    "    'lr': 0.00035,\n",
    "    'h_dim': 100,\n",
    "    'n_layers': 3,\n",
    "    'activation': 'tanh',\n",
    "    'reg': 0.001,\n",
    "    'momentum': 0.95, \n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "optimizer_sgd = SGD(learning_rate=best_config_sgd_cup['lr'], momentum=best_config_sgd_cup['momentum'])\n",
    "model_nn_sgd_cup = get_nn_regressor(optimizer_sgd, best_config_sgd_cup)\n",
    "solver_sgd = Solver(model_nn_sgd_cup, x_train_cup, y_train_cup, x_internal_test_cup, y_internal_test_cup, target='mean_euclidean_error')\n",
    "solver_sgd.train(epochs=1500, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93ddbf68-bd7a-422d-bf8e-75ba8cfa45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "29/29 [==============================] - 1s 16ms/step - loss: 740.8928 - mean_euclidean_error: 42.3680 - val_loss: 562.0319 - val_mean_euclidean_error: 37.1776\n",
      "Epoch 2/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 647.8185 - mean_euclidean_error: 38.3024 - val_loss: 484.3904 - val_mean_euclidean_error: 34.1411\n",
      "Epoch 3/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 565.3552 - mean_euclidean_error: 35.6912 - val_loss: 420.1421 - val_mean_euclidean_error: 31.3361\n",
      "Epoch 4/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 499.5715 - mean_euclidean_error: 33.7931 - val_loss: 370.9395 - val_mean_euclidean_error: 29.0694\n",
      "Epoch 5/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 448.4428 - mean_euclidean_error: 31.6065 - val_loss: 332.0056 - val_mean_euclidean_error: 27.2174\n",
      "Epoch 6/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 407.1106 - mean_euclidean_error: 29.2149 - val_loss: 300.0948 - val_mean_euclidean_error: 25.6497\n",
      "Epoch 7/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 372.4634 - mean_euclidean_error: 28.6563 - val_loss: 272.8087 - val_mean_euclidean_error: 24.2720\n",
      "Epoch 8/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 341.5227 - mean_euclidean_error: 26.7221 - val_loss: 247.8927 - val_mean_euclidean_error: 22.9942\n",
      "Epoch 9/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 313.8151 - mean_euclidean_error: 25.8469 - val_loss: 226.4462 - val_mean_euclidean_error: 21.8411\n",
      "Epoch 10/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 288.9612 - mean_euclidean_error: 24.0273 - val_loss: 206.6200 - val_mean_euclidean_error: 20.7463\n",
      "Epoch 11/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 266.1978 - mean_euclidean_error: 23.0975 - val_loss: 189.5387 - val_mean_euclidean_error: 19.7602\n",
      "Epoch 12/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 245.8451 - mean_euclidean_error: 21.9776 - val_loss: 173.1765 - val_mean_euclidean_error: 18.8011\n",
      "Epoch 13/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 226.6366 - mean_euclidean_error: 21.8244 - val_loss: 158.5710 - val_mean_euclidean_error: 17.9261\n",
      "Epoch 14/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 208.5431 - mean_euclidean_error: 20.1876 - val_loss: 144.9328 - val_mean_euclidean_error: 17.0968\n",
      "Epoch 15/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 192.0366 - mean_euclidean_error: 19.6033 - val_loss: 132.9178 - val_mean_euclidean_error: 16.3492\n",
      "Epoch 16/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 176.8487 - mean_euclidean_error: 18.8473 - val_loss: 121.5557 - val_mean_euclidean_error: 15.6117\n",
      "Epoch 17/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 162.7946 - mean_euclidean_error: 18.0936 - val_loss: 111.0625 - val_mean_euclidean_error: 14.9205\n",
      "Epoch 18/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 149.6457 - mean_euclidean_error: 17.8483 - val_loss: 101.5012 - val_mean_euclidean_error: 14.2921\n",
      "Epoch 19/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 137.2709 - mean_euclidean_error: 16.5592 - val_loss: 92.5633 - val_mean_euclidean_error: 13.6620\n",
      "Epoch 20/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 125.8918 - mean_euclidean_error: 15.8615 - val_loss: 84.3822 - val_mean_euclidean_error: 13.0460\n",
      "Epoch 21/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 115.2671 - mean_euclidean_error: 15.5779 - val_loss: 76.7788 - val_mean_euclidean_error: 12.4833\n",
      "Epoch 22/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 104.8281 - mean_euclidean_error: 14.5642 - val_loss: 68.9370 - val_mean_euclidean_error: 11.8065\n",
      "Epoch 23/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 94.8211 - mean_euclidean_error: 13.8995 - val_loss: 61.4866 - val_mean_euclidean_error: 11.1578\n",
      "Epoch 24/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 85.2834 - mean_euclidean_error: 13.1807 - val_loss: 54.3791 - val_mean_euclidean_error: 10.4234\n",
      "Epoch 25/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 76.2900 - mean_euclidean_error: 12.0347 - val_loss: 47.9144 - val_mean_euclidean_error: 9.7045\n",
      "Epoch 26/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 68.2314 - mean_euclidean_error: 11.2537 - val_loss: 42.1377 - val_mean_euclidean_error: 9.0035\n",
      "Epoch 27/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 60.9307 - mean_euclidean_error: 10.3796 - val_loss: 37.3236 - val_mean_euclidean_error: 8.4778\n",
      "Epoch 28/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 54.4828 - mean_euclidean_error: 9.5768 - val_loss: 32.9231 - val_mean_euclidean_error: 7.9045\n",
      "Epoch 29/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 48.7114 - mean_euclidean_error: 9.1692 - val_loss: 29.1151 - val_mean_euclidean_error: 7.4290\n",
      "Epoch 30/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 43.5071 - mean_euclidean_error: 8.6295 - val_loss: 25.4208 - val_mean_euclidean_error: 6.9408\n",
      "Epoch 31/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 38.6558 - mean_euclidean_error: 8.0093 - val_loss: 22.2768 - val_mean_euclidean_error: 6.5043\n",
      "Epoch 32/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 34.3385 - mean_euclidean_error: 7.3958 - val_loss: 19.4716 - val_mean_euclidean_error: 6.0576\n",
      "Epoch 33/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 30.5052 - mean_euclidean_error: 7.1835 - val_loss: 17.0417 - val_mean_euclidean_error: 5.6241\n",
      "Epoch 34/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 27.0132 - mean_euclidean_error: 6.4098 - val_loss: 14.8436 - val_mean_euclidean_error: 5.2126\n",
      "Epoch 35/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 23.9986 - mean_euclidean_error: 6.0034 - val_loss: 13.0445 - val_mean_euclidean_error: 4.8433\n",
      "Epoch 36/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 21.4366 - mean_euclidean_error: 5.6622 - val_loss: 11.3942 - val_mean_euclidean_error: 4.4039\n",
      "Epoch 37/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 19.0639 - mean_euclidean_error: 5.3512 - val_loss: 10.0787 - val_mean_euclidean_error: 4.1263\n",
      "Epoch 38/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 17.0143 - mean_euclidean_error: 5.1538 - val_loss: 8.9497 - val_mean_euclidean_error: 3.8091\n",
      "Epoch 39/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 15.1306 - mean_euclidean_error: 4.7585 - val_loss: 7.9346 - val_mean_euclidean_error: 3.5665\n",
      "Epoch 40/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 13.5481 - mean_euclidean_error: 4.4603 - val_loss: 7.1706 - val_mean_euclidean_error: 3.3437\n",
      "Epoch 41/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 12.1860 - mean_euclidean_error: 4.2756 - val_loss: 6.3963 - val_mean_euclidean_error: 3.1164\n",
      "Epoch 42/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 11.0224 - mean_euclidean_error: 4.0698 - val_loss: 5.7846 - val_mean_euclidean_error: 2.9136\n",
      "Epoch 43/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 9.9818 - mean_euclidean_error: 3.9352 - val_loss: 5.3411 - val_mean_euclidean_error: 2.8024\n",
      "Epoch 44/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.1478 - mean_euclidean_error: 3.6277 - val_loss: 4.9695 - val_mean_euclidean_error: 2.7436\n",
      "Epoch 45/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 8.3967 - mean_euclidean_error: 3.4740 - val_loss: 4.6731 - val_mean_euclidean_error: 2.6952\n",
      "Epoch 46/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 7.8100 - mean_euclidean_error: 3.4635 - val_loss: 4.4580 - val_mean_euclidean_error: 2.5334\n",
      "Epoch 47/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 7.2452 - mean_euclidean_error: 3.1813 - val_loss: 4.1566 - val_mean_euclidean_error: 2.4853\n",
      "Epoch 48/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 6.7816 - mean_euclidean_error: 3.1413 - val_loss: 4.0469 - val_mean_euclidean_error: 2.4487\n",
      "Epoch 49/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 6.4219 - mean_euclidean_error: 3.0264 - val_loss: 3.8488 - val_mean_euclidean_error: 2.4372\n",
      "Epoch 50/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 6.0525 - mean_euclidean_error: 2.8920 - val_loss: 3.6835 - val_mean_euclidean_error: 2.4039\n",
      "Epoch 51/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 5.7585 - mean_euclidean_error: 2.7985 - val_loss: 3.5128 - val_mean_euclidean_error: 2.2830\n",
      "Epoch 52/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 5.5196 - mean_euclidean_error: 2.7675 - val_loss: 3.4409 - val_mean_euclidean_error: 2.2754\n",
      "Epoch 53/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 5.2705 - mean_euclidean_error: 2.6690 - val_loss: 3.3138 - val_mean_euclidean_error: 2.2378\n",
      "Epoch 54/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 5.0785 - mean_euclidean_error: 2.5812 - val_loss: 3.1837 - val_mean_euclidean_error: 2.1814\n",
      "Epoch 55/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 4.8857 - mean_euclidean_error: 2.5533 - val_loss: 3.0602 - val_mean_euclidean_error: 2.0332\n",
      "Epoch 56/1500\n",
      "29/29 [==============================] - 1s 20ms/step - loss: 4.7403 - mean_euclidean_error: 2.5017 - val_loss: 3.0522 - val_mean_euclidean_error: 2.1583\n",
      "Epoch 57/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 4.5422 - mean_euclidean_error: 2.4684 - val_loss: 2.9370 - val_mean_euclidean_error: 2.0362\n",
      "Epoch 58/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 4.3619 - mean_euclidean_error: 2.3715 - val_loss: 2.8490 - val_mean_euclidean_error: 1.9936\n",
      "Epoch 59/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 4.2288 - mean_euclidean_error: 2.3744 - val_loss: 2.8194 - val_mean_euclidean_error: 1.9091\n",
      "Epoch 60/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 4.0689 - mean_euclidean_error: 2.2264 - val_loss: 2.7747 - val_mean_euclidean_error: 1.9122\n",
      "Epoch 61/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 3.8986 - mean_euclidean_error: 2.1871 - val_loss: 2.7220 - val_mean_euclidean_error: 1.8752\n",
      "Epoch 62/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 3.7348 - mean_euclidean_error: 2.1529 - val_loss: 2.6134 - val_mean_euclidean_error: 1.8324\n",
      "Epoch 63/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 3.5680 - mean_euclidean_error: 2.0991 - val_loss: 2.5972 - val_mean_euclidean_error: 1.8093\n",
      "Epoch 64/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 3.4055 - mean_euclidean_error: 2.0662 - val_loss: 2.4553 - val_mean_euclidean_error: 1.8149\n",
      "Epoch 65/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 3.2537 - mean_euclidean_error: 2.0197 - val_loss: 2.5279 - val_mean_euclidean_error: 1.8271\n",
      "Epoch 66/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 3.0916 - mean_euclidean_error: 1.9387 - val_loss: 2.3703 - val_mean_euclidean_error: 1.7034\n",
      "Epoch 67/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 2.9832 - mean_euclidean_error: 1.9658 - val_loss: 2.4026 - val_mean_euclidean_error: 1.6948\n",
      "Epoch 68/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 2.8642 - mean_euclidean_error: 1.8606 - val_loss: 2.2852 - val_mean_euclidean_error: 1.7110\n",
      "Epoch 69/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 2.7262 - mean_euclidean_error: 1.7708 - val_loss: 2.2612 - val_mean_euclidean_error: 1.6417\n",
      "Epoch 70/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.6209 - mean_euclidean_error: 1.7361 - val_loss: 2.2119 - val_mean_euclidean_error: 1.6628\n",
      "Epoch 71/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 2.5496 - mean_euclidean_error: 1.7492 - val_loss: 2.2006 - val_mean_euclidean_error: 1.6900\n",
      "Epoch 72/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 2.4666 - mean_euclidean_error: 1.6791 - val_loss: 2.1561 - val_mean_euclidean_error: 1.5859\n",
      "Epoch 73/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.3718 - mean_euclidean_error: 1.6699 - val_loss: 2.1459 - val_mean_euclidean_error: 1.6321\n",
      "Epoch 74/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 2.3257 - mean_euclidean_error: 1.6445 - val_loss: 2.0131 - val_mean_euclidean_error: 1.5270\n",
      "Epoch 75/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 2.2111 - mean_euclidean_error: 1.5554 - val_loss: 1.9699 - val_mean_euclidean_error: 1.5215\n",
      "Epoch 76/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 2.1453 - mean_euclidean_error: 1.5493 - val_loss: 2.0377 - val_mean_euclidean_error: 1.5587\n",
      "Epoch 77/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 2.0723 - mean_euclidean_error: 1.5681 - val_loss: 1.9061 - val_mean_euclidean_error: 1.4996\n",
      "Epoch 78/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.9989 - mean_euclidean_error: 1.4831 - val_loss: 1.8916 - val_mean_euclidean_error: 1.4987\n",
      "Epoch 79/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.9101 - mean_euclidean_error: 1.4961 - val_loss: 1.8530 - val_mean_euclidean_error: 1.4520\n",
      "Epoch 80/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.8542 - mean_euclidean_error: 1.4440 - val_loss: 1.8235 - val_mean_euclidean_error: 1.5416\n",
      "Epoch 81/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.8128 - mean_euclidean_error: 1.4395 - val_loss: 1.7657 - val_mean_euclidean_error: 1.4397\n",
      "Epoch 82/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.7371 - mean_euclidean_error: 1.3943 - val_loss: 1.7149 - val_mean_euclidean_error: 1.4243\n",
      "Epoch 83/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.7080 - mean_euclidean_error: 1.3918 - val_loss: 1.6784 - val_mean_euclidean_error: 1.3616\n",
      "Epoch 84/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.6601 - mean_euclidean_error: 1.3349 - val_loss: 1.6748 - val_mean_euclidean_error: 1.3207\n",
      "Epoch 85/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.6203 - mean_euclidean_error: 1.3867 - val_loss: 1.6565 - val_mean_euclidean_error: 1.3327\n",
      "Epoch 86/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.6255 - mean_euclidean_error: 1.3314 - val_loss: 1.6404 - val_mean_euclidean_error: 1.3533\n",
      "Epoch 87/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.5609 - mean_euclidean_error: 1.2808 - val_loss: 1.6039 - val_mean_euclidean_error: 1.3129\n",
      "Epoch 88/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 1.5287 - mean_euclidean_error: 1.2439 - val_loss: 1.5845 - val_mean_euclidean_error: 1.3745\n",
      "Epoch 89/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.4999 - mean_euclidean_error: 1.2519 - val_loss: 1.5747 - val_mean_euclidean_error: 1.3382\n",
      "Epoch 90/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.5064 - mean_euclidean_error: 1.2549 - val_loss: 1.5142 - val_mean_euclidean_error: 1.2705\n",
      "Epoch 91/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.4727 - mean_euclidean_error: 1.2304 - val_loss: 1.4889 - val_mean_euclidean_error: 1.2556\n",
      "Epoch 92/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.4585 - mean_euclidean_error: 1.2144 - val_loss: 1.4854 - val_mean_euclidean_error: 1.2497\n",
      "Epoch 93/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.4272 - mean_euclidean_error: 1.1976 - val_loss: 1.4597 - val_mean_euclidean_error: 1.2794\n",
      "Epoch 94/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.3973 - mean_euclidean_error: 1.1696 - val_loss: 1.4433 - val_mean_euclidean_error: 1.2050\n",
      "Epoch 95/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 1.3729 - mean_euclidean_error: 1.1507 - val_loss: 1.4172 - val_mean_euclidean_error: 1.1969\n",
      "Epoch 96/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.3502 - mean_euclidean_error: 1.1113 - val_loss: 1.4280 - val_mean_euclidean_error: 1.2127\n",
      "Epoch 97/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.3450 - mean_euclidean_error: 1.1445 - val_loss: 1.4017 - val_mean_euclidean_error: 1.2365\n",
      "Epoch 98/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.3216 - mean_euclidean_error: 1.1150 - val_loss: 1.4439 - val_mean_euclidean_error: 1.2076\n",
      "Epoch 99/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.3302 - mean_euclidean_error: 1.1393 - val_loss: 1.3964 - val_mean_euclidean_error: 1.2175\n",
      "Epoch 100/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.3083 - mean_euclidean_error: 1.1094 - val_loss: 1.3551 - val_mean_euclidean_error: 1.1915\n",
      "Epoch 101/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.2702 - mean_euclidean_error: 1.0709 - val_loss: 1.4198 - val_mean_euclidean_error: 1.2829\n",
      "Epoch 102/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.2711 - mean_euclidean_error: 1.0944 - val_loss: 1.3836 - val_mean_euclidean_error: 1.1447\n",
      "Epoch 103/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.2645 - mean_euclidean_error: 1.1210 - val_loss: 1.3287 - val_mean_euclidean_error: 1.1931\n",
      "Epoch 104/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.2738 - mean_euclidean_error: 1.0878 - val_loss: 1.3404 - val_mean_euclidean_error: 1.1037\n",
      "Epoch 105/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.2359 - mean_euclidean_error: 1.0699 - val_loss: 1.3161 - val_mean_euclidean_error: 1.1402\n",
      "Epoch 106/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 1.2109 - mean_euclidean_error: 1.0294 - val_loss: 1.3078 - val_mean_euclidean_error: 1.0768\n",
      "Epoch 107/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 1.2128 - mean_euclidean_error: 1.0479 - val_loss: 1.2594 - val_mean_euclidean_error: 1.1016\n",
      "Epoch 108/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1803 - mean_euclidean_error: 1.0155 - val_loss: 1.3405 - val_mean_euclidean_error: 1.1963\n",
      "Epoch 109/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1847 - mean_euclidean_error: 1.0328 - val_loss: 1.2911 - val_mean_euclidean_error: 1.0504\n",
      "Epoch 110/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1744 - mean_euclidean_error: 1.0031 - val_loss: 1.3167 - val_mean_euclidean_error: 1.1802\n",
      "Epoch 111/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.1558 - mean_euclidean_error: 0.9857 - val_loss: 1.2443 - val_mean_euclidean_error: 1.0620\n",
      "Epoch 112/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1420 - mean_euclidean_error: 0.9917 - val_loss: 1.2946 - val_mean_euclidean_error: 1.1156\n",
      "Epoch 113/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1378 - mean_euclidean_error: 0.9875 - val_loss: 1.2648 - val_mean_euclidean_error: 1.1397\n",
      "Epoch 114/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1514 - mean_euclidean_error: 1.0205 - val_loss: 1.2191 - val_mean_euclidean_error: 1.0535\n",
      "Epoch 115/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.1308 - mean_euclidean_error: 0.9672 - val_loss: 1.2330 - val_mean_euclidean_error: 1.0833\n",
      "Epoch 116/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1169 - mean_euclidean_error: 0.9810 - val_loss: 1.2282 - val_mean_euclidean_error: 1.0671\n",
      "Epoch 117/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1123 - mean_euclidean_error: 0.9716 - val_loss: 1.2556 - val_mean_euclidean_error: 1.0950\n",
      "Epoch 118/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.1063 - mean_euclidean_error: 0.9948 - val_loss: 1.2228 - val_mean_euclidean_error: 1.0909\n",
      "Epoch 119/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1036 - mean_euclidean_error: 0.9627 - val_loss: 1.2502 - val_mean_euclidean_error: 1.1017\n",
      "Epoch 120/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0774 - mean_euclidean_error: 0.9270 - val_loss: 1.2601 - val_mean_euclidean_error: 1.0882\n",
      "Epoch 121/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0706 - mean_euclidean_error: 0.9560 - val_loss: 1.2632 - val_mean_euclidean_error: 1.0832\n",
      "Epoch 122/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0810 - mean_euclidean_error: 0.9612 - val_loss: 1.2404 - val_mean_euclidean_error: 1.0652\n",
      "Epoch 123/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0663 - mean_euclidean_error: 0.9576 - val_loss: 1.1846 - val_mean_euclidean_error: 1.0448\n",
      "Epoch 124/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0485 - mean_euclidean_error: 0.9114 - val_loss: 1.1938 - val_mean_euclidean_error: 1.0398\n",
      "Epoch 125/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0519 - mean_euclidean_error: 0.9111 - val_loss: 1.2032 - val_mean_euclidean_error: 1.0680\n",
      "Epoch 126/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0587 - mean_euclidean_error: 0.9315 - val_loss: 1.2272 - val_mean_euclidean_error: 1.0421\n",
      "Epoch 127/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0451 - mean_euclidean_error: 0.9133 - val_loss: 1.1586 - val_mean_euclidean_error: 0.9478\n",
      "Epoch 128/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0321 - mean_euclidean_error: 0.8806 - val_loss: 1.2035 - val_mean_euclidean_error: 1.1105\n",
      "Epoch 129/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0372 - mean_euclidean_error: 0.8956 - val_loss: 1.1589 - val_mean_euclidean_error: 0.9639\n",
      "Epoch 130/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0380 - mean_euclidean_error: 0.9083 - val_loss: 1.1569 - val_mean_euclidean_error: 0.9624\n",
      "Epoch 131/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0178 - mean_euclidean_error: 0.8744 - val_loss: 1.2059 - val_mean_euclidean_error: 1.1009\n",
      "Epoch 132/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 1.0105 - mean_euclidean_error: 0.8654 - val_loss: 1.1416 - val_mean_euclidean_error: 0.9723\n",
      "Epoch 133/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0141 - mean_euclidean_error: 0.8736 - val_loss: 1.1395 - val_mean_euclidean_error: 1.0356\n",
      "Epoch 134/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9981 - mean_euclidean_error: 0.8558 - val_loss: 1.1714 - val_mean_euclidean_error: 1.0352\n",
      "Epoch 135/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.9937 - mean_euclidean_error: 0.8438 - val_loss: 1.1645 - val_mean_euclidean_error: 1.0322\n",
      "Epoch 136/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9972 - mean_euclidean_error: 0.8627 - val_loss: 1.1692 - val_mean_euclidean_error: 0.9779\n",
      "Epoch 137/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9979 - mean_euclidean_error: 0.8571 - val_loss: 1.1612 - val_mean_euclidean_error: 0.9764\n",
      "Epoch 138/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9815 - mean_euclidean_error: 0.8523 - val_loss: 1.1372 - val_mean_euclidean_error: 0.9212\n",
      "Epoch 139/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9979 - mean_euclidean_error: 0.8751 - val_loss: 1.1574 - val_mean_euclidean_error: 1.0173\n",
      "Epoch 140/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9879 - mean_euclidean_error: 0.8565 - val_loss: 1.1333 - val_mean_euclidean_error: 0.9619\n",
      "Epoch 141/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9666 - mean_euclidean_error: 0.8255 - val_loss: 1.1627 - val_mean_euclidean_error: 0.9278\n",
      "Epoch 142/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9990 - mean_euclidean_error: 0.8893 - val_loss: 1.1280 - val_mean_euclidean_error: 0.9273\n",
      "Epoch 143/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9714 - mean_euclidean_error: 0.8923 - val_loss: 1.1447 - val_mean_euclidean_error: 0.9297\n",
      "Epoch 144/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9806 - mean_euclidean_error: 0.8868 - val_loss: 1.1884 - val_mean_euclidean_error: 1.0283\n",
      "Epoch 145/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9632 - mean_euclidean_error: 0.8268 - val_loss: 1.1274 - val_mean_euclidean_error: 1.0010\n",
      "Epoch 146/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9431 - mean_euclidean_error: 0.8054 - val_loss: 1.1446 - val_mean_euclidean_error: 1.0089\n",
      "Epoch 147/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.9422 - mean_euclidean_error: 0.8026 - val_loss: 1.1184 - val_mean_euclidean_error: 0.9245\n",
      "Epoch 148/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.9365 - mean_euclidean_error: 0.8140 - val_loss: 1.1462 - val_mean_euclidean_error: 1.0148\n",
      "Epoch 149/1500\n",
      "29/29 [==============================] - 1s 16ms/step - loss: 0.9541 - mean_euclidean_error: 0.8420 - val_loss: 1.1111 - val_mean_euclidean_error: 0.9344\n",
      "Epoch 150/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.9368 - mean_euclidean_error: 0.8052 - val_loss: 1.1113 - val_mean_euclidean_error: 0.9076\n",
      "Epoch 151/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9316 - mean_euclidean_error: 0.8166 - val_loss: 1.1178 - val_mean_euclidean_error: 0.9179\n",
      "Epoch 152/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.9347 - mean_euclidean_error: 0.7975 - val_loss: 1.1376 - val_mean_euclidean_error: 0.9314\n",
      "Epoch 153/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9211 - mean_euclidean_error: 0.7907 - val_loss: 1.1314 - val_mean_euclidean_error: 0.9628\n",
      "Epoch 154/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.9347 - mean_euclidean_error: 0.8067 - val_loss: 1.1021 - val_mean_euclidean_error: 0.9680\n",
      "Epoch 155/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9125 - mean_euclidean_error: 0.7895 - val_loss: 1.1037 - val_mean_euclidean_error: 0.8868\n",
      "Epoch 156/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.9151 - mean_euclidean_error: 0.7801 - val_loss: 1.1034 - val_mean_euclidean_error: 0.9378\n",
      "Epoch 157/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.9081 - mean_euclidean_error: 0.7890 - val_loss: 1.1292 - val_mean_euclidean_error: 0.9510\n",
      "Epoch 158/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9193 - mean_euclidean_error: 0.7953 - val_loss: 1.1650 - val_mean_euclidean_error: 1.0199\n",
      "Epoch 159/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9089 - mean_euclidean_error: 0.7816 - val_loss: 1.1234 - val_mean_euclidean_error: 0.9486\n",
      "Epoch 160/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.9042 - mean_euclidean_error: 0.7723 - val_loss: 1.1330 - val_mean_euclidean_error: 0.9921\n",
      "Epoch 161/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.9085 - mean_euclidean_error: 0.7852 - val_loss: 1.0992 - val_mean_euclidean_error: 0.8852\n",
      "Epoch 162/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.9150 - mean_euclidean_error: 0.7944 - val_loss: 1.0978 - val_mean_euclidean_error: 0.8981\n",
      "Epoch 163/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8970 - mean_euclidean_error: 0.7759 - val_loss: 1.1607 - val_mean_euclidean_error: 1.0038\n",
      "Epoch 164/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.9183 - mean_euclidean_error: 0.8182 - val_loss: 1.1148 - val_mean_euclidean_error: 0.9426\n",
      "Epoch 165/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8901 - mean_euclidean_error: 0.7697 - val_loss: 1.1081 - val_mean_euclidean_error: 0.9075\n",
      "Epoch 166/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.8957 - mean_euclidean_error: 0.7818 - val_loss: 1.1396 - val_mean_euclidean_error: 0.9363\n",
      "Epoch 167/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8962 - mean_euclidean_error: 0.7791 - val_loss: 1.1118 - val_mean_euclidean_error: 0.9117\n",
      "Epoch 168/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8738 - mean_euclidean_error: 0.7431 - val_loss: 1.1308 - val_mean_euclidean_error: 0.9859\n",
      "Epoch 169/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8807 - mean_euclidean_error: 0.7607 - val_loss: 1.0981 - val_mean_euclidean_error: 0.9288\n",
      "Epoch 170/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8723 - mean_euclidean_error: 0.7392 - val_loss: 1.1250 - val_mean_euclidean_error: 0.9527\n",
      "Epoch 171/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.8826 - mean_euclidean_error: 0.7794 - val_loss: 1.1028 - val_mean_euclidean_error: 0.8919\n",
      "Epoch 172/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8840 - mean_euclidean_error: 0.7613 - val_loss: 1.0956 - val_mean_euclidean_error: 0.8911\n",
      "Epoch 173/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8646 - mean_euclidean_error: 0.7313 - val_loss: 1.0898 - val_mean_euclidean_error: 0.9251\n",
      "Epoch 174/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8620 - mean_euclidean_error: 0.7247 - val_loss: 1.0973 - val_mean_euclidean_error: 0.8971\n",
      "Epoch 175/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8552 - mean_euclidean_error: 0.7241 - val_loss: 1.1003 - val_mean_euclidean_error: 0.9158\n",
      "Epoch 176/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8647 - mean_euclidean_error: 0.7486 - val_loss: 1.1147 - val_mean_euclidean_error: 0.9291\n",
      "Epoch 177/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8722 - mean_euclidean_error: 0.7523 - val_loss: 1.0922 - val_mean_euclidean_error: 0.8373\n",
      "Epoch 178/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8861 - mean_euclidean_error: 0.7773 - val_loss: 1.0907 - val_mean_euclidean_error: 0.9359\n",
      "Epoch 179/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8599 - mean_euclidean_error: 0.7353 - val_loss: 1.0969 - val_mean_euclidean_error: 0.9788\n",
      "Epoch 180/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.8596 - mean_euclidean_error: 0.7625 - val_loss: 1.0956 - val_mean_euclidean_error: 0.9443\n",
      "Epoch 181/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8734 - mean_euclidean_error: 0.7715 - val_loss: 1.1000 - val_mean_euclidean_error: 1.0257\n",
      "Epoch 182/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8540 - mean_euclidean_error: 0.7289 - val_loss: 1.0415 - val_mean_euclidean_error: 0.8579\n",
      "Epoch 183/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8515 - mean_euclidean_error: 0.7284 - val_loss: 1.0584 - val_mean_euclidean_error: 0.8811\n",
      "Epoch 184/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8486 - mean_euclidean_error: 0.7251 - val_loss: 1.0949 - val_mean_euclidean_error: 0.9174\n",
      "Epoch 185/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8474 - mean_euclidean_error: 0.7221 - val_loss: 1.0828 - val_mean_euclidean_error: 0.8947\n",
      "Epoch 186/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8477 - mean_euclidean_error: 0.7325 - val_loss: 1.0703 - val_mean_euclidean_error: 0.8961\n",
      "Epoch 187/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8547 - mean_euclidean_error: 0.7374 - val_loss: 1.0747 - val_mean_euclidean_error: 0.8914\n",
      "Epoch 188/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8498 - mean_euclidean_error: 0.7498 - val_loss: 1.0985 - val_mean_euclidean_error: 0.9483\n",
      "Epoch 189/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8449 - mean_euclidean_error: 0.7374 - val_loss: 1.0629 - val_mean_euclidean_error: 0.8591\n",
      "Epoch 190/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8429 - mean_euclidean_error: 0.7352 - val_loss: 1.0904 - val_mean_euclidean_error: 0.9445\n",
      "Epoch 191/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8505 - mean_euclidean_error: 0.7472 - val_loss: 1.0872 - val_mean_euclidean_error: 0.9064\n",
      "Epoch 192/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8459 - mean_euclidean_error: 0.7296 - val_loss: 1.0554 - val_mean_euclidean_error: 0.8251\n",
      "Epoch 193/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.8320 - mean_euclidean_error: 0.7181 - val_loss: 1.1001 - val_mean_euclidean_error: 0.9655\n",
      "Epoch 194/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8466 - mean_euclidean_error: 0.7376 - val_loss: 1.0904 - val_mean_euclidean_error: 0.8782\n",
      "Epoch 195/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8381 - mean_euclidean_error: 0.7107 - val_loss: 1.0444 - val_mean_euclidean_error: 0.8694\n",
      "Epoch 196/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8288 - mean_euclidean_error: 0.7029 - val_loss: 1.0644 - val_mean_euclidean_error: 0.9369\n",
      "Epoch 197/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8202 - mean_euclidean_error: 0.6880 - val_loss: 1.0683 - val_mean_euclidean_error: 0.9156\n",
      "Epoch 198/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8229 - mean_euclidean_error: 0.6872 - val_loss: 1.0689 - val_mean_euclidean_error: 0.9235\n",
      "Epoch 199/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8177 - mean_euclidean_error: 0.6972 - val_loss: 1.0623 - val_mean_euclidean_error: 0.9400\n",
      "Epoch 200/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8236 - mean_euclidean_error: 0.7120 - val_loss: 1.0387 - val_mean_euclidean_error: 0.8613\n",
      "Epoch 201/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.8186 - mean_euclidean_error: 0.7030 - val_loss: 1.0740 - val_mean_euclidean_error: 0.8394\n",
      "Epoch 202/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.8202 - mean_euclidean_error: 0.6927 - val_loss: 1.1145 - val_mean_euclidean_error: 0.9352\n",
      "Epoch 203/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.8158 - mean_euclidean_error: 0.6891 - val_loss: 1.0509 - val_mean_euclidean_error: 0.8557\n",
      "Epoch 204/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8111 - mean_euclidean_error: 0.6891 - val_loss: 1.0893 - val_mean_euclidean_error: 0.9676\n",
      "Epoch 205/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8218 - mean_euclidean_error: 0.6968 - val_loss: 1.0911 - val_mean_euclidean_error: 0.9855\n",
      "Epoch 206/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8112 - mean_euclidean_error: 0.6860 - val_loss: 1.0550 - val_mean_euclidean_error: 0.8573\n",
      "Epoch 207/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.8211 - mean_euclidean_error: 0.7043 - val_loss: 1.0828 - val_mean_euclidean_error: 0.8695\n",
      "Epoch 208/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.8152 - mean_euclidean_error: 0.6926 - val_loss: 1.0804 - val_mean_euclidean_error: 0.9039\n",
      "Epoch 209/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8060 - mean_euclidean_error: 0.6760 - val_loss: 1.0838 - val_mean_euclidean_error: 0.8625\n",
      "Epoch 210/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.8057 - mean_euclidean_error: 0.6791 - val_loss: 1.0746 - val_mean_euclidean_error: 0.9408\n",
      "Epoch 211/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.8035 - mean_euclidean_error: 0.6896 - val_loss: 1.0610 - val_mean_euclidean_error: 0.8772\n",
      "Epoch 212/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.8082 - mean_euclidean_error: 0.6905 - val_loss: 1.0666 - val_mean_euclidean_error: 0.9498\n",
      "Epoch 213/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.8205 - mean_euclidean_error: 0.7103 - val_loss: 1.0973 - val_mean_euclidean_error: 0.9704\n",
      "Epoch 214/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8238 - mean_euclidean_error: 0.7243 - val_loss: 1.0475 - val_mean_euclidean_error: 0.8839\n",
      "Epoch 215/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.8033 - mean_euclidean_error: 0.6882 - val_loss: 1.0538 - val_mean_euclidean_error: 0.9303\n",
      "Epoch 216/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.7935 - mean_euclidean_error: 0.6605 - val_loss: 1.0485 - val_mean_euclidean_error: 0.9102\n",
      "Epoch 217/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7882 - mean_euclidean_error: 0.6477 - val_loss: 1.0621 - val_mean_euclidean_error: 0.8779\n",
      "Epoch 218/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.8165 - mean_euclidean_error: 0.7108 - val_loss: 1.0638 - val_mean_euclidean_error: 0.9059\n",
      "Epoch 219/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.7973 - mean_euclidean_error: 0.6753 - val_loss: 1.0834 - val_mean_euclidean_error: 0.8532\n",
      "Epoch 220/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7982 - mean_euclidean_error: 0.6790 - val_loss: 1.0357 - val_mean_euclidean_error: 0.8565\n",
      "Epoch 221/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7875 - mean_euclidean_error: 0.6541 - val_loss: 1.0943 - val_mean_euclidean_error: 0.9498\n",
      "Epoch 222/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7910 - mean_euclidean_error: 0.6613 - val_loss: 1.0466 - val_mean_euclidean_error: 0.8510\n",
      "Epoch 223/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7901 - mean_euclidean_error: 0.6715 - val_loss: 1.0345 - val_mean_euclidean_error: 0.8106\n",
      "Epoch 224/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7916 - mean_euclidean_error: 0.6678 - val_loss: 1.0682 - val_mean_euclidean_error: 0.8810\n",
      "Epoch 225/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7901 - mean_euclidean_error: 0.6708 - val_loss: 1.0353 - val_mean_euclidean_error: 0.8603\n",
      "Epoch 226/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7973 - mean_euclidean_error: 0.6925 - val_loss: 1.0367 - val_mean_euclidean_error: 0.8516\n",
      "Epoch 227/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7903 - mean_euclidean_error: 0.6684 - val_loss: 1.0512 - val_mean_euclidean_error: 0.8526\n",
      "Epoch 228/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7903 - mean_euclidean_error: 0.6807 - val_loss: 1.0415 - val_mean_euclidean_error: 0.9153\n",
      "Epoch 229/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7864 - mean_euclidean_error: 0.6803 - val_loss: 1.0519 - val_mean_euclidean_error: 0.8554\n",
      "Epoch 230/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7965 - mean_euclidean_error: 0.6725 - val_loss: 1.0117 - val_mean_euclidean_error: 0.8316\n",
      "Epoch 231/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7758 - mean_euclidean_error: 0.6433 - val_loss: 1.0237 - val_mean_euclidean_error: 0.9011\n",
      "Epoch 232/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7702 - mean_euclidean_error: 0.6352 - val_loss: 1.0360 - val_mean_euclidean_error: 0.8687\n",
      "Epoch 233/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7694 - mean_euclidean_error: 0.6661 - val_loss: 1.0584 - val_mean_euclidean_error: 0.8888\n",
      "Epoch 234/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7783 - mean_euclidean_error: 0.6527 - val_loss: 1.0690 - val_mean_euclidean_error: 0.8344\n",
      "Epoch 235/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7707 - mean_euclidean_error: 0.6488 - val_loss: 1.0607 - val_mean_euclidean_error: 0.8725\n",
      "Epoch 236/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7733 - mean_euclidean_error: 0.6478 - val_loss: 1.0732 - val_mean_euclidean_error: 0.9625\n",
      "Epoch 237/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.7765 - mean_euclidean_error: 0.6570 - val_loss: 1.0277 - val_mean_euclidean_error: 0.8547\n",
      "Epoch 238/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7684 - mean_euclidean_error: 0.6431 - val_loss: 1.0366 - val_mean_euclidean_error: 0.8348\n",
      "Epoch 239/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7734 - mean_euclidean_error: 0.6485 - val_loss: 1.0270 - val_mean_euclidean_error: 0.8210\n",
      "Epoch 240/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7700 - mean_euclidean_error: 0.6379 - val_loss: 1.0680 - val_mean_euclidean_error: 0.8847\n",
      "Epoch 241/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7620 - mean_euclidean_error: 0.6302 - val_loss: 1.0602 - val_mean_euclidean_error: 0.9159\n",
      "Epoch 242/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7691 - mean_euclidean_error: 0.6544 - val_loss: 1.0692 - val_mean_euclidean_error: 0.9085\n",
      "Epoch 243/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7758 - mean_euclidean_error: 0.6521 - val_loss: 1.0479 - val_mean_euclidean_error: 0.8571\n",
      "Epoch 244/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7671 - mean_euclidean_error: 0.6515 - val_loss: 1.0243 - val_mean_euclidean_error: 0.8649\n",
      "Epoch 245/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7811 - mean_euclidean_error: 0.6758 - val_loss: 1.0359 - val_mean_euclidean_error: 0.9585\n",
      "Epoch 246/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7740 - mean_euclidean_error: 0.6571 - val_loss: 1.0378 - val_mean_euclidean_error: 0.9445\n",
      "Epoch 247/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7749 - mean_euclidean_error: 0.6485 - val_loss: 1.0037 - val_mean_euclidean_error: 0.8248\n",
      "Epoch 248/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7532 - mean_euclidean_error: 0.6230 - val_loss: 1.0396 - val_mean_euclidean_error: 0.8571\n",
      "Epoch 249/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7662 - mean_euclidean_error: 0.6708 - val_loss: 1.0499 - val_mean_euclidean_error: 0.8914\n",
      "Epoch 250/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7628 - mean_euclidean_error: 0.6347 - val_loss: 1.0654 - val_mean_euclidean_error: 0.8894\n",
      "Epoch 251/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7654 - mean_euclidean_error: 0.6482 - val_loss: 1.0258 - val_mean_euclidean_error: 0.8218\n",
      "Epoch 252/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7539 - mean_euclidean_error: 0.6256 - val_loss: 1.0552 - val_mean_euclidean_error: 0.8647\n",
      "Epoch 253/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7546 - mean_euclidean_error: 0.6253 - val_loss: 1.0583 - val_mean_euclidean_error: 0.8585\n",
      "Epoch 254/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7578 - mean_euclidean_error: 0.6322 - val_loss: 1.0547 - val_mean_euclidean_error: 0.9171\n",
      "Epoch 255/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7563 - mean_euclidean_error: 0.6300 - val_loss: 1.0402 - val_mean_euclidean_error: 0.8928\n",
      "Epoch 256/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7516 - mean_euclidean_error: 0.6211 - val_loss: 1.0329 - val_mean_euclidean_error: 0.8708\n",
      "Epoch 257/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7444 - mean_euclidean_error: 0.6198 - val_loss: 1.0307 - val_mean_euclidean_error: 0.8566\n",
      "Epoch 258/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7554 - mean_euclidean_error: 0.6383 - val_loss: 1.0315 - val_mean_euclidean_error: 0.9009\n",
      "Epoch 259/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7708 - mean_euclidean_error: 0.6648 - val_loss: 1.0317 - val_mean_euclidean_error: 0.9127\n",
      "Epoch 260/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7512 - mean_euclidean_error: 0.6305 - val_loss: 1.0090 - val_mean_euclidean_error: 0.8324\n",
      "Epoch 261/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7555 - mean_euclidean_error: 0.6313 - val_loss: 1.0033 - val_mean_euclidean_error: 0.8633\n",
      "Epoch 262/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7595 - mean_euclidean_error: 0.6330 - val_loss: 1.0175 - val_mean_euclidean_error: 0.8551\n",
      "Epoch 263/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7478 - mean_euclidean_error: 0.6243 - val_loss: 1.0318 - val_mean_euclidean_error: 0.9018\n",
      "Epoch 264/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7540 - mean_euclidean_error: 0.6272 - val_loss: 0.9907 - val_mean_euclidean_error: 0.8164\n",
      "Epoch 265/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.7424 - mean_euclidean_error: 0.6169 - val_loss: 1.0131 - val_mean_euclidean_error: 0.8324\n",
      "Epoch 266/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7451 - mean_euclidean_error: 0.6155 - val_loss: 1.0395 - val_mean_euclidean_error: 0.8563\n",
      "Epoch 267/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7496 - mean_euclidean_error: 0.6446 - val_loss: 1.0072 - val_mean_euclidean_error: 0.8402\n",
      "Epoch 268/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7564 - mean_euclidean_error: 0.6245 - val_loss: 1.0346 - val_mean_euclidean_error: 0.8580\n",
      "Epoch 269/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7391 - mean_euclidean_error: 0.5952 - val_loss: 1.0053 - val_mean_euclidean_error: 0.8430\n",
      "Epoch 270/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7445 - mean_euclidean_error: 0.6163 - val_loss: 1.0205 - val_mean_euclidean_error: 0.8281\n",
      "Epoch 271/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7407 - mean_euclidean_error: 0.6007 - val_loss: 1.0201 - val_mean_euclidean_error: 0.8532\n",
      "Epoch 272/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7398 - mean_euclidean_error: 0.6097 - val_loss: 1.0183 - val_mean_euclidean_error: 0.8030\n",
      "Epoch 273/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7381 - mean_euclidean_error: 0.6202 - val_loss: 1.0064 - val_mean_euclidean_error: 0.8286\n",
      "Epoch 274/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7473 - mean_euclidean_error: 0.6173 - val_loss: 1.0154 - val_mean_euclidean_error: 0.8263\n",
      "Epoch 275/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7494 - mean_euclidean_error: 0.6253 - val_loss: 1.0175 - val_mean_euclidean_error: 0.8261\n",
      "Epoch 276/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7382 - mean_euclidean_error: 0.6071 - val_loss: 1.0063 - val_mean_euclidean_error: 0.8517\n",
      "Epoch 277/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7356 - mean_euclidean_error: 0.6043 - val_loss: 1.0103 - val_mean_euclidean_error: 0.8914\n",
      "Epoch 278/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7395 - mean_euclidean_error: 0.6141 - val_loss: 1.0181 - val_mean_euclidean_error: 0.8657\n",
      "Epoch 279/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7340 - mean_euclidean_error: 0.6040 - val_loss: 1.0087 - val_mean_euclidean_error: 0.8453\n",
      "Epoch 280/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7405 - mean_euclidean_error: 0.6214 - val_loss: 1.0217 - val_mean_euclidean_error: 0.8753\n",
      "Epoch 281/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7334 - mean_euclidean_error: 0.5927 - val_loss: 0.9990 - val_mean_euclidean_error: 0.8797\n",
      "Epoch 282/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.7325 - mean_euclidean_error: 0.5957 - val_loss: 1.0021 - val_mean_euclidean_error: 0.8485\n",
      "Epoch 283/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7414 - mean_euclidean_error: 0.6112 - val_loss: 1.0561 - val_mean_euclidean_error: 0.9352\n",
      "Epoch 284/1500\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.7331 - mean_euclidean_error: 0.6101 - val_loss: 0.9872 - val_mean_euclidean_error: 0.8101\n",
      "Epoch 285/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7407 - mean_euclidean_error: 0.6086 - val_loss: 1.0266 - val_mean_euclidean_error: 0.7967\n",
      "Epoch 286/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7319 - mean_euclidean_error: 0.6047 - val_loss: 1.0104 - val_mean_euclidean_error: 0.8573\n",
      "Epoch 287/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7451 - mean_euclidean_error: 0.6199 - val_loss: 0.9842 - val_mean_euclidean_error: 0.8443\n",
      "Epoch 288/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7242 - mean_euclidean_error: 0.5833 - val_loss: 1.0202 - val_mean_euclidean_error: 0.8686\n",
      "Epoch 289/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7301 - mean_euclidean_error: 0.5943 - val_loss: 1.0134 - val_mean_euclidean_error: 0.8402\n",
      "Epoch 290/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7233 - mean_euclidean_error: 0.5855 - val_loss: 1.0245 - val_mean_euclidean_error: 0.8937\n",
      "Epoch 291/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7317 - mean_euclidean_error: 0.6190 - val_loss: 1.0091 - val_mean_euclidean_error: 0.9016\n",
      "Epoch 292/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.7351 - mean_euclidean_error: 0.6012 - val_loss: 1.0278 - val_mean_euclidean_error: 0.8586\n",
      "Epoch 293/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7386 - mean_euclidean_error: 0.6180 - val_loss: 1.0248 - val_mean_euclidean_error: 0.8596\n",
      "Epoch 294/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7247 - mean_euclidean_error: 0.5875 - val_loss: 0.9760 - val_mean_euclidean_error: 0.8293\n",
      "Epoch 295/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7300 - mean_euclidean_error: 0.5949 - val_loss: 0.9984 - val_mean_euclidean_error: 0.8048\n",
      "Epoch 296/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7204 - mean_euclidean_error: 0.5746 - val_loss: 0.9992 - val_mean_euclidean_error: 0.8314\n",
      "Epoch 297/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.7272 - mean_euclidean_error: 0.5969 - val_loss: 0.9848 - val_mean_euclidean_error: 0.8419\n",
      "Epoch 298/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7302 - mean_euclidean_error: 0.5989 - val_loss: 1.0042 - val_mean_euclidean_error: 0.8738\n",
      "Epoch 299/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7265 - mean_euclidean_error: 0.6045 - val_loss: 0.9839 - val_mean_euclidean_error: 0.8268\n",
      "Epoch 300/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7325 - mean_euclidean_error: 0.6111 - val_loss: 0.9982 - val_mean_euclidean_error: 0.8336\n",
      "Epoch 301/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7257 - mean_euclidean_error: 0.6040 - val_loss: 1.0375 - val_mean_euclidean_error: 0.8188\n",
      "Epoch 302/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7273 - mean_euclidean_error: 0.5948 - val_loss: 1.0006 - val_mean_euclidean_error: 0.8554\n",
      "Epoch 303/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7362 - mean_euclidean_error: 0.6158 - val_loss: 0.9833 - val_mean_euclidean_error: 0.7670\n",
      "Epoch 304/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7106 - mean_euclidean_error: 0.5717 - val_loss: 1.0247 - val_mean_euclidean_error: 0.8668\n",
      "Epoch 305/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7233 - mean_euclidean_error: 0.5906 - val_loss: 0.9949 - val_mean_euclidean_error: 0.7977\n",
      "Epoch 306/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7244 - mean_euclidean_error: 0.5948 - val_loss: 1.0022 - val_mean_euclidean_error: 0.8078\n",
      "Epoch 307/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7282 - mean_euclidean_error: 0.6042 - val_loss: 0.9740 - val_mean_euclidean_error: 0.7631\n",
      "Epoch 308/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7238 - mean_euclidean_error: 0.5991 - val_loss: 1.0117 - val_mean_euclidean_error: 0.7759\n",
      "Epoch 309/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7316 - mean_euclidean_error: 0.6067 - val_loss: 0.9896 - val_mean_euclidean_error: 0.7881\n",
      "Epoch 310/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7203 - mean_euclidean_error: 0.5807 - val_loss: 1.0022 - val_mean_euclidean_error: 0.7762\n",
      "Epoch 311/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7136 - mean_euclidean_error: 0.5774 - val_loss: 1.0051 - val_mean_euclidean_error: 0.7967\n",
      "Epoch 312/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7211 - mean_euclidean_error: 0.5941 - val_loss: 0.9911 - val_mean_euclidean_error: 0.7918\n",
      "Epoch 313/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7199 - mean_euclidean_error: 0.5928 - val_loss: 0.9960 - val_mean_euclidean_error: 0.8043\n",
      "Epoch 314/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7265 - mean_euclidean_error: 0.6041 - val_loss: 0.9869 - val_mean_euclidean_error: 0.8233\n",
      "Epoch 315/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7140 - mean_euclidean_error: 0.5774 - val_loss: 0.9862 - val_mean_euclidean_error: 0.8299\n",
      "Epoch 316/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7125 - mean_euclidean_error: 0.5741 - val_loss: 0.9961 - val_mean_euclidean_error: 0.8094\n",
      "Epoch 317/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7110 - mean_euclidean_error: 0.5656 - val_loss: 0.9895 - val_mean_euclidean_error: 0.8543\n",
      "Epoch 318/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7082 - mean_euclidean_error: 0.5798 - val_loss: 0.9845 - val_mean_euclidean_error: 0.8069\n",
      "Epoch 319/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7118 - mean_euclidean_error: 0.5735 - val_loss: 0.9663 - val_mean_euclidean_error: 0.7983\n",
      "Epoch 320/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7107 - mean_euclidean_error: 0.5776 - val_loss: 0.9798 - val_mean_euclidean_error: 0.7846\n",
      "Epoch 321/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7137 - mean_euclidean_error: 0.5851 - val_loss: 1.0106 - val_mean_euclidean_error: 0.8985\n",
      "Epoch 322/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7128 - mean_euclidean_error: 0.5723 - val_loss: 1.0056 - val_mean_euclidean_error: 0.8386\n",
      "Epoch 323/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7045 - mean_euclidean_error: 0.5597 - val_loss: 0.9964 - val_mean_euclidean_error: 0.8576\n",
      "Epoch 324/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7053 - mean_euclidean_error: 0.5611 - val_loss: 0.9768 - val_mean_euclidean_error: 0.8139\n",
      "Epoch 325/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7098 - mean_euclidean_error: 0.5714 - val_loss: 0.9937 - val_mean_euclidean_error: 0.8106\n",
      "Epoch 326/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7153 - mean_euclidean_error: 0.6163 - val_loss: 0.9749 - val_mean_euclidean_error: 0.8089\n",
      "Epoch 327/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7346 - mean_euclidean_error: 0.6175 - val_loss: 0.9839 - val_mean_euclidean_error: 0.7996\n",
      "Epoch 328/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7144 - mean_euclidean_error: 0.5859 - val_loss: 0.9600 - val_mean_euclidean_error: 0.7925\n",
      "Epoch 329/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7080 - mean_euclidean_error: 0.5672 - val_loss: 0.9796 - val_mean_euclidean_error: 0.7762\n",
      "Epoch 330/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7012 - mean_euclidean_error: 0.5559 - val_loss: 0.9765 - val_mean_euclidean_error: 0.7692\n",
      "Epoch 331/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7116 - mean_euclidean_error: 0.5783 - val_loss: 0.9818 - val_mean_euclidean_error: 0.7873\n",
      "Epoch 332/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7119 - mean_euclidean_error: 0.5803 - val_loss: 0.9608 - val_mean_euclidean_error: 0.7668\n",
      "Epoch 333/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7093 - mean_euclidean_error: 0.5718 - val_loss: 0.9938 - val_mean_euclidean_error: 0.7818\n",
      "Epoch 334/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7084 - mean_euclidean_error: 0.5719 - val_loss: 0.9606 - val_mean_euclidean_error: 0.7880\n",
      "Epoch 335/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7135 - mean_euclidean_error: 0.5950 - val_loss: 0.9680 - val_mean_euclidean_error: 0.8162\n",
      "Epoch 336/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7151 - mean_euclidean_error: 0.5889 - val_loss: 1.0076 - val_mean_euclidean_error: 0.8194\n",
      "Epoch 337/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7018 - mean_euclidean_error: 0.5590 - val_loss: 0.9792 - val_mean_euclidean_error: 0.8001\n",
      "Epoch 338/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7084 - mean_euclidean_error: 0.5765 - val_loss: 0.9723 - val_mean_euclidean_error: 0.7931\n",
      "Epoch 339/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7038 - mean_euclidean_error: 0.5611 - val_loss: 0.9775 - val_mean_euclidean_error: 0.7912\n",
      "Epoch 340/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6998 - mean_euclidean_error: 0.5517 - val_loss: 0.9984 - val_mean_euclidean_error: 0.8304\n",
      "Epoch 341/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7073 - mean_euclidean_error: 0.5670 - val_loss: 0.9658 - val_mean_euclidean_error: 0.7919\n",
      "Epoch 342/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.7038 - mean_euclidean_error: 0.5652 - val_loss: 0.9919 - val_mean_euclidean_error: 0.8612\n",
      "Epoch 343/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7092 - mean_euclidean_error: 0.5798 - val_loss: 0.9505 - val_mean_euclidean_error: 0.7919\n",
      "Epoch 344/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.7028 - mean_euclidean_error: 0.5613 - val_loss: 0.9818 - val_mean_euclidean_error: 0.7906\n",
      "Epoch 345/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6981 - mean_euclidean_error: 0.5514 - val_loss: 0.9480 - val_mean_euclidean_error: 0.7541\n",
      "Epoch 346/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7007 - mean_euclidean_error: 0.5661 - val_loss: 1.0083 - val_mean_euclidean_error: 0.8432\n",
      "Epoch 347/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7111 - mean_euclidean_error: 0.5840 - val_loss: 0.9633 - val_mean_euclidean_error: 0.7561\n",
      "Epoch 348/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6947 - mean_euclidean_error: 0.5430 - val_loss: 1.0150 - val_mean_euclidean_error: 0.8469\n",
      "Epoch 349/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6969 - mean_euclidean_error: 0.5544 - val_loss: 1.0011 - val_mean_euclidean_error: 0.8272\n",
      "Epoch 350/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7062 - mean_euclidean_error: 0.5761 - val_loss: 0.9914 - val_mean_euclidean_error: 0.8018\n",
      "Epoch 351/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7117 - mean_euclidean_error: 0.5958 - val_loss: 0.9763 - val_mean_euclidean_error: 0.8165\n",
      "Epoch 352/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6949 - mean_euclidean_error: 0.5529 - val_loss: 0.9805 - val_mean_euclidean_error: 0.7483\n",
      "Epoch 353/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7012 - mean_euclidean_error: 0.5678 - val_loss: 0.9616 - val_mean_euclidean_error: 0.7906\n",
      "Epoch 354/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6979 - mean_euclidean_error: 0.5678 - val_loss: 0.9673 - val_mean_euclidean_error: 0.7855\n",
      "Epoch 355/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.7061 - mean_euclidean_error: 0.5740 - val_loss: 0.9820 - val_mean_euclidean_error: 0.8083\n",
      "Epoch 356/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6978 - mean_euclidean_error: 0.5563 - val_loss: 0.9561 - val_mean_euclidean_error: 0.7381\n",
      "Epoch 357/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6926 - mean_euclidean_error: 0.5416 - val_loss: 0.9539 - val_mean_euclidean_error: 0.7833\n",
      "Epoch 358/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6861 - mean_euclidean_error: 0.5317 - val_loss: 0.9700 - val_mean_euclidean_error: 0.7962\n",
      "Epoch 359/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7029 - mean_euclidean_error: 0.5748 - val_loss: 0.9850 - val_mean_euclidean_error: 0.8536\n",
      "Epoch 360/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7043 - mean_euclidean_error: 0.5774 - val_loss: 0.9689 - val_mean_euclidean_error: 0.7598\n",
      "Epoch 361/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.7130 - mean_euclidean_error: 0.5855 - val_loss: 0.9881 - val_mean_euclidean_error: 0.8264\n",
      "Epoch 362/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6916 - mean_euclidean_error: 0.5573 - val_loss: 0.9730 - val_mean_euclidean_error: 0.7808\n",
      "Epoch 363/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6920 - mean_euclidean_error: 0.5584 - val_loss: 0.9830 - val_mean_euclidean_error: 0.8202\n",
      "Epoch 364/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7002 - mean_euclidean_error: 0.5787 - val_loss: 0.9692 - val_mean_euclidean_error: 0.7915\n",
      "Epoch 365/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.7105 - mean_euclidean_error: 0.5809 - val_loss: 0.9819 - val_mean_euclidean_error: 0.8582\n",
      "Epoch 366/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6913 - mean_euclidean_error: 0.5634 - val_loss: 0.9494 - val_mean_euclidean_error: 0.7817\n",
      "Epoch 367/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6999 - mean_euclidean_error: 0.5729 - val_loss: 0.9969 - val_mean_euclidean_error: 0.8105\n",
      "Epoch 368/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6967 - mean_euclidean_error: 0.5761 - val_loss: 0.9883 - val_mean_euclidean_error: 0.8034\n",
      "Epoch 369/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.7057 - mean_euclidean_error: 0.5862 - val_loss: 0.9876 - val_mean_euclidean_error: 0.7711\n",
      "Epoch 370/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6887 - mean_euclidean_error: 0.5505 - val_loss: 0.9577 - val_mean_euclidean_error: 0.7478\n",
      "Epoch 371/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6900 - mean_euclidean_error: 0.5468 - val_loss: 0.9832 - val_mean_euclidean_error: 0.7883\n",
      "Epoch 372/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6954 - mean_euclidean_error: 0.5576 - val_loss: 0.9777 - val_mean_euclidean_error: 0.7813\n",
      "Epoch 373/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6944 - mean_euclidean_error: 0.5652 - val_loss: 0.9587 - val_mean_euclidean_error: 0.7510\n",
      "Epoch 374/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6905 - mean_euclidean_error: 0.5448 - val_loss: 0.9910 - val_mean_euclidean_error: 0.7836\n",
      "Epoch 375/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6885 - mean_euclidean_error: 0.5438 - val_loss: 0.9764 - val_mean_euclidean_error: 0.8118\n",
      "Epoch 376/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6903 - mean_euclidean_error: 0.5584 - val_loss: 0.9839 - val_mean_euclidean_error: 0.8454\n",
      "Epoch 377/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6868 - mean_euclidean_error: 0.5461 - val_loss: 0.9949 - val_mean_euclidean_error: 0.8198\n",
      "Epoch 378/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6964 - mean_euclidean_error: 0.5654 - val_loss: 0.9908 - val_mean_euclidean_error: 0.8156\n",
      "Epoch 379/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6967 - mean_euclidean_error: 0.5594 - val_loss: 0.9436 - val_mean_euclidean_error: 0.7667\n",
      "Epoch 380/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6870 - mean_euclidean_error: 0.5431 - val_loss: 0.9652 - val_mean_euclidean_error: 0.7889\n",
      "Epoch 381/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6897 - mean_euclidean_error: 0.5552 - val_loss: 0.9444 - val_mean_euclidean_error: 0.7580\n",
      "Epoch 382/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6939 - mean_euclidean_error: 0.5852 - val_loss: 0.9746 - val_mean_euclidean_error: 0.8044\n",
      "Epoch 383/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.7026 - mean_euclidean_error: 0.5767 - val_loss: 0.9776 - val_mean_euclidean_error: 0.7504\n",
      "Epoch 384/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6824 - mean_euclidean_error: 0.5378 - val_loss: 1.0055 - val_mean_euclidean_error: 0.8654\n",
      "Epoch 385/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6836 - mean_euclidean_error: 0.5437 - val_loss: 0.9909 - val_mean_euclidean_error: 0.8798\n",
      "Epoch 386/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6859 - mean_euclidean_error: 0.5486 - val_loss: 0.9689 - val_mean_euclidean_error: 0.7533\n",
      "Epoch 387/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6933 - mean_euclidean_error: 0.5662 - val_loss: 0.9620 - val_mean_euclidean_error: 0.7662\n",
      "Epoch 388/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6841 - mean_euclidean_error: 0.5460 - val_loss: 0.9546 - val_mean_euclidean_error: 0.7858\n",
      "Epoch 389/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6835 - mean_euclidean_error: 0.5350 - val_loss: 0.9558 - val_mean_euclidean_error: 0.7796\n",
      "Epoch 390/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6795 - mean_euclidean_error: 0.5319 - val_loss: 0.9346 - val_mean_euclidean_error: 0.7636\n",
      "Epoch 391/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6919 - mean_euclidean_error: 0.5655 - val_loss: 0.9499 - val_mean_euclidean_error: 0.7742\n",
      "Epoch 392/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.7026 - mean_euclidean_error: 0.5763 - val_loss: 0.9601 - val_mean_euclidean_error: 0.7876\n",
      "Epoch 393/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6804 - mean_euclidean_error: 0.5314 - val_loss: 0.9722 - val_mean_euclidean_error: 0.8179\n",
      "Epoch 394/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.6925 - mean_euclidean_error: 0.5656 - val_loss: 0.9575 - val_mean_euclidean_error: 0.7632\n",
      "Epoch 395/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6859 - mean_euclidean_error: 0.5571 - val_loss: 0.9729 - val_mean_euclidean_error: 0.7633\n",
      "Epoch 396/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6810 - mean_euclidean_error: 0.5339 - val_loss: 0.9480 - val_mean_euclidean_error: 0.7606\n",
      "Epoch 397/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6785 - mean_euclidean_error: 0.5223 - val_loss: 0.9747 - val_mean_euclidean_error: 0.7920\n",
      "Epoch 398/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6757 - mean_euclidean_error: 0.5278 - val_loss: 0.9513 - val_mean_euclidean_error: 0.7772\n",
      "Epoch 399/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6799 - mean_euclidean_error: 0.5335 - val_loss: 0.9467 - val_mean_euclidean_error: 0.7425\n",
      "Epoch 400/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6812 - mean_euclidean_error: 0.5381 - val_loss: 0.9498 - val_mean_euclidean_error: 0.7594\n",
      "Epoch 401/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6798 - mean_euclidean_error: 0.5381 - val_loss: 0.9621 - val_mean_euclidean_error: 0.7966\n",
      "Epoch 402/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6854 - mean_euclidean_error: 0.5466 - val_loss: 0.9458 - val_mean_euclidean_error: 0.7803\n",
      "Epoch 403/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.6791 - mean_euclidean_error: 0.5356 - val_loss: 0.9490 - val_mean_euclidean_error: 0.7769\n",
      "Epoch 404/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6846 - mean_euclidean_error: 0.5450 - val_loss: 1.0102 - val_mean_euclidean_error: 0.8693\n",
      "Epoch 405/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6874 - mean_euclidean_error: 0.5539 - val_loss: 0.9554 - val_mean_euclidean_error: 0.7662\n",
      "Epoch 406/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.6740 - mean_euclidean_error: 0.5268 - val_loss: 0.9324 - val_mean_euclidean_error: 0.7666\n",
      "Epoch 407/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6779 - mean_euclidean_error: 0.5411 - val_loss: 0.9491 - val_mean_euclidean_error: 0.7546\n",
      "Epoch 408/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6775 - mean_euclidean_error: 0.5264 - val_loss: 0.9571 - val_mean_euclidean_error: 0.7991\n",
      "Epoch 409/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6723 - mean_euclidean_error: 0.5287 - val_loss: 0.9494 - val_mean_euclidean_error: 0.7632\n",
      "Epoch 410/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6767 - mean_euclidean_error: 0.5308 - val_loss: 0.9638 - val_mean_euclidean_error: 0.7696\n",
      "Epoch 411/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6837 - mean_euclidean_error: 0.5459 - val_loss: 0.9478 - val_mean_euclidean_error: 0.7311\n",
      "Epoch 412/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6747 - mean_euclidean_error: 0.5216 - val_loss: 0.9436 - val_mean_euclidean_error: 0.7530\n",
      "Epoch 413/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6756 - mean_euclidean_error: 0.5377 - val_loss: 0.9521 - val_mean_euclidean_error: 0.7400\n",
      "Epoch 414/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6816 - mean_euclidean_error: 0.5479 - val_loss: 0.9315 - val_mean_euclidean_error: 0.7518\n",
      "Epoch 415/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6801 - mean_euclidean_error: 0.5427 - val_loss: 1.0030 - val_mean_euclidean_error: 0.8472\n",
      "Epoch 416/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6823 - mean_euclidean_error: 0.5641 - val_loss: 0.9270 - val_mean_euclidean_error: 0.7473\n",
      "Epoch 417/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6871 - mean_euclidean_error: 0.5603 - val_loss: 0.9355 - val_mean_euclidean_error: 0.7787\n",
      "Epoch 418/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6811 - mean_euclidean_error: 0.5532 - val_loss: 0.9444 - val_mean_euclidean_error: 0.7282\n",
      "Epoch 419/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6811 - mean_euclidean_error: 0.5488 - val_loss: 0.9543 - val_mean_euclidean_error: 0.8161\n",
      "Epoch 420/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6767 - mean_euclidean_error: 0.5365 - val_loss: 0.9424 - val_mean_euclidean_error: 0.7741\n",
      "Epoch 421/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6831 - mean_euclidean_error: 0.5621 - val_loss: 0.9775 - val_mean_euclidean_error: 0.8057\n",
      "Epoch 422/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6857 - mean_euclidean_error: 0.5646 - val_loss: 0.9580 - val_mean_euclidean_error: 0.7892\n",
      "Epoch 423/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6806 - mean_euclidean_error: 0.5491 - val_loss: 0.9391 - val_mean_euclidean_error: 0.7310\n",
      "Epoch 424/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6759 - mean_euclidean_error: 0.5361 - val_loss: 0.9441 - val_mean_euclidean_error: 0.8077\n",
      "Epoch 425/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6676 - mean_euclidean_error: 0.5105 - val_loss: 0.9680 - val_mean_euclidean_error: 0.7527\n",
      "Epoch 426/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6685 - mean_euclidean_error: 0.5250 - val_loss: 0.9425 - val_mean_euclidean_error: 0.7735\n",
      "Epoch 427/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6755 - mean_euclidean_error: 0.5351 - val_loss: 0.9495 - val_mean_euclidean_error: 0.7430\n",
      "Epoch 428/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6723 - mean_euclidean_error: 0.5227 - val_loss: 0.9293 - val_mean_euclidean_error: 0.7071\n",
      "Epoch 429/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6707 - mean_euclidean_error: 0.5253 - val_loss: 0.9374 - val_mean_euclidean_error: 0.7233\n",
      "Epoch 430/1500\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.6724 - mean_euclidean_error: 0.5242 - val_loss: 0.9287 - val_mean_euclidean_error: 0.7587\n",
      "Epoch 431/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6747 - mean_euclidean_error: 0.5295 - val_loss: 0.9419 - val_mean_euclidean_error: 0.7470\n",
      "Epoch 432/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6650 - mean_euclidean_error: 0.5089 - val_loss: 0.9438 - val_mean_euclidean_error: 0.7033\n",
      "Epoch 433/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6669 - mean_euclidean_error: 0.5144 - val_loss: 0.9412 - val_mean_euclidean_error: 0.7249\n",
      "Epoch 434/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6742 - mean_euclidean_error: 0.5381 - val_loss: 0.9327 - val_mean_euclidean_error: 0.7108\n",
      "Epoch 435/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6694 - mean_euclidean_error: 0.5392 - val_loss: 0.9573 - val_mean_euclidean_error: 0.7464\n",
      "Epoch 436/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6767 - mean_euclidean_error: 0.5377 - val_loss: 0.9808 - val_mean_euclidean_error: 0.8360\n",
      "Epoch 437/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6680 - mean_euclidean_error: 0.5103 - val_loss: 0.9463 - val_mean_euclidean_error: 0.7457\n",
      "Epoch 438/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6664 - mean_euclidean_error: 0.5197 - val_loss: 0.9601 - val_mean_euclidean_error: 0.8152\n",
      "Epoch 439/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6847 - mean_euclidean_error: 0.5565 - val_loss: 0.9702 - val_mean_euclidean_error: 0.7598\n",
      "Epoch 440/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6751 - mean_euclidean_error: 0.5440 - val_loss: 0.9316 - val_mean_euclidean_error: 0.7229\n",
      "Epoch 441/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6811 - mean_euclidean_error: 0.5487 - val_loss: 0.9676 - val_mean_euclidean_error: 0.8447\n",
      "Epoch 442/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6727 - mean_euclidean_error: 0.5378 - val_loss: 0.9483 - val_mean_euclidean_error: 0.7976\n",
      "Epoch 443/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6660 - mean_euclidean_error: 0.5345 - val_loss: 0.9364 - val_mean_euclidean_error: 0.7606\n",
      "Epoch 444/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6718 - mean_euclidean_error: 0.5293 - val_loss: 0.9140 - val_mean_euclidean_error: 0.7280\n",
      "Epoch 445/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6732 - mean_euclidean_error: 0.5276 - val_loss: 0.9411 - val_mean_euclidean_error: 0.8169\n",
      "Epoch 446/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6747 - mean_euclidean_error: 0.5425 - val_loss: 0.9535 - val_mean_euclidean_error: 0.7946\n",
      "Epoch 447/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6754 - mean_euclidean_error: 0.5514 - val_loss: 0.9637 - val_mean_euclidean_error: 0.8846\n",
      "Epoch 448/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6771 - mean_euclidean_error: 0.5417 - val_loss: 0.9243 - val_mean_euclidean_error: 0.7970\n",
      "Epoch 449/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6647 - mean_euclidean_error: 0.5052 - val_loss: 0.9350 - val_mean_euclidean_error: 0.7817\n",
      "Epoch 450/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6600 - mean_euclidean_error: 0.5110 - val_loss: 0.9407 - val_mean_euclidean_error: 0.7565\n",
      "Epoch 451/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6723 - mean_euclidean_error: 0.5474 - val_loss: 0.9210 - val_mean_euclidean_error: 0.7243\n",
      "Epoch 452/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6685 - mean_euclidean_error: 0.5224 - val_loss: 0.9508 - val_mean_euclidean_error: 0.7454\n",
      "Epoch 453/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6754 - mean_euclidean_error: 0.5411 - val_loss: 0.9545 - val_mean_euclidean_error: 0.7598\n",
      "Epoch 454/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6648 - mean_euclidean_error: 0.5342 - val_loss: 0.9179 - val_mean_euclidean_error: 0.7270\n",
      "Epoch 455/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6787 - mean_euclidean_error: 0.5524 - val_loss: 0.9273 - val_mean_euclidean_error: 0.7388\n",
      "Epoch 456/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6625 - mean_euclidean_error: 0.5134 - val_loss: 0.9290 - val_mean_euclidean_error: 0.7321\n",
      "Epoch 457/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6603 - mean_euclidean_error: 0.5090 - val_loss: 0.9326 - val_mean_euclidean_error: 0.7395\n",
      "Epoch 458/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6604 - mean_euclidean_error: 0.5080 - val_loss: 0.9340 - val_mean_euclidean_error: 0.7307\n",
      "Epoch 459/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6685 - mean_euclidean_error: 0.5315 - val_loss: 0.9079 - val_mean_euclidean_error: 0.7169\n",
      "Epoch 460/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6685 - mean_euclidean_error: 0.5405 - val_loss: 0.9232 - val_mean_euclidean_error: 0.7601\n",
      "Epoch 461/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.7078 - mean_euclidean_error: 0.5944 - val_loss: 0.9760 - val_mean_euclidean_error: 0.8185\n",
      "Epoch 462/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6741 - mean_euclidean_error: 0.5402 - val_loss: 0.9263 - val_mean_euclidean_error: 0.7596\n",
      "Epoch 463/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6599 - mean_euclidean_error: 0.5107 - val_loss: 0.9373 - val_mean_euclidean_error: 0.7440\n",
      "Epoch 464/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6554 - mean_euclidean_error: 0.5018 - val_loss: 0.8900 - val_mean_euclidean_error: 0.7004\n",
      "Epoch 465/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6579 - mean_euclidean_error: 0.5036 - val_loss: 0.9562 - val_mean_euclidean_error: 0.7548\n",
      "Epoch 466/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6609 - mean_euclidean_error: 0.5079 - val_loss: 0.9371 - val_mean_euclidean_error: 0.7488\n",
      "Epoch 467/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6584 - mean_euclidean_error: 0.5143 - val_loss: 0.9424 - val_mean_euclidean_error: 0.7759\n",
      "Epoch 468/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6868 - mean_euclidean_error: 0.5640 - val_loss: 0.9395 - val_mean_euclidean_error: 0.7530\n",
      "Epoch 469/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.6603 - mean_euclidean_error: 0.5132 - val_loss: 0.9199 - val_mean_euclidean_error: 0.7327\n",
      "Epoch 470/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6588 - mean_euclidean_error: 0.5136 - val_loss: 0.9329 - val_mean_euclidean_error: 0.7209\n",
      "Epoch 471/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6684 - mean_euclidean_error: 0.5341 - val_loss: 0.9372 - val_mean_euclidean_error: 0.7103\n",
      "Epoch 472/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6579 - mean_euclidean_error: 0.5132 - val_loss: 0.9432 - val_mean_euclidean_error: 0.8082\n",
      "Epoch 473/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6653 - mean_euclidean_error: 0.5209 - val_loss: 0.9464 - val_mean_euclidean_error: 0.7723\n",
      "Epoch 474/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6700 - mean_euclidean_error: 0.5326 - val_loss: 0.9351 - val_mean_euclidean_error: 0.7645\n",
      "Epoch 475/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6632 - mean_euclidean_error: 0.5374 - val_loss: 0.9496 - val_mean_euclidean_error: 0.8601\n",
      "Epoch 476/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6860 - mean_euclidean_error: 0.5713 - val_loss: 0.9264 - val_mean_euclidean_error: 0.8018\n",
      "Epoch 477/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6589 - mean_euclidean_error: 0.5133 - val_loss: 0.9230 - val_mean_euclidean_error: 0.7354\n",
      "Epoch 478/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6688 - mean_euclidean_error: 0.5501 - val_loss: 0.9198 - val_mean_euclidean_error: 0.7438\n",
      "Epoch 479/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6643 - mean_euclidean_error: 0.5287 - val_loss: 0.9439 - val_mean_euclidean_error: 0.8250\n",
      "Epoch 480/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6658 - mean_euclidean_error: 0.5254 - val_loss: 0.9233 - val_mean_euclidean_error: 0.7537\n",
      "Epoch 481/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6546 - mean_euclidean_error: 0.5109 - val_loss: 0.9125 - val_mean_euclidean_error: 0.7389\n",
      "Epoch 482/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6568 - mean_euclidean_error: 0.5067 - val_loss: 0.9278 - val_mean_euclidean_error: 0.7525\n",
      "Epoch 483/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6636 - mean_euclidean_error: 0.5217 - val_loss: 0.9282 - val_mean_euclidean_error: 0.7066\n",
      "Epoch 484/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6573 - mean_euclidean_error: 0.5006 - val_loss: 0.9361 - val_mean_euclidean_error: 0.7234\n",
      "Epoch 485/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6529 - mean_euclidean_error: 0.4936 - val_loss: 0.9293 - val_mean_euclidean_error: 0.7059\n",
      "Epoch 486/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6648 - mean_euclidean_error: 0.5306 - val_loss: 0.9267 - val_mean_euclidean_error: 0.7118\n",
      "Epoch 487/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6540 - mean_euclidean_error: 0.4967 - val_loss: 0.9507 - val_mean_euclidean_error: 0.7777\n",
      "Epoch 488/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6569 - mean_euclidean_error: 0.5089 - val_loss: 0.9525 - val_mean_euclidean_error: 0.7524\n",
      "Epoch 489/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6543 - mean_euclidean_error: 0.5002 - val_loss: 0.9053 - val_mean_euclidean_error: 0.7208\n",
      "Epoch 490/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6574 - mean_euclidean_error: 0.5126 - val_loss: 0.9218 - val_mean_euclidean_error: 0.7425\n",
      "Epoch 491/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6702 - mean_euclidean_error: 0.5419 - val_loss: 0.9213 - val_mean_euclidean_error: 0.7576\n",
      "Epoch 492/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6589 - mean_euclidean_error: 0.5116 - val_loss: 0.8943 - val_mean_euclidean_error: 0.6858\n",
      "Epoch 493/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6594 - mean_euclidean_error: 0.5119 - val_loss: 0.9297 - val_mean_euclidean_error: 0.7323\n",
      "Epoch 494/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6535 - mean_euclidean_error: 0.4986 - val_loss: 0.9237 - val_mean_euclidean_error: 0.7320\n",
      "Epoch 495/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6570 - mean_euclidean_error: 0.5096 - val_loss: 0.9110 - val_mean_euclidean_error: 0.7118\n",
      "Epoch 496/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6546 - mean_euclidean_error: 0.5098 - val_loss: 0.9521 - val_mean_euclidean_error: 0.8015\n",
      "Epoch 497/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6621 - mean_euclidean_error: 0.5165 - val_loss: 0.9601 - val_mean_euclidean_error: 0.8044\n",
      "Epoch 498/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6637 - mean_euclidean_error: 0.5328 - val_loss: 0.9205 - val_mean_euclidean_error: 0.7347\n",
      "Epoch 499/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6465 - mean_euclidean_error: 0.4886 - val_loss: 0.9253 - val_mean_euclidean_error: 0.7724\n",
      "Epoch 500/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6546 - mean_euclidean_error: 0.4992 - val_loss: 0.9267 - val_mean_euclidean_error: 0.7532\n",
      "Epoch 501/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6572 - mean_euclidean_error: 0.5095 - val_loss: 0.9120 - val_mean_euclidean_error: 0.7499\n",
      "Epoch 502/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6580 - mean_euclidean_error: 0.5150 - val_loss: 0.9032 - val_mean_euclidean_error: 0.6996\n",
      "Epoch 503/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6500 - mean_euclidean_error: 0.5008 - val_loss: 0.9221 - val_mean_euclidean_error: 0.7158\n",
      "Epoch 504/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6509 - mean_euclidean_error: 0.5105 - val_loss: 0.9209 - val_mean_euclidean_error: 0.7661\n",
      "Epoch 505/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6702 - mean_euclidean_error: 0.5473 - val_loss: 0.9121 - val_mean_euclidean_error: 0.7051\n",
      "Epoch 506/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6569 - mean_euclidean_error: 0.5153 - val_loss: 0.9349 - val_mean_euclidean_error: 0.8129\n",
      "Epoch 507/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6590 - mean_euclidean_error: 0.5172 - val_loss: 0.9387 - val_mean_euclidean_error: 0.8088\n",
      "Epoch 508/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6617 - mean_euclidean_error: 0.5399 - val_loss: 0.9181 - val_mean_euclidean_error: 0.7668\n",
      "Epoch 509/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6661 - mean_euclidean_error: 0.5255 - val_loss: 0.9594 - val_mean_euclidean_error: 0.7964\n",
      "Epoch 510/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6605 - mean_euclidean_error: 0.5191 - val_loss: 0.8913 - val_mean_euclidean_error: 0.7464\n",
      "Epoch 511/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6533 - mean_euclidean_error: 0.5151 - val_loss: 0.9245 - val_mean_euclidean_error: 0.7820\n",
      "Epoch 512/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6572 - mean_euclidean_error: 0.5117 - val_loss: 0.9100 - val_mean_euclidean_error: 0.7287\n",
      "Epoch 513/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6485 - mean_euclidean_error: 0.4936 - val_loss: 0.9089 - val_mean_euclidean_error: 0.7412\n",
      "Epoch 514/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6524 - mean_euclidean_error: 0.5113 - val_loss: 0.9323 - val_mean_euclidean_error: 0.7804\n",
      "Epoch 515/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6621 - mean_euclidean_error: 0.5250 - val_loss: 0.9062 - val_mean_euclidean_error: 0.7690\n",
      "Epoch 516/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6505 - mean_euclidean_error: 0.4976 - val_loss: 0.8919 - val_mean_euclidean_error: 0.7061\n",
      "Epoch 517/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6498 - mean_euclidean_error: 0.5037 - val_loss: 0.9011 - val_mean_euclidean_error: 0.7125\n",
      "Epoch 518/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6566 - mean_euclidean_error: 0.5111 - val_loss: 0.9415 - val_mean_euclidean_error: 0.8375\n",
      "Epoch 519/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6637 - mean_euclidean_error: 0.5251 - val_loss: 0.9307 - val_mean_euclidean_error: 0.7842\n",
      "Epoch 520/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6546 - mean_euclidean_error: 0.5134 - val_loss: 0.9377 - val_mean_euclidean_error: 0.7915\n",
      "Epoch 521/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6535 - mean_euclidean_error: 0.5049 - val_loss: 0.9091 - val_mean_euclidean_error: 0.7428\n",
      "Epoch 522/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6458 - mean_euclidean_error: 0.4818 - val_loss: 0.9033 - val_mean_euclidean_error: 0.7163\n",
      "Epoch 523/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6506 - mean_euclidean_error: 0.4970 - val_loss: 0.8748 - val_mean_euclidean_error: 0.7191\n",
      "Epoch 524/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6401 - mean_euclidean_error: 0.4766 - val_loss: 0.9172 - val_mean_euclidean_error: 0.7285\n",
      "Epoch 525/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6459 - mean_euclidean_error: 0.4857 - val_loss: 0.9074 - val_mean_euclidean_error: 0.7201\n",
      "Epoch 526/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6490 - mean_euclidean_error: 0.5042 - val_loss: 0.8859 - val_mean_euclidean_error: 0.7464\n",
      "Epoch 527/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6779 - mean_euclidean_error: 0.5563 - val_loss: 0.9837 - val_mean_euclidean_error: 0.8900\n",
      "Epoch 528/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6591 - mean_euclidean_error: 0.5129 - val_loss: 0.8986 - val_mean_euclidean_error: 0.7477\n",
      "Epoch 529/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6402 - mean_euclidean_error: 0.4746 - val_loss: 0.8996 - val_mean_euclidean_error: 0.7179\n",
      "Epoch 530/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6445 - mean_euclidean_error: 0.4867 - val_loss: 0.9034 - val_mean_euclidean_error: 0.7212\n",
      "Epoch 531/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6586 - mean_euclidean_error: 0.5164 - val_loss: 0.9007 - val_mean_euclidean_error: 0.7356\n",
      "Epoch 532/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6513 - mean_euclidean_error: 0.5124 - val_loss: 0.9047 - val_mean_euclidean_error: 0.7703\n",
      "Epoch 533/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6595 - mean_euclidean_error: 0.5278 - val_loss: 0.9224 - val_mean_euclidean_error: 0.7836\n",
      "Epoch 534/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6486 - mean_euclidean_error: 0.5090 - val_loss: 0.8842 - val_mean_euclidean_error: 0.7529\n",
      "Epoch 535/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6471 - mean_euclidean_error: 0.5089 - val_loss: 0.9160 - val_mean_euclidean_error: 0.7240\n",
      "Epoch 536/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6642 - mean_euclidean_error: 0.5300 - val_loss: 0.8993 - val_mean_euclidean_error: 0.7174\n",
      "Epoch 537/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6412 - mean_euclidean_error: 0.4842 - val_loss: 0.9088 - val_mean_euclidean_error: 0.7403\n",
      "Epoch 538/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6501 - mean_euclidean_error: 0.5010 - val_loss: 0.8983 - val_mean_euclidean_error: 0.7194\n",
      "Epoch 539/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6473 - mean_euclidean_error: 0.5061 - val_loss: 0.8936 - val_mean_euclidean_error: 0.6962\n",
      "Epoch 540/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6510 - mean_euclidean_error: 0.5096 - val_loss: 0.8768 - val_mean_euclidean_error: 0.7060\n",
      "Epoch 541/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6456 - mean_euclidean_error: 0.5090 - val_loss: 0.9133 - val_mean_euclidean_error: 0.7344\n",
      "Epoch 542/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6488 - mean_euclidean_error: 0.4898 - val_loss: 0.8888 - val_mean_euclidean_error: 0.7714\n",
      "Epoch 543/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6430 - mean_euclidean_error: 0.5011 - val_loss: 0.9112 - val_mean_euclidean_error: 0.7421\n",
      "Epoch 544/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6592 - mean_euclidean_error: 0.5405 - val_loss: 0.9010 - val_mean_euclidean_error: 0.7091\n",
      "Epoch 545/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6526 - mean_euclidean_error: 0.5220 - val_loss: 0.8848 - val_mean_euclidean_error: 0.7476\n",
      "Epoch 546/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6607 - mean_euclidean_error: 0.5248 - val_loss: 0.9060 - val_mean_euclidean_error: 0.7076\n",
      "Epoch 547/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6600 - mean_euclidean_error: 0.5235 - val_loss: 0.9160 - val_mean_euclidean_error: 0.7775\n",
      "Epoch 548/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6417 - mean_euclidean_error: 0.5035 - val_loss: 0.8920 - val_mean_euclidean_error: 0.7640\n",
      "Epoch 549/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6487 - mean_euclidean_error: 0.4921 - val_loss: 0.9222 - val_mean_euclidean_error: 0.7337\n",
      "Epoch 550/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6490 - mean_euclidean_error: 0.5125 - val_loss: 0.9093 - val_mean_euclidean_error: 0.7355\n",
      "Epoch 551/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6537 - mean_euclidean_error: 0.5255 - val_loss: 0.9044 - val_mean_euclidean_error: 0.7155\n",
      "Epoch 552/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6437 - mean_euclidean_error: 0.4959 - val_loss: 0.8974 - val_mean_euclidean_error: 0.7110\n",
      "Epoch 553/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6468 - mean_euclidean_error: 0.4916 - val_loss: 0.8788 - val_mean_euclidean_error: 0.6788\n",
      "Epoch 554/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6445 - mean_euclidean_error: 0.4965 - val_loss: 0.9051 - val_mean_euclidean_error: 0.7585\n",
      "Epoch 555/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6444 - mean_euclidean_error: 0.5021 - val_loss: 0.9019 - val_mean_euclidean_error: 0.7119\n",
      "Epoch 556/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6538 - mean_euclidean_error: 0.5197 - val_loss: 0.8868 - val_mean_euclidean_error: 0.7411\n",
      "Epoch 557/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6536 - mean_euclidean_error: 0.5213 - val_loss: 0.9215 - val_mean_euclidean_error: 0.8227\n",
      "Epoch 558/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6459 - mean_euclidean_error: 0.5085 - val_loss: 0.9232 - val_mean_euclidean_error: 0.8197\n",
      "Epoch 559/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6626 - mean_euclidean_error: 0.5379 - val_loss: 0.9073 - val_mean_euclidean_error: 0.7428\n",
      "Epoch 560/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6405 - mean_euclidean_error: 0.4915 - val_loss: 0.8851 - val_mean_euclidean_error: 0.7002\n",
      "Epoch 561/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6552 - mean_euclidean_error: 0.5331 - val_loss: 0.9192 - val_mean_euclidean_error: 0.7720\n",
      "Epoch 562/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6461 - mean_euclidean_error: 0.5086 - val_loss: 0.8939 - val_mean_euclidean_error: 0.7367\n",
      "Epoch 563/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6412 - mean_euclidean_error: 0.4849 - val_loss: 0.9094 - val_mean_euclidean_error: 0.7074\n",
      "Epoch 564/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6448 - mean_euclidean_error: 0.4961 - val_loss: 0.8871 - val_mean_euclidean_error: 0.7550\n",
      "Epoch 565/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6418 - mean_euclidean_error: 0.4931 - val_loss: 0.8822 - val_mean_euclidean_error: 0.6873\n",
      "Epoch 566/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6452 - mean_euclidean_error: 0.4922 - val_loss: 0.8896 - val_mean_euclidean_error: 0.7064\n",
      "Epoch 567/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6414 - mean_euclidean_error: 0.5075 - val_loss: 0.8879 - val_mean_euclidean_error: 0.6792\n",
      "Epoch 568/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6501 - mean_euclidean_error: 0.5131 - val_loss: 0.8757 - val_mean_euclidean_error: 0.7029\n",
      "Epoch 569/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6460 - mean_euclidean_error: 0.5046 - val_loss: 0.8940 - val_mean_euclidean_error: 0.7249\n",
      "Epoch 570/1500\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.6376 - mean_euclidean_error: 0.4850 - val_loss: 0.8989 - val_mean_euclidean_error: 0.7558\n",
      "Epoch 571/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6345 - mean_euclidean_error: 0.4840 - val_loss: 0.8889 - val_mean_euclidean_error: 0.7368\n",
      "Epoch 572/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6530 - mean_euclidean_error: 0.5281 - val_loss: 0.8950 - val_mean_euclidean_error: 0.6941\n",
      "Epoch 573/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6445 - mean_euclidean_error: 0.5111 - val_loss: 0.8640 - val_mean_euclidean_error: 0.6786\n",
      "Epoch 574/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6401 - mean_euclidean_error: 0.4863 - val_loss: 0.8725 - val_mean_euclidean_error: 0.7487\n",
      "Epoch 575/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6393 - mean_euclidean_error: 0.4883 - val_loss: 0.8886 - val_mean_euclidean_error: 0.7308\n",
      "Epoch 576/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6407 - mean_euclidean_error: 0.4838 - val_loss: 0.9038 - val_mean_euclidean_error: 0.7063\n",
      "Epoch 577/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6338 - mean_euclidean_error: 0.4652 - val_loss: 0.8718 - val_mean_euclidean_error: 0.7046\n",
      "Epoch 578/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6357 - mean_euclidean_error: 0.4821 - val_loss: 0.8861 - val_mean_euclidean_error: 0.7540\n",
      "Epoch 579/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6401 - mean_euclidean_error: 0.4965 - val_loss: 0.8585 - val_mean_euclidean_error: 0.7392\n",
      "Epoch 580/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6461 - mean_euclidean_error: 0.5125 - val_loss: 0.8804 - val_mean_euclidean_error: 0.7347\n",
      "Epoch 581/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6400 - mean_euclidean_error: 0.4879 - val_loss: 0.8832 - val_mean_euclidean_error: 0.7017\n",
      "Epoch 582/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6379 - mean_euclidean_error: 0.4881 - val_loss: 0.8718 - val_mean_euclidean_error: 0.7110\n",
      "Epoch 583/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6490 - mean_euclidean_error: 0.5120 - val_loss: 0.8791 - val_mean_euclidean_error: 0.6895\n",
      "Epoch 584/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6357 - mean_euclidean_error: 0.4737 - val_loss: 0.8793 - val_mean_euclidean_error: 0.7150\n",
      "Epoch 585/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6374 - mean_euclidean_error: 0.4809 - val_loss: 0.8716 - val_mean_euclidean_error: 0.7345\n",
      "Epoch 586/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6359 - mean_euclidean_error: 0.4872 - val_loss: 0.8827 - val_mean_euclidean_error: 0.7283\n",
      "Epoch 587/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6503 - mean_euclidean_error: 0.5194 - val_loss: 0.8890 - val_mean_euclidean_error: 0.7029\n",
      "Epoch 588/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6411 - mean_euclidean_error: 0.4973 - val_loss: 0.9016 - val_mean_euclidean_error: 0.7490\n",
      "Epoch 589/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6324 - mean_euclidean_error: 0.4782 - val_loss: 0.8729 - val_mean_euclidean_error: 0.7104\n",
      "Epoch 590/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6436 - mean_euclidean_error: 0.4966 - val_loss: 0.8841 - val_mean_euclidean_error: 0.7482\n",
      "Epoch 591/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6438 - mean_euclidean_error: 0.5066 - val_loss: 0.8828 - val_mean_euclidean_error: 0.7136\n",
      "Epoch 592/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6410 - mean_euclidean_error: 0.4876 - val_loss: 0.8837 - val_mean_euclidean_error: 0.7651\n",
      "Epoch 593/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6370 - mean_euclidean_error: 0.4815 - val_loss: 0.8844 - val_mean_euclidean_error: 0.7309\n",
      "Epoch 594/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6282 - mean_euclidean_error: 0.4555 - val_loss: 0.8855 - val_mean_euclidean_error: 0.7401\n",
      "Epoch 595/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6438 - mean_euclidean_error: 0.5100 - val_loss: 0.9004 - val_mean_euclidean_error: 0.7512\n",
      "Epoch 596/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6395 - mean_euclidean_error: 0.4949 - val_loss: 0.8570 - val_mean_euclidean_error: 0.6800\n",
      "Epoch 597/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6315 - mean_euclidean_error: 0.4882 - val_loss: 0.9072 - val_mean_euclidean_error: 0.7663\n",
      "Epoch 598/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6562 - mean_euclidean_error: 0.5320 - val_loss: 0.8840 - val_mean_euclidean_error: 0.7559\n",
      "Epoch 599/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6398 - mean_euclidean_error: 0.4996 - val_loss: 0.8783 - val_mean_euclidean_error: 0.7376\n",
      "Epoch 600/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6407 - mean_euclidean_error: 0.5020 - val_loss: 0.9204 - val_mean_euclidean_error: 0.7316\n",
      "Epoch 601/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6427 - mean_euclidean_error: 0.4925 - val_loss: 0.8601 - val_mean_euclidean_error: 0.6956\n",
      "Epoch 602/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6339 - mean_euclidean_error: 0.4804 - val_loss: 0.8818 - val_mean_euclidean_error: 0.7020\n",
      "Epoch 603/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6323 - mean_euclidean_error: 0.4769 - val_loss: 0.8923 - val_mean_euclidean_error: 0.7768\n",
      "Epoch 604/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6326 - mean_euclidean_error: 0.4824 - val_loss: 0.8942 - val_mean_euclidean_error: 0.7324\n",
      "Epoch 605/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6333 - mean_euclidean_error: 0.4807 - val_loss: 0.8760 - val_mean_euclidean_error: 0.6979\n",
      "Epoch 606/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6344 - mean_euclidean_error: 0.4766 - val_loss: 0.8734 - val_mean_euclidean_error: 0.7059\n",
      "Epoch 607/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6359 - mean_euclidean_error: 0.4898 - val_loss: 0.8887 - val_mean_euclidean_error: 0.7507\n",
      "Epoch 608/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6354 - mean_euclidean_error: 0.4842 - val_loss: 0.8753 - val_mean_euclidean_error: 0.6913\n",
      "Epoch 609/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6414 - mean_euclidean_error: 0.4975 - val_loss: 0.8631 - val_mean_euclidean_error: 0.7048\n",
      "Epoch 610/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6476 - mean_euclidean_error: 0.5172 - val_loss: 0.8841 - val_mean_euclidean_error: 0.7089\n",
      "Epoch 611/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6445 - mean_euclidean_error: 0.5073 - val_loss: 0.8796 - val_mean_euclidean_error: 0.7551\n",
      "Epoch 612/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6317 - mean_euclidean_error: 0.4780 - val_loss: 0.8787 - val_mean_euclidean_error: 0.7103\n",
      "Epoch 613/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6343 - mean_euclidean_error: 0.4894 - val_loss: 0.8697 - val_mean_euclidean_error: 0.7122\n",
      "Epoch 614/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6465 - mean_euclidean_error: 0.5086 - val_loss: 0.9133 - val_mean_euclidean_error: 0.7729\n",
      "Epoch 615/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6345 - mean_euclidean_error: 0.4883 - val_loss: 0.8654 - val_mean_euclidean_error: 0.6864\n",
      "Epoch 616/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6387 - mean_euclidean_error: 0.5010 - val_loss: 0.9079 - val_mean_euclidean_error: 0.7255\n",
      "Epoch 617/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6353 - mean_euclidean_error: 0.4916 - val_loss: 0.8701 - val_mean_euclidean_error: 0.6957\n",
      "Epoch 618/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6339 - mean_euclidean_error: 0.4923 - val_loss: 0.9256 - val_mean_euclidean_error: 0.8163\n",
      "Epoch 619/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6542 - mean_euclidean_error: 0.5381 - val_loss: 0.8873 - val_mean_euclidean_error: 0.7902\n",
      "Epoch 620/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6430 - mean_euclidean_error: 0.5111 - val_loss: 0.8999 - val_mean_euclidean_error: 0.7703\n",
      "Epoch 621/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6356 - mean_euclidean_error: 0.4889 - val_loss: 0.8718 - val_mean_euclidean_error: 0.7367\n",
      "Epoch 622/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6413 - mean_euclidean_error: 0.5022 - val_loss: 0.8701 - val_mean_euclidean_error: 0.7142\n",
      "Epoch 623/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6265 - mean_euclidean_error: 0.4647 - val_loss: 0.8579 - val_mean_euclidean_error: 0.6991\n",
      "Epoch 624/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6319 - mean_euclidean_error: 0.4811 - val_loss: 0.8574 - val_mean_euclidean_error: 0.6849\n",
      "Epoch 625/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6396 - mean_euclidean_error: 0.5035 - val_loss: 0.8658 - val_mean_euclidean_error: 0.6994\n",
      "Epoch 626/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6347 - mean_euclidean_error: 0.4867 - val_loss: 0.8885 - val_mean_euclidean_error: 0.7066\n",
      "Epoch 627/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6349 - mean_euclidean_error: 0.4858 - val_loss: 0.8730 - val_mean_euclidean_error: 0.7233\n",
      "Epoch 628/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6386 - mean_euclidean_error: 0.4980 - val_loss: 0.8669 - val_mean_euclidean_error: 0.6915\n",
      "Epoch 629/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.6317 - mean_euclidean_error: 0.4785 - val_loss: 0.8758 - val_mean_euclidean_error: 0.7113\n",
      "Epoch 630/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6369 - mean_euclidean_error: 0.5003 - val_loss: 0.8800 - val_mean_euclidean_error: 0.7491\n",
      "Epoch 631/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6352 - mean_euclidean_error: 0.4915 - val_loss: 0.8995 - val_mean_euclidean_error: 0.7089\n",
      "Epoch 632/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6291 - mean_euclidean_error: 0.4791 - val_loss: 0.8552 - val_mean_euclidean_error: 0.6894\n",
      "Epoch 633/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6360 - mean_euclidean_error: 0.4903 - val_loss: 0.9145 - val_mean_euclidean_error: 0.7807\n",
      "Epoch 634/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6455 - mean_euclidean_error: 0.5114 - val_loss: 0.8930 - val_mean_euclidean_error: 0.7551\n",
      "Epoch 635/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6401 - mean_euclidean_error: 0.5024 - val_loss: 0.8972 - val_mean_euclidean_error: 0.7728\n",
      "Epoch 636/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6620 - mean_euclidean_error: 0.5436 - val_loss: 0.9111 - val_mean_euclidean_error: 0.7650\n",
      "Epoch 637/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6389 - mean_euclidean_error: 0.5075 - val_loss: 0.8668 - val_mean_euclidean_error: 0.6985\n",
      "Epoch 638/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6310 - mean_euclidean_error: 0.4942 - val_loss: 0.9058 - val_mean_euclidean_error: 0.7823\n",
      "Epoch 639/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6388 - mean_euclidean_error: 0.5010 - val_loss: 0.8964 - val_mean_euclidean_error: 0.7473\n",
      "Epoch 640/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6339 - mean_euclidean_error: 0.4857 - val_loss: 0.8705 - val_mean_euclidean_error: 0.7175\n",
      "Epoch 641/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6310 - mean_euclidean_error: 0.4960 - val_loss: 0.8718 - val_mean_euclidean_error: 0.7134\n",
      "Epoch 642/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6536 - mean_euclidean_error: 0.5308 - val_loss: 0.8904 - val_mean_euclidean_error: 0.7421\n",
      "Epoch 643/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6281 - mean_euclidean_error: 0.4724 - val_loss: 0.8868 - val_mean_euclidean_error: 0.7489\n",
      "Epoch 644/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6307 - mean_euclidean_error: 0.4834 - val_loss: 0.8685 - val_mean_euclidean_error: 0.7022\n",
      "Epoch 645/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6302 - mean_euclidean_error: 0.4779 - val_loss: 0.8496 - val_mean_euclidean_error: 0.6877\n",
      "Epoch 646/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6276 - mean_euclidean_error: 0.4778 - val_loss: 0.8637 - val_mean_euclidean_error: 0.7036\n",
      "Epoch 647/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6327 - mean_euclidean_error: 0.4879 - val_loss: 0.8894 - val_mean_euclidean_error: 0.7315\n",
      "Epoch 648/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6398 - mean_euclidean_error: 0.5123 - val_loss: 0.8716 - val_mean_euclidean_error: 0.6790\n",
      "Epoch 649/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6377 - mean_euclidean_error: 0.5011 - val_loss: 0.8424 - val_mean_euclidean_error: 0.6980\n",
      "Epoch 650/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6283 - mean_euclidean_error: 0.4688 - val_loss: 0.8674 - val_mean_euclidean_error: 0.7093\n",
      "Epoch 651/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6286 - mean_euclidean_error: 0.4809 - val_loss: 0.8495 - val_mean_euclidean_error: 0.6705\n",
      "Epoch 652/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6249 - mean_euclidean_error: 0.4747 - val_loss: 0.8520 - val_mean_euclidean_error: 0.6773\n",
      "Epoch 653/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6242 - mean_euclidean_error: 0.4682 - val_loss: 0.8884 - val_mean_euclidean_error: 0.7041\n",
      "Epoch 654/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6296 - mean_euclidean_error: 0.4828 - val_loss: 0.8583 - val_mean_euclidean_error: 0.7248\n",
      "Epoch 655/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6417 - mean_euclidean_error: 0.5072 - val_loss: 0.8774 - val_mean_euclidean_error: 0.7015\n",
      "Epoch 656/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6307 - mean_euclidean_error: 0.4817 - val_loss: 0.8454 - val_mean_euclidean_error: 0.6935\n",
      "Epoch 657/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6299 - mean_euclidean_error: 0.4813 - val_loss: 0.8514 - val_mean_euclidean_error: 0.6729\n",
      "Epoch 658/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6318 - mean_euclidean_error: 0.4845 - val_loss: 0.8861 - val_mean_euclidean_error: 0.7561\n",
      "Epoch 659/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6311 - mean_euclidean_error: 0.4867 - val_loss: 0.8366 - val_mean_euclidean_error: 0.6544\n",
      "Epoch 660/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6226 - mean_euclidean_error: 0.4631 - val_loss: 0.8992 - val_mean_euclidean_error: 0.7587\n",
      "Epoch 661/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6290 - mean_euclidean_error: 0.4863 - val_loss: 0.8598 - val_mean_euclidean_error: 0.6769\n",
      "Epoch 662/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6332 - mean_euclidean_error: 0.5103 - val_loss: 0.8819 - val_mean_euclidean_error: 0.7325\n",
      "Epoch 663/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6373 - mean_euclidean_error: 0.4897 - val_loss: 0.8470 - val_mean_euclidean_error: 0.6939\n",
      "Epoch 664/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6295 - mean_euclidean_error: 0.4817 - val_loss: 0.8596 - val_mean_euclidean_error: 0.6719\n",
      "Epoch 665/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6357 - mean_euclidean_error: 0.4892 - val_loss: 0.8545 - val_mean_euclidean_error: 0.6967\n",
      "Epoch 666/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6247 - mean_euclidean_error: 0.4739 - val_loss: 0.8547 - val_mean_euclidean_error: 0.7177\n",
      "Epoch 667/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6294 - mean_euclidean_error: 0.4846 - val_loss: 0.8681 - val_mean_euclidean_error: 0.6744\n",
      "Epoch 668/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6360 - mean_euclidean_error: 0.4987 - val_loss: 0.8631 - val_mean_euclidean_error: 0.6829\n",
      "Epoch 669/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6237 - mean_euclidean_error: 0.4675 - val_loss: 0.8579 - val_mean_euclidean_error: 0.7303\n",
      "Epoch 670/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6321 - mean_euclidean_error: 0.4885 - val_loss: 0.8625 - val_mean_euclidean_error: 0.7571\n",
      "Epoch 671/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6250 - mean_euclidean_error: 0.4789 - val_loss: 0.8473 - val_mean_euclidean_error: 0.6969\n",
      "Epoch 672/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6375 - mean_euclidean_error: 0.5101 - val_loss: 0.8726 - val_mean_euclidean_error: 0.7107\n",
      "Epoch 673/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6316 - mean_euclidean_error: 0.4902 - val_loss: 0.8431 - val_mean_euclidean_error: 0.6742\n",
      "Epoch 674/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6254 - mean_euclidean_error: 0.4698 - val_loss: 0.8396 - val_mean_euclidean_error: 0.6953\n",
      "Epoch 675/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6243 - mean_euclidean_error: 0.4658 - val_loss: 0.8435 - val_mean_euclidean_error: 0.6845\n",
      "Epoch 676/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6208 - mean_euclidean_error: 0.4787 - val_loss: 0.8260 - val_mean_euclidean_error: 0.6852\n",
      "Epoch 677/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6366 - mean_euclidean_error: 0.4942 - val_loss: 0.8717 - val_mean_euclidean_error: 0.7435\n",
      "Epoch 678/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6257 - mean_euclidean_error: 0.4702 - val_loss: 0.8506 - val_mean_euclidean_error: 0.7243\n",
      "Epoch 679/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6265 - mean_euclidean_error: 0.4778 - val_loss: 0.8915 - val_mean_euclidean_error: 0.7405\n",
      "Epoch 680/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6278 - mean_euclidean_error: 0.4829 - val_loss: 0.9119 - val_mean_euclidean_error: 0.8870\n",
      "Epoch 681/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6421 - mean_euclidean_error: 0.5257 - val_loss: 0.8651 - val_mean_euclidean_error: 0.7032\n",
      "Epoch 682/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6350 - mean_euclidean_error: 0.5044 - val_loss: 0.8621 - val_mean_euclidean_error: 0.7260\n",
      "Epoch 683/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6297 - mean_euclidean_error: 0.4833 - val_loss: 0.8701 - val_mean_euclidean_error: 0.6634\n",
      "Epoch 684/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6291 - mean_euclidean_error: 0.4884 - val_loss: 0.8696 - val_mean_euclidean_error: 0.7549\n",
      "Epoch 685/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6368 - mean_euclidean_error: 0.5031 - val_loss: 0.8592 - val_mean_euclidean_error: 0.6680\n",
      "Epoch 686/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6209 - mean_euclidean_error: 0.4671 - val_loss: 0.8725 - val_mean_euclidean_error: 0.7052\n",
      "Epoch 687/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6397 - mean_euclidean_error: 0.5099 - val_loss: 0.8557 - val_mean_euclidean_error: 0.6945\n",
      "Epoch 688/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6312 - mean_euclidean_error: 0.4925 - val_loss: 0.8985 - val_mean_euclidean_error: 0.8241\n",
      "Epoch 689/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6250 - mean_euclidean_error: 0.4765 - val_loss: 0.8624 - val_mean_euclidean_error: 0.6934\n",
      "Epoch 690/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6279 - mean_euclidean_error: 0.4829 - val_loss: 0.8594 - val_mean_euclidean_error: 0.6859\n",
      "Epoch 691/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6243 - mean_euclidean_error: 0.4723 - val_loss: 0.8532 - val_mean_euclidean_error: 0.7440\n",
      "Epoch 692/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6228 - mean_euclidean_error: 0.4711 - val_loss: 0.8766 - val_mean_euclidean_error: 0.7388\n",
      "Epoch 693/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6298 - mean_euclidean_error: 0.4960 - val_loss: 0.8411 - val_mean_euclidean_error: 0.6812\n",
      "Epoch 694/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6231 - mean_euclidean_error: 0.4743 - val_loss: 0.8519 - val_mean_euclidean_error: 0.6752\n",
      "Epoch 695/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6244 - mean_euclidean_error: 0.4710 - val_loss: 0.8656 - val_mean_euclidean_error: 0.6760\n",
      "Epoch 696/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6221 - mean_euclidean_error: 0.4733 - val_loss: 0.8602 - val_mean_euclidean_error: 0.6915\n",
      "Epoch 697/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6258 - mean_euclidean_error: 0.4875 - val_loss: 0.8535 - val_mean_euclidean_error: 0.7217\n",
      "Epoch 698/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6506 - mean_euclidean_error: 0.5249 - val_loss: 0.8833 - val_mean_euclidean_error: 0.7769\n",
      "Epoch 699/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6215 - mean_euclidean_error: 0.4680 - val_loss: 0.8426 - val_mean_euclidean_error: 0.6896\n",
      "Epoch 700/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6165 - mean_euclidean_error: 0.4587 - val_loss: 0.8667 - val_mean_euclidean_error: 0.7033\n",
      "Epoch 701/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6238 - mean_euclidean_error: 0.4706 - val_loss: 0.8351 - val_mean_euclidean_error: 0.6720\n",
      "Epoch 702/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6236 - mean_euclidean_error: 0.4737 - val_loss: 0.8385 - val_mean_euclidean_error: 0.7075\n",
      "Epoch 703/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6184 - mean_euclidean_error: 0.4672 - val_loss: 0.8765 - val_mean_euclidean_error: 0.7587\n",
      "Epoch 704/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6379 - mean_euclidean_error: 0.5151 - val_loss: 0.8929 - val_mean_euclidean_error: 0.8118\n",
      "Epoch 705/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6304 - mean_euclidean_error: 0.5037 - val_loss: 0.8684 - val_mean_euclidean_error: 0.7114\n",
      "Epoch 706/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6245 - mean_euclidean_error: 0.4787 - val_loss: 0.8523 - val_mean_euclidean_error: 0.6995\n",
      "Epoch 707/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6201 - mean_euclidean_error: 0.4671 - val_loss: 0.8497 - val_mean_euclidean_error: 0.7172\n",
      "Epoch 708/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6185 - mean_euclidean_error: 0.4638 - val_loss: 0.8272 - val_mean_euclidean_error: 0.6866\n",
      "Epoch 709/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6251 - mean_euclidean_error: 0.4775 - val_loss: 0.8578 - val_mean_euclidean_error: 0.7290\n",
      "Epoch 710/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6226 - mean_euclidean_error: 0.4772 - val_loss: 0.8498 - val_mean_euclidean_error: 0.7237\n",
      "Epoch 711/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6209 - mean_euclidean_error: 0.4686 - val_loss: 0.8402 - val_mean_euclidean_error: 0.6755\n",
      "Epoch 712/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6473 - mean_euclidean_error: 0.5293 - val_loss: 0.8453 - val_mean_euclidean_error: 0.7038\n",
      "Epoch 713/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6360 - mean_euclidean_error: 0.5130 - val_loss: 0.8481 - val_mean_euclidean_error: 0.7226\n",
      "Epoch 714/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6169 - mean_euclidean_error: 0.4576 - val_loss: 0.8372 - val_mean_euclidean_error: 0.6744\n",
      "Epoch 715/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6172 - mean_euclidean_error: 0.4674 - val_loss: 0.8599 - val_mean_euclidean_error: 0.7482\n",
      "Epoch 716/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6277 - mean_euclidean_error: 0.4841 - val_loss: 0.8386 - val_mean_euclidean_error: 0.6977\n",
      "Epoch 717/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6241 - mean_euclidean_error: 0.4818 - val_loss: 0.8582 - val_mean_euclidean_error: 0.6980\n",
      "Epoch 718/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6229 - mean_euclidean_error: 0.5045 - val_loss: 0.8441 - val_mean_euclidean_error: 0.6501\n",
      "Epoch 719/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.6244 - mean_euclidean_error: 0.4703 - val_loss: 0.8912 - val_mean_euclidean_error: 0.7501\n",
      "Epoch 720/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6246 - mean_euclidean_error: 0.4786 - val_loss: 0.8526 - val_mean_euclidean_error: 0.6922\n",
      "Epoch 721/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6173 - mean_euclidean_error: 0.4546 - val_loss: 0.8472 - val_mean_euclidean_error: 0.7209\n",
      "Epoch 722/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6219 - mean_euclidean_error: 0.4715 - val_loss: 0.8418 - val_mean_euclidean_error: 0.6619\n",
      "Epoch 723/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6271 - mean_euclidean_error: 0.4882 - val_loss: 0.8869 - val_mean_euclidean_error: 0.8059\n",
      "Epoch 724/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6218 - mean_euclidean_error: 0.4731 - val_loss: 0.8600 - val_mean_euclidean_error: 0.7198\n",
      "Epoch 725/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6183 - mean_euclidean_error: 0.4708 - val_loss: 0.8419 - val_mean_euclidean_error: 0.6669\n",
      "Epoch 726/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6154 - mean_euclidean_error: 0.4522 - val_loss: 0.8709 - val_mean_euclidean_error: 0.7448\n",
      "Epoch 727/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6239 - mean_euclidean_error: 0.4813 - val_loss: 0.8705 - val_mean_euclidean_error: 0.7615\n",
      "Epoch 728/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6215 - mean_euclidean_error: 0.4701 - val_loss: 0.8452 - val_mean_euclidean_error: 0.6989\n",
      "Epoch 729/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6183 - mean_euclidean_error: 0.4643 - val_loss: 0.8426 - val_mean_euclidean_error: 0.7242\n",
      "Epoch 730/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6111 - mean_euclidean_error: 0.4538 - val_loss: 0.8380 - val_mean_euclidean_error: 0.6772\n",
      "Epoch 731/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6232 - mean_euclidean_error: 0.4841 - val_loss: 0.8369 - val_mean_euclidean_error: 0.6735\n",
      "Epoch 732/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6223 - mean_euclidean_error: 0.4805 - val_loss: 0.8497 - val_mean_euclidean_error: 0.7054\n",
      "Epoch 733/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6209 - mean_euclidean_error: 0.4685 - val_loss: 0.8668 - val_mean_euclidean_error: 0.7027\n",
      "Epoch 734/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6217 - mean_euclidean_error: 0.4729 - val_loss: 0.8330 - val_mean_euclidean_error: 0.6695\n",
      "Epoch 735/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6143 - mean_euclidean_error: 0.4523 - val_loss: 0.8587 - val_mean_euclidean_error: 0.7036\n",
      "Epoch 736/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6151 - mean_euclidean_error: 0.4617 - val_loss: 0.8328 - val_mean_euclidean_error: 0.6548\n",
      "Epoch 737/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6176 - mean_euclidean_error: 0.4757 - val_loss: 0.8728 - val_mean_euclidean_error: 0.7461\n",
      "Epoch 738/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6312 - mean_euclidean_error: 0.4965 - val_loss: 0.8358 - val_mean_euclidean_error: 0.6866\n",
      "Epoch 739/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6115 - mean_euclidean_error: 0.4485 - val_loss: 0.8185 - val_mean_euclidean_error: 0.6770\n",
      "Epoch 740/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6110 - mean_euclidean_error: 0.4526 - val_loss: 0.8491 - val_mean_euclidean_error: 0.6754\n",
      "Epoch 741/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6319 - mean_euclidean_error: 0.5004 - val_loss: 0.8635 - val_mean_euclidean_error: 0.7091\n",
      "Epoch 742/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6318 - mean_euclidean_error: 0.5049 - val_loss: 0.8417 - val_mean_euclidean_error: 0.7759\n",
      "Epoch 743/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6177 - mean_euclidean_error: 0.4710 - val_loss: 0.8093 - val_mean_euclidean_error: 0.7061\n",
      "Epoch 744/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6170 - mean_euclidean_error: 0.4634 - val_loss: 0.8300 - val_mean_euclidean_error: 0.7098\n",
      "Epoch 745/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6123 - mean_euclidean_error: 0.4501 - val_loss: 0.8155 - val_mean_euclidean_error: 0.6817\n",
      "Epoch 746/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6106 - mean_euclidean_error: 0.4548 - val_loss: 0.8318 - val_mean_euclidean_error: 0.6518\n",
      "Epoch 747/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6412 - mean_euclidean_error: 0.5185 - val_loss: 0.8481 - val_mean_euclidean_error: 0.7210\n",
      "Epoch 748/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6202 - mean_euclidean_error: 0.4766 - val_loss: 0.8450 - val_mean_euclidean_error: 0.7136\n",
      "Epoch 749/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6239 - mean_euclidean_error: 0.4795 - val_loss: 0.8207 - val_mean_euclidean_error: 0.6750\n",
      "Epoch 750/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6150 - mean_euclidean_error: 0.4683 - val_loss: 0.8388 - val_mean_euclidean_error: 0.7029\n",
      "Epoch 751/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6200 - mean_euclidean_error: 0.4673 - val_loss: 0.8378 - val_mean_euclidean_error: 0.7080\n",
      "Epoch 752/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6173 - mean_euclidean_error: 0.4653 - val_loss: 0.8281 - val_mean_euclidean_error: 0.7109\n",
      "Epoch 753/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6157 - mean_euclidean_error: 0.4592 - val_loss: 0.8597 - val_mean_euclidean_error: 0.7342\n",
      "Epoch 754/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6194 - mean_euclidean_error: 0.4714 - val_loss: 0.8616 - val_mean_euclidean_error: 0.7184\n",
      "Epoch 755/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6174 - mean_euclidean_error: 0.4668 - val_loss: 0.8466 - val_mean_euclidean_error: 0.7318\n",
      "Epoch 756/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6182 - mean_euclidean_error: 0.4693 - val_loss: 0.8384 - val_mean_euclidean_error: 0.6919\n",
      "Epoch 757/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6152 - mean_euclidean_error: 0.4602 - val_loss: 0.8370 - val_mean_euclidean_error: 0.7024\n",
      "Epoch 758/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6202 - mean_euclidean_error: 0.4865 - val_loss: 0.8149 - val_mean_euclidean_error: 0.6637\n",
      "Epoch 759/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6209 - mean_euclidean_error: 0.4781 - val_loss: 0.8364 - val_mean_euclidean_error: 0.8044\n",
      "Epoch 760/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6290 - mean_euclidean_error: 0.5040 - val_loss: 0.8294 - val_mean_euclidean_error: 0.6768\n",
      "Epoch 761/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6259 - mean_euclidean_error: 0.4876 - val_loss: 0.8203 - val_mean_euclidean_error: 0.6707\n",
      "Epoch 762/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6226 - mean_euclidean_error: 0.4821 - val_loss: 0.8172 - val_mean_euclidean_error: 0.6407\n",
      "Epoch 763/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6137 - mean_euclidean_error: 0.4645 - val_loss: 0.8269 - val_mean_euclidean_error: 0.7017\n",
      "Epoch 764/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6154 - mean_euclidean_error: 0.4700 - val_loss: 0.8126 - val_mean_euclidean_error: 0.6844\n",
      "Epoch 765/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6118 - mean_euclidean_error: 0.4548 - val_loss: 0.8353 - val_mean_euclidean_error: 0.7382\n",
      "Epoch 766/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6120 - mean_euclidean_error: 0.4601 - val_loss: 0.8373 - val_mean_euclidean_error: 0.7181\n",
      "Epoch 767/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6268 - mean_euclidean_error: 0.4984 - val_loss: 0.8624 - val_mean_euclidean_error: 0.7533\n",
      "Epoch 768/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6186 - mean_euclidean_error: 0.4749 - val_loss: 0.8432 - val_mean_euclidean_error: 0.7302\n",
      "Epoch 769/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6140 - mean_euclidean_error: 0.4693 - val_loss: 0.8401 - val_mean_euclidean_error: 0.7051\n",
      "Epoch 770/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6279 - mean_euclidean_error: 0.4935 - val_loss: 0.8649 - val_mean_euclidean_error: 0.7467\n",
      "Epoch 771/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6200 - mean_euclidean_error: 0.4715 - val_loss: 0.8290 - val_mean_euclidean_error: 0.6728\n",
      "Epoch 772/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6186 - mean_euclidean_error: 0.4710 - val_loss: 0.8194 - val_mean_euclidean_error: 0.6584\n",
      "Epoch 773/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6101 - mean_euclidean_error: 0.4482 - val_loss: 0.8343 - val_mean_euclidean_error: 0.6853\n",
      "Epoch 774/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6160 - mean_euclidean_error: 0.4769 - val_loss: 0.8297 - val_mean_euclidean_error: 0.6821\n",
      "Epoch 775/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6238 - mean_euclidean_error: 0.4927 - val_loss: 0.8312 - val_mean_euclidean_error: 0.7052\n",
      "Epoch 776/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6105 - mean_euclidean_error: 0.4524 - val_loss: 0.8215 - val_mean_euclidean_error: 0.6670\n",
      "Epoch 777/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6157 - mean_euclidean_error: 0.4681 - val_loss: 0.8351 - val_mean_euclidean_error: 0.7546\n",
      "Epoch 778/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6257 - mean_euclidean_error: 0.5022 - val_loss: 0.8965 - val_mean_euclidean_error: 0.8195\n",
      "Epoch 779/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6199 - mean_euclidean_error: 0.4836 - val_loss: 0.8375 - val_mean_euclidean_error: 0.7609\n",
      "Epoch 780/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6244 - mean_euclidean_error: 0.4881 - val_loss: 0.8307 - val_mean_euclidean_error: 0.6958\n",
      "Epoch 781/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6210 - mean_euclidean_error: 0.4845 - val_loss: 0.8218 - val_mean_euclidean_error: 0.6825\n",
      "Epoch 782/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6184 - mean_euclidean_error: 0.4768 - val_loss: 0.8225 - val_mean_euclidean_error: 0.6758\n",
      "Epoch 783/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6101 - mean_euclidean_error: 0.4536 - val_loss: 0.8258 - val_mean_euclidean_error: 0.6514\n",
      "Epoch 784/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6095 - mean_euclidean_error: 0.4536 - val_loss: 0.8385 - val_mean_euclidean_error: 0.7049\n",
      "Epoch 785/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6155 - mean_euclidean_error: 0.4711 - val_loss: 0.8248 - val_mean_euclidean_error: 0.7053\n",
      "Epoch 786/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6144 - mean_euclidean_error: 0.4676 - val_loss: 0.8132 - val_mean_euclidean_error: 0.6884\n",
      "Epoch 787/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6108 - mean_euclidean_error: 0.4494 - val_loss: 0.8134 - val_mean_euclidean_error: 0.6527\n",
      "Epoch 788/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6242 - mean_euclidean_error: 0.5011 - val_loss: 0.8635 - val_mean_euclidean_error: 0.7594\n",
      "Epoch 789/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6174 - mean_euclidean_error: 0.4764 - val_loss: 0.8204 - val_mean_euclidean_error: 0.6726\n",
      "Epoch 790/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.6218 - mean_euclidean_error: 0.4869 - val_loss: 0.8416 - val_mean_euclidean_error: 0.6835\n",
      "Epoch 791/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6145 - mean_euclidean_error: 0.4652 - val_loss: 0.8306 - val_mean_euclidean_error: 0.6805\n",
      "Epoch 792/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6050 - mean_euclidean_error: 0.4438 - val_loss: 0.8214 - val_mean_euclidean_error: 0.6651\n",
      "Epoch 793/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6153 - mean_euclidean_error: 0.4635 - val_loss: 0.8296 - val_mean_euclidean_error: 0.7002\n",
      "Epoch 794/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6129 - mean_euclidean_error: 0.4674 - val_loss: 0.8378 - val_mean_euclidean_error: 0.6679\n",
      "Epoch 795/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6153 - mean_euclidean_error: 0.4708 - val_loss: 0.8320 - val_mean_euclidean_error: 0.6728\n",
      "Epoch 796/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6170 - mean_euclidean_error: 0.4749 - val_loss: 0.8147 - val_mean_euclidean_error: 0.7090\n",
      "Epoch 797/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6135 - mean_euclidean_error: 0.4691 - val_loss: 0.8543 - val_mean_euclidean_error: 0.7556\n",
      "Epoch 798/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6154 - mean_euclidean_error: 0.4716 - val_loss: 0.8215 - val_mean_euclidean_error: 0.6950\n",
      "Epoch 799/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6081 - mean_euclidean_error: 0.4582 - val_loss: 0.8332 - val_mean_euclidean_error: 0.7502\n",
      "Epoch 800/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6253 - mean_euclidean_error: 0.4910 - val_loss: 0.8456 - val_mean_euclidean_error: 0.7079\n",
      "Epoch 801/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6134 - mean_euclidean_error: 0.4665 - val_loss: 0.8240 - val_mean_euclidean_error: 0.6813\n",
      "Epoch 802/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6119 - mean_euclidean_error: 0.4583 - val_loss: 0.8235 - val_mean_euclidean_error: 0.7029\n",
      "Epoch 803/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6122 - mean_euclidean_error: 0.4584 - val_loss: 0.8227 - val_mean_euclidean_error: 0.6745\n",
      "Epoch 804/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6077 - mean_euclidean_error: 0.4492 - val_loss: 0.8317 - val_mean_euclidean_error: 0.6429\n",
      "Epoch 805/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6089 - mean_euclidean_error: 0.4454 - val_loss: 0.8272 - val_mean_euclidean_error: 0.7203\n",
      "Epoch 806/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6121 - mean_euclidean_error: 0.4601 - val_loss: 0.8328 - val_mean_euclidean_error: 0.7359\n",
      "Epoch 807/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6140 - mean_euclidean_error: 0.4720 - val_loss: 0.8198 - val_mean_euclidean_error: 0.6889\n",
      "Epoch 808/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6125 - mean_euclidean_error: 0.4664 - val_loss: 0.8107 - val_mean_euclidean_error: 0.6667\n",
      "Epoch 809/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6074 - mean_euclidean_error: 0.4476 - val_loss: 0.8077 - val_mean_euclidean_error: 0.6421\n",
      "Epoch 810/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6229 - mean_euclidean_error: 0.4907 - val_loss: 0.8443 - val_mean_euclidean_error: 0.7766\n",
      "Epoch 811/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6293 - mean_euclidean_error: 0.5102 - val_loss: 0.8052 - val_mean_euclidean_error: 0.6709\n",
      "Epoch 812/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6115 - mean_euclidean_error: 0.4715 - val_loss: 0.8327 - val_mean_euclidean_error: 0.7131\n",
      "Epoch 813/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6111 - mean_euclidean_error: 0.4612 - val_loss: 0.7986 - val_mean_euclidean_error: 0.6795\n",
      "Epoch 814/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6082 - mean_euclidean_error: 0.4488 - val_loss: 0.8049 - val_mean_euclidean_error: 0.6839\n",
      "Epoch 815/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6029 - mean_euclidean_error: 0.4345 - val_loss: 0.8231 - val_mean_euclidean_error: 0.6601\n",
      "Epoch 816/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6035 - mean_euclidean_error: 0.4350 - val_loss: 0.8027 - val_mean_euclidean_error: 0.6430\n",
      "Epoch 817/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6112 - mean_euclidean_error: 0.4637 - val_loss: 0.8239 - val_mean_euclidean_error: 0.6702\n",
      "Epoch 818/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6073 - mean_euclidean_error: 0.4527 - val_loss: 0.8028 - val_mean_euclidean_error: 0.6675\n",
      "Epoch 819/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6160 - mean_euclidean_error: 0.4732 - val_loss: 0.8089 - val_mean_euclidean_error: 0.6729\n",
      "Epoch 820/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6075 - mean_euclidean_error: 0.4526 - val_loss: 0.8184 - val_mean_euclidean_error: 0.6883\n",
      "Epoch 821/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6041 - mean_euclidean_error: 0.4393 - val_loss: 0.8319 - val_mean_euclidean_error: 0.6761\n",
      "Epoch 822/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6063 - mean_euclidean_error: 0.4476 - val_loss: 0.8075 - val_mean_euclidean_error: 0.6513\n",
      "Epoch 823/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6204 - mean_euclidean_error: 0.4801 - val_loss: 0.8034 - val_mean_euclidean_error: 0.6313\n",
      "Epoch 824/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6097 - mean_euclidean_error: 0.4628 - val_loss: 0.8446 - val_mean_euclidean_error: 0.7480\n",
      "Epoch 825/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6195 - mean_euclidean_error: 0.4825 - val_loss: 0.8452 - val_mean_euclidean_error: 0.6928\n",
      "Epoch 826/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6193 - mean_euclidean_error: 0.4769 - val_loss: 0.8302 - val_mean_euclidean_error: 0.7122\n",
      "Epoch 827/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6091 - mean_euclidean_error: 0.4628 - val_loss: 0.8145 - val_mean_euclidean_error: 0.6571\n",
      "Epoch 828/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6055 - mean_euclidean_error: 0.4500 - val_loss: 0.8352 - val_mean_euclidean_error: 0.7219\n",
      "Epoch 829/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6168 - mean_euclidean_error: 0.4872 - val_loss: 0.8455 - val_mean_euclidean_error: 0.7314\n",
      "Epoch 830/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6197 - mean_euclidean_error: 0.4845 - val_loss: 0.8356 - val_mean_euclidean_error: 0.6983\n",
      "Epoch 831/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6172 - mean_euclidean_error: 0.4845 - val_loss: 0.8055 - val_mean_euclidean_error: 0.6739\n",
      "Epoch 832/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6053 - mean_euclidean_error: 0.4491 - val_loss: 0.8086 - val_mean_euclidean_error: 0.6798\n",
      "Epoch 833/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6111 - mean_euclidean_error: 0.4655 - val_loss: 0.8015 - val_mean_euclidean_error: 0.6707\n",
      "Epoch 834/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6086 - mean_euclidean_error: 0.4499 - val_loss: 0.8149 - val_mean_euclidean_error: 0.6750\n",
      "Epoch 835/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6049 - mean_euclidean_error: 0.4497 - val_loss: 0.8082 - val_mean_euclidean_error: 0.6701\n",
      "Epoch 836/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6048 - mean_euclidean_error: 0.4457 - val_loss: 0.8235 - val_mean_euclidean_error: 0.7167\n",
      "Epoch 837/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6023 - mean_euclidean_error: 0.4446 - val_loss: 0.8130 - val_mean_euclidean_error: 0.6806\n",
      "Epoch 838/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6132 - mean_euclidean_error: 0.4671 - val_loss: 0.8125 - val_mean_euclidean_error: 0.6469\n",
      "Epoch 839/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6034 - mean_euclidean_error: 0.4448 - val_loss: 0.7926 - val_mean_euclidean_error: 0.6615\n",
      "Epoch 840/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6052 - mean_euclidean_error: 0.4514 - val_loss: 0.8155 - val_mean_euclidean_error: 0.6736\n",
      "Epoch 841/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6067 - mean_euclidean_error: 0.4502 - val_loss: 0.8054 - val_mean_euclidean_error: 0.6369\n",
      "Epoch 842/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6047 - mean_euclidean_error: 0.4470 - val_loss: 0.8239 - val_mean_euclidean_error: 0.7397\n",
      "Epoch 843/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6091 - mean_euclidean_error: 0.4604 - val_loss: 0.8442 - val_mean_euclidean_error: 0.7281\n",
      "Epoch 844/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6242 - mean_euclidean_error: 0.4898 - val_loss: 0.8225 - val_mean_euclidean_error: 0.6636\n",
      "Epoch 845/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6136 - mean_euclidean_error: 0.4695 - val_loss: 0.8255 - val_mean_euclidean_error: 0.6715\n",
      "Epoch 846/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6078 - mean_euclidean_error: 0.4708 - val_loss: 0.8186 - val_mean_euclidean_error: 0.6702\n",
      "Epoch 847/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6087 - mean_euclidean_error: 0.4532 - val_loss: 0.8183 - val_mean_euclidean_error: 0.7193\n",
      "Epoch 848/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6085 - mean_euclidean_error: 0.4595 - val_loss: 0.8084 - val_mean_euclidean_error: 0.6661\n",
      "Epoch 849/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6057 - mean_euclidean_error: 0.4526 - val_loss: 0.8175 - val_mean_euclidean_error: 0.6581\n",
      "Epoch 850/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6088 - mean_euclidean_error: 0.4652 - val_loss: 0.8176 - val_mean_euclidean_error: 0.6791\n",
      "Epoch 851/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6141 - mean_euclidean_error: 0.4827 - val_loss: 0.8725 - val_mean_euclidean_error: 0.7983\n",
      "Epoch 852/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6358 - mean_euclidean_error: 0.5119 - val_loss: 0.8355 - val_mean_euclidean_error: 0.6817\n",
      "Epoch 853/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6055 - mean_euclidean_error: 0.4499 - val_loss: 0.7972 - val_mean_euclidean_error: 0.6723\n",
      "Epoch 854/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6107 - mean_euclidean_error: 0.4684 - val_loss: 0.8248 - val_mean_euclidean_error: 0.7598\n",
      "Epoch 855/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6124 - mean_euclidean_error: 0.4677 - val_loss: 0.8342 - val_mean_euclidean_error: 0.7694\n",
      "Epoch 856/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6070 - mean_euclidean_error: 0.4565 - val_loss: 0.8257 - val_mean_euclidean_error: 0.7367\n",
      "Epoch 857/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6018 - mean_euclidean_error: 0.4572 - val_loss: 0.8229 - val_mean_euclidean_error: 0.6982\n",
      "Epoch 858/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6082 - mean_euclidean_error: 0.4617 - val_loss: 0.8114 - val_mean_euclidean_error: 0.7028\n",
      "Epoch 859/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6077 - mean_euclidean_error: 0.4577 - val_loss: 0.7841 - val_mean_euclidean_error: 0.6466\n",
      "Epoch 860/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6041 - mean_euclidean_error: 0.4525 - val_loss: 0.7950 - val_mean_euclidean_error: 0.6485\n",
      "Epoch 861/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6076 - mean_euclidean_error: 0.4496 - val_loss: 0.7936 - val_mean_euclidean_error: 0.6937\n",
      "Epoch 862/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6069 - mean_euclidean_error: 0.4504 - val_loss: 0.8106 - val_mean_euclidean_error: 0.7240\n",
      "Epoch 863/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6100 - mean_euclidean_error: 0.4644 - val_loss: 0.8017 - val_mean_euclidean_error: 0.6523\n",
      "Epoch 864/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6029 - mean_euclidean_error: 0.4521 - val_loss: 0.8090 - val_mean_euclidean_error: 0.6517\n",
      "Epoch 865/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6142 - mean_euclidean_error: 0.4746 - val_loss: 0.8095 - val_mean_euclidean_error: 0.6770\n",
      "Epoch 866/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6066 - mean_euclidean_error: 0.4655 - val_loss: 0.8053 - val_mean_euclidean_error: 0.6867\n",
      "Epoch 867/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6151 - mean_euclidean_error: 0.4776 - val_loss: 0.8860 - val_mean_euclidean_error: 0.8753\n",
      "Epoch 868/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6359 - mean_euclidean_error: 0.5254 - val_loss: 0.8128 - val_mean_euclidean_error: 0.6857\n",
      "Epoch 869/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6112 - mean_euclidean_error: 0.4721 - val_loss: 0.7939 - val_mean_euclidean_error: 0.6582\n",
      "Epoch 870/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6180 - mean_euclidean_error: 0.4813 - val_loss: 0.8090 - val_mean_euclidean_error: 0.6819\n",
      "Epoch 871/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6020 - mean_euclidean_error: 0.4413 - val_loss: 0.8024 - val_mean_euclidean_error: 0.7062\n",
      "Epoch 872/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6075 - mean_euclidean_error: 0.4560 - val_loss: 0.7982 - val_mean_euclidean_error: 0.6721\n",
      "Epoch 873/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6074 - mean_euclidean_error: 0.4575 - val_loss: 0.7917 - val_mean_euclidean_error: 0.6547\n",
      "Epoch 874/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6125 - mean_euclidean_error: 0.4750 - val_loss: 0.8450 - val_mean_euclidean_error: 0.7325\n",
      "Epoch 875/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6157 - mean_euclidean_error: 0.4820 - val_loss: 0.8263 - val_mean_euclidean_error: 0.7220\n",
      "Epoch 876/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6024 - mean_euclidean_error: 0.4486 - val_loss: 0.8235 - val_mean_euclidean_error: 0.6688\n",
      "Epoch 877/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6042 - mean_euclidean_error: 0.4609 - val_loss: 0.8098 - val_mean_euclidean_error: 0.6716\n",
      "Epoch 878/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6196 - mean_euclidean_error: 0.4779 - val_loss: 0.7977 - val_mean_euclidean_error: 0.6809\n",
      "Epoch 879/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6084 - mean_euclidean_error: 0.4846 - val_loss: 0.7908 - val_mean_euclidean_error: 0.6655\n",
      "Epoch 880/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6155 - mean_euclidean_error: 0.4774 - val_loss: 0.8118 - val_mean_euclidean_error: 0.7137\n",
      "Epoch 881/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6094 - mean_euclidean_error: 0.4606 - val_loss: 0.8016 - val_mean_euclidean_error: 0.6663\n",
      "Epoch 882/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6043 - mean_euclidean_error: 0.4510 - val_loss: 0.8197 - val_mean_euclidean_error: 0.7464\n",
      "Epoch 883/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6124 - mean_euclidean_error: 0.4697 - val_loss: 0.8042 - val_mean_euclidean_error: 0.7064\n",
      "Epoch 884/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6072 - mean_euclidean_error: 0.4775 - val_loss: 0.8427 - val_mean_euclidean_error: 0.7414\n",
      "Epoch 885/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6140 - mean_euclidean_error: 0.4774 - val_loss: 0.8173 - val_mean_euclidean_error: 0.6948\n",
      "Epoch 886/1500\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.6021 - mean_euclidean_error: 0.4457 - val_loss: 0.7994 - val_mean_euclidean_error: 0.6268\n",
      "Epoch 887/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.5999 - mean_euclidean_error: 0.4404 - val_loss: 0.8115 - val_mean_euclidean_error: 0.6817\n",
      "Epoch 888/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6101 - mean_euclidean_error: 0.4657 - val_loss: 0.7931 - val_mean_euclidean_error: 0.6540\n",
      "Epoch 889/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6071 - mean_euclidean_error: 0.4562 - val_loss: 0.8025 - val_mean_euclidean_error: 0.6957\n",
      "Epoch 890/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5969 - mean_euclidean_error: 0.4326 - val_loss: 0.7865 - val_mean_euclidean_error: 0.6352\n",
      "Epoch 891/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5975 - mean_euclidean_error: 0.4429 - val_loss: 0.8283 - val_mean_euclidean_error: 0.7245\n",
      "Epoch 892/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6101 - mean_euclidean_error: 0.4662 - val_loss: 0.8283 - val_mean_euclidean_error: 0.7179\n",
      "Epoch 893/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6072 - mean_euclidean_error: 0.4566 - val_loss: 0.8061 - val_mean_euclidean_error: 0.6622\n",
      "Epoch 894/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6012 - mean_euclidean_error: 0.4419 - val_loss: 0.7987 - val_mean_euclidean_error: 0.6650\n",
      "Epoch 895/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6018 - mean_euclidean_error: 0.4583 - val_loss: 0.8357 - val_mean_euclidean_error: 0.7370\n",
      "Epoch 896/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6107 - mean_euclidean_error: 0.4674 - val_loss: 0.7919 - val_mean_euclidean_error: 0.6315\n",
      "Epoch 897/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5993 - mean_euclidean_error: 0.4485 - val_loss: 0.7951 - val_mean_euclidean_error: 0.7065\n",
      "Epoch 898/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6055 - mean_euclidean_error: 0.4622 - val_loss: 0.7955 - val_mean_euclidean_error: 0.6767\n",
      "Epoch 899/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6016 - mean_euclidean_error: 0.4546 - val_loss: 0.7886 - val_mean_euclidean_error: 0.6390\n",
      "Epoch 900/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6057 - mean_euclidean_error: 0.4571 - val_loss: 0.8094 - val_mean_euclidean_error: 0.6542\n",
      "Epoch 901/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.5962 - mean_euclidean_error: 0.4377 - val_loss: 0.8010 - val_mean_euclidean_error: 0.6878\n",
      "Epoch 902/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6112 - mean_euclidean_error: 0.4685 - val_loss: 0.7953 - val_mean_euclidean_error: 0.6583\n",
      "Epoch 903/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.5996 - mean_euclidean_error: 0.4451 - val_loss: 0.7998 - val_mean_euclidean_error: 0.6658\n",
      "Epoch 904/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6076 - mean_euclidean_error: 0.4594 - val_loss: 0.7969 - val_mean_euclidean_error: 0.6787\n",
      "Epoch 905/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5971 - mean_euclidean_error: 0.4332 - val_loss: 0.8112 - val_mean_euclidean_error: 0.6519\n",
      "Epoch 906/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5978 - mean_euclidean_error: 0.4345 - val_loss: 0.8045 - val_mean_euclidean_error: 0.6546\n",
      "Epoch 907/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5993 - mean_euclidean_error: 0.4374 - val_loss: 0.8400 - val_mean_euclidean_error: 0.6918\n",
      "Epoch 908/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6151 - mean_euclidean_error: 0.4798 - val_loss: 0.7953 - val_mean_euclidean_error: 0.6384\n",
      "Epoch 909/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6022 - mean_euclidean_error: 0.4522 - val_loss: 0.7966 - val_mean_euclidean_error: 0.6689\n",
      "Epoch 910/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6053 - mean_euclidean_error: 0.4584 - val_loss: 0.8120 - val_mean_euclidean_error: 0.6858\n",
      "Epoch 911/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6021 - mean_euclidean_error: 0.4469 - val_loss: 0.8009 - val_mean_euclidean_error: 0.6531\n",
      "Epoch 912/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6001 - mean_euclidean_error: 0.4449 - val_loss: 0.8120 - val_mean_euclidean_error: 0.6848\n",
      "Epoch 913/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6010 - mean_euclidean_error: 0.4537 - val_loss: 0.8144 - val_mean_euclidean_error: 0.6978\n",
      "Epoch 914/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6178 - mean_euclidean_error: 0.5022 - val_loss: 0.8003 - val_mean_euclidean_error: 0.6744\n",
      "Epoch 915/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6085 - mean_euclidean_error: 0.4645 - val_loss: 0.8127 - val_mean_euclidean_error: 0.6988\n",
      "Epoch 916/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6053 - mean_euclidean_error: 0.4534 - val_loss: 0.8038 - val_mean_euclidean_error: 0.6693\n",
      "Epoch 917/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.5965 - mean_euclidean_error: 0.4355 - val_loss: 0.8060 - val_mean_euclidean_error: 0.6636\n",
      "Epoch 918/1500\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 0.5999 - mean_euclidean_error: 0.4405 - val_loss: 0.7989 - val_mean_euclidean_error: 0.6900\n",
      "Epoch 919/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6009 - mean_euclidean_error: 0.4476 - val_loss: 0.8180 - val_mean_euclidean_error: 0.7014\n",
      "Epoch 920/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6019 - mean_euclidean_error: 0.4513 - val_loss: 0.8027 - val_mean_euclidean_error: 0.6721\n",
      "Epoch 921/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5994 - mean_euclidean_error: 0.4464 - val_loss: 0.7931 - val_mean_euclidean_error: 0.6846\n",
      "Epoch 922/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6076 - mean_euclidean_error: 0.4652 - val_loss: 0.7938 - val_mean_euclidean_error: 0.6616\n",
      "Epoch 923/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6078 - mean_euclidean_error: 0.4676 - val_loss: 0.8045 - val_mean_euclidean_error: 0.6747\n",
      "Epoch 924/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6045 - mean_euclidean_error: 0.4558 - val_loss: 0.7986 - val_mean_euclidean_error: 0.6673\n",
      "Epoch 925/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6016 - mean_euclidean_error: 0.4539 - val_loss: 0.7956 - val_mean_euclidean_error: 0.6825\n",
      "Epoch 926/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6156 - mean_euclidean_error: 0.4840 - val_loss: 0.7868 - val_mean_euclidean_error: 0.6658\n",
      "Epoch 927/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6009 - mean_euclidean_error: 0.4567 - val_loss: 0.7951 - val_mean_euclidean_error: 0.6738\n",
      "Epoch 928/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6010 - mean_euclidean_error: 0.4456 - val_loss: 0.7996 - val_mean_euclidean_error: 0.6569\n",
      "Epoch 929/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.5975 - mean_euclidean_error: 0.4382 - val_loss: 0.7942 - val_mean_euclidean_error: 0.6657\n",
      "Epoch 930/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.5987 - mean_euclidean_error: 0.4490 - val_loss: 0.8353 - val_mean_euclidean_error: 0.7591\n",
      "Epoch 931/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6103 - mean_euclidean_error: 0.4726 - val_loss: 0.8108 - val_mean_euclidean_error: 0.7044\n",
      "Epoch 932/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5992 - mean_euclidean_error: 0.4422 - val_loss: 0.7908 - val_mean_euclidean_error: 0.6597\n",
      "Epoch 933/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5987 - mean_euclidean_error: 0.4463 - val_loss: 0.7993 - val_mean_euclidean_error: 0.6932\n",
      "Epoch 934/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6027 - mean_euclidean_error: 0.4558 - val_loss: 0.7956 - val_mean_euclidean_error: 0.6749\n",
      "Epoch 935/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6031 - mean_euclidean_error: 0.4644 - val_loss: 0.7903 - val_mean_euclidean_error: 0.6926\n",
      "Epoch 936/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6044 - mean_euclidean_error: 0.4617 - val_loss: 0.7808 - val_mean_euclidean_error: 0.6540\n",
      "Epoch 937/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6011 - mean_euclidean_error: 0.4588 - val_loss: 0.7916 - val_mean_euclidean_error: 0.6966\n",
      "Epoch 938/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5994 - mean_euclidean_error: 0.4477 - val_loss: 0.8361 - val_mean_euclidean_error: 0.7202\n",
      "Epoch 939/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6148 - mean_euclidean_error: 0.4824 - val_loss: 0.7893 - val_mean_euclidean_error: 0.6455\n",
      "Epoch 940/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6055 - mean_euclidean_error: 0.4576 - val_loss: 0.8135 - val_mean_euclidean_error: 0.7090\n",
      "Epoch 941/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6034 - mean_euclidean_error: 0.4540 - val_loss: 0.7880 - val_mean_euclidean_error: 0.6430\n",
      "Epoch 942/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5938 - mean_euclidean_error: 0.4316 - val_loss: 0.7937 - val_mean_euclidean_error: 0.6505\n",
      "Epoch 943/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5977 - mean_euclidean_error: 0.4477 - val_loss: 0.7809 - val_mean_euclidean_error: 0.6107\n",
      "Epoch 944/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.5962 - mean_euclidean_error: 0.4346 - val_loss: 0.7835 - val_mean_euclidean_error: 0.6365\n",
      "Epoch 945/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5958 - mean_euclidean_error: 0.4341 - val_loss: 0.7798 - val_mean_euclidean_error: 0.6501\n",
      "Epoch 946/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6022 - mean_euclidean_error: 0.4557 - val_loss: 0.8042 - val_mean_euclidean_error: 0.6923\n",
      "Epoch 947/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5955 - mean_euclidean_error: 0.4377 - val_loss: 0.8038 - val_mean_euclidean_error: 0.7144\n",
      "Epoch 948/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6008 - mean_euclidean_error: 0.4521 - val_loss: 0.8059 - val_mean_euclidean_error: 0.7141\n",
      "Epoch 949/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6041 - mean_euclidean_error: 0.4659 - val_loss: 0.8078 - val_mean_euclidean_error: 0.6721\n",
      "Epoch 950/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6085 - mean_euclidean_error: 0.4793 - val_loss: 0.7804 - val_mean_euclidean_error: 0.6447\n",
      "Epoch 951/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5990 - mean_euclidean_error: 0.4444 - val_loss: 0.7757 - val_mean_euclidean_error: 0.6617\n",
      "Epoch 952/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6040 - mean_euclidean_error: 0.4642 - val_loss: 0.8076 - val_mean_euclidean_error: 0.7019\n",
      "Epoch 953/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6054 - mean_euclidean_error: 0.4677 - val_loss: 0.7998 - val_mean_euclidean_error: 0.6367\n",
      "Epoch 954/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6001 - mean_euclidean_error: 0.4572 - val_loss: 0.8058 - val_mean_euclidean_error: 0.6948\n",
      "Epoch 955/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5991 - mean_euclidean_error: 0.4432 - val_loss: 0.8042 - val_mean_euclidean_error: 0.6726\n",
      "Epoch 956/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6092 - mean_euclidean_error: 0.4736 - val_loss: 0.7915 - val_mean_euclidean_error: 0.6487\n",
      "Epoch 957/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5930 - mean_euclidean_error: 0.4346 - val_loss: 0.7993 - val_mean_euclidean_error: 0.6750\n",
      "Epoch 958/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6016 - mean_euclidean_error: 0.4616 - val_loss: 0.8214 - val_mean_euclidean_error: 0.7350\n",
      "Epoch 959/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6016 - mean_euclidean_error: 0.4523 - val_loss: 0.7916 - val_mean_euclidean_error: 0.6721\n",
      "Epoch 960/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5966 - mean_euclidean_error: 0.4366 - val_loss: 0.8160 - val_mean_euclidean_error: 0.6977\n",
      "Epoch 961/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6023 - mean_euclidean_error: 0.4618 - val_loss: 0.8002 - val_mean_euclidean_error: 0.7013\n",
      "Epoch 962/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6039 - mean_euclidean_error: 0.4622 - val_loss: 0.7944 - val_mean_euclidean_error: 0.6459\n",
      "Epoch 963/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6017 - mean_euclidean_error: 0.4623 - val_loss: 0.7948 - val_mean_euclidean_error: 0.6858\n",
      "Epoch 964/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6040 - mean_euclidean_error: 0.4633 - val_loss: 0.7890 - val_mean_euclidean_error: 0.6781\n",
      "Epoch 965/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5990 - mean_euclidean_error: 0.4462 - val_loss: 0.7966 - val_mean_euclidean_error: 0.6538\n",
      "Epoch 966/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5950 - mean_euclidean_error: 0.4371 - val_loss: 0.7823 - val_mean_euclidean_error: 0.6274\n",
      "Epoch 967/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5979 - mean_euclidean_error: 0.4461 - val_loss: 0.7951 - val_mean_euclidean_error: 0.7196\n",
      "Epoch 968/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6031 - mean_euclidean_error: 0.4591 - val_loss: 0.7939 - val_mean_euclidean_error: 0.6419\n",
      "Epoch 969/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5949 - mean_euclidean_error: 0.4380 - val_loss: 0.7870 - val_mean_euclidean_error: 0.6615\n",
      "Epoch 970/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5964 - mean_euclidean_error: 0.4393 - val_loss: 0.8024 - val_mean_euclidean_error: 0.7197\n",
      "Epoch 971/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6011 - mean_euclidean_error: 0.4608 - val_loss: 0.7883 - val_mean_euclidean_error: 0.6485\n",
      "Epoch 972/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5977 - mean_euclidean_error: 0.4464 - val_loss: 0.7959 - val_mean_euclidean_error: 0.6660\n",
      "Epoch 973/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6017 - mean_euclidean_error: 0.4503 - val_loss: 0.7983 - val_mean_euclidean_error: 0.6777\n",
      "Epoch 974/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5958 - mean_euclidean_error: 0.4536 - val_loss: 0.8077 - val_mean_euclidean_error: 0.6878\n",
      "Epoch 975/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6132 - mean_euclidean_error: 0.4853 - val_loss: 0.7846 - val_mean_euclidean_error: 0.6437\n",
      "Epoch 976/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5961 - mean_euclidean_error: 0.4382 - val_loss: 0.7967 - val_mean_euclidean_error: 0.6756\n",
      "Epoch 977/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5940 - mean_euclidean_error: 0.4401 - val_loss: 0.7846 - val_mean_euclidean_error: 0.6682\n",
      "Epoch 978/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6071 - mean_euclidean_error: 0.4790 - val_loss: 0.7822 - val_mean_euclidean_error: 0.6571\n",
      "Epoch 979/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6072 - mean_euclidean_error: 0.4797 - val_loss: 0.8060 - val_mean_euclidean_error: 0.6676\n",
      "Epoch 980/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6015 - mean_euclidean_error: 0.4585 - val_loss: 0.7717 - val_mean_euclidean_error: 0.6227\n",
      "Epoch 981/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5980 - mean_euclidean_error: 0.4440 - val_loss: 0.7839 - val_mean_euclidean_error: 0.6535\n",
      "Epoch 982/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5883 - mean_euclidean_error: 0.4232 - val_loss: 0.7737 - val_mean_euclidean_error: 0.6532\n",
      "Epoch 983/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6000 - mean_euclidean_error: 0.4454 - val_loss: 0.7831 - val_mean_euclidean_error: 0.6474\n",
      "Epoch 984/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5947 - mean_euclidean_error: 0.4380 - val_loss: 0.7923 - val_mean_euclidean_error: 0.6467\n",
      "Epoch 985/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5928 - mean_euclidean_error: 0.4321 - val_loss: 0.7802 - val_mean_euclidean_error: 0.6596\n",
      "Epoch 986/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5960 - mean_euclidean_error: 0.4420 - val_loss: 0.7773 - val_mean_euclidean_error: 0.6858\n",
      "Epoch 987/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5947 - mean_euclidean_error: 0.4443 - val_loss: 0.7895 - val_mean_euclidean_error: 0.6615\n",
      "Epoch 988/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5965 - mean_euclidean_error: 0.4412 - val_loss: 0.7873 - val_mean_euclidean_error: 0.6784\n",
      "Epoch 989/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5994 - mean_euclidean_error: 0.4643 - val_loss: 0.8046 - val_mean_euclidean_error: 0.7011\n",
      "Epoch 990/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6021 - mean_euclidean_error: 0.4675 - val_loss: 0.7971 - val_mean_euclidean_error: 0.6898\n",
      "Epoch 991/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5992 - mean_euclidean_error: 0.4484 - val_loss: 0.7764 - val_mean_euclidean_error: 0.6328\n",
      "Epoch 992/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5910 - mean_euclidean_error: 0.4349 - val_loss: 0.7782 - val_mean_euclidean_error: 0.6774\n",
      "Epoch 993/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6045 - mean_euclidean_error: 0.4678 - val_loss: 0.8030 - val_mean_euclidean_error: 0.7020\n",
      "Epoch 994/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5916 - mean_euclidean_error: 0.4378 - val_loss: 0.7966 - val_mean_euclidean_error: 0.6687\n",
      "Epoch 995/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5958 - mean_euclidean_error: 0.4396 - val_loss: 0.7957 - val_mean_euclidean_error: 0.6514\n",
      "Epoch 996/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5954 - mean_euclidean_error: 0.4431 - val_loss: 0.7850 - val_mean_euclidean_error: 0.6589\n",
      "Epoch 997/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6050 - mean_euclidean_error: 0.4659 - val_loss: 0.7968 - val_mean_euclidean_error: 0.6903\n",
      "Epoch 998/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6001 - mean_euclidean_error: 0.4582 - val_loss: 0.7928 - val_mean_euclidean_error: 0.7082\n",
      "Epoch 999/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5926 - mean_euclidean_error: 0.4404 - val_loss: 0.7993 - val_mean_euclidean_error: 0.6611\n",
      "Epoch 1000/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6040 - mean_euclidean_error: 0.4587 - val_loss: 0.8097 - val_mean_euclidean_error: 0.6669\n",
      "Epoch 1001/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6016 - mean_euclidean_error: 0.4602 - val_loss: 0.7874 - val_mean_euclidean_error: 0.6626\n",
      "Epoch 1002/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5936 - mean_euclidean_error: 0.4415 - val_loss: 0.8171 - val_mean_euclidean_error: 0.6559\n",
      "Epoch 1003/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6012 - mean_euclidean_error: 0.4615 - val_loss: 0.8000 - val_mean_euclidean_error: 0.6834\n",
      "Epoch 1004/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5956 - mean_euclidean_error: 0.4432 - val_loss: 0.7738 - val_mean_euclidean_error: 0.6276\n",
      "Epoch 1005/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5936 - mean_euclidean_error: 0.4419 - val_loss: 0.7797 - val_mean_euclidean_error: 0.6577\n",
      "Epoch 1006/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6103 - mean_euclidean_error: 0.4872 - val_loss: 0.7840 - val_mean_euclidean_error: 0.6563\n",
      "Epoch 1007/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5951 - mean_euclidean_error: 0.4511 - val_loss: 0.7994 - val_mean_euclidean_error: 0.7219\n",
      "Epoch 1008/1500\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.6030 - mean_euclidean_error: 0.4656 - val_loss: 0.7820 - val_mean_euclidean_error: 0.6856\n",
      "Epoch 1009/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5882 - mean_euclidean_error: 0.4250 - val_loss: 0.7948 - val_mean_euclidean_error: 0.6815\n",
      "Epoch 1010/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5928 - mean_euclidean_error: 0.4362 - val_loss: 0.7831 - val_mean_euclidean_error: 0.6564\n",
      "Epoch 1011/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6016 - mean_euclidean_error: 0.4618 - val_loss: 0.7952 - val_mean_euclidean_error: 0.7331\n",
      "Epoch 1012/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6024 - mean_euclidean_error: 0.4636 - val_loss: 0.7979 - val_mean_euclidean_error: 0.7230\n",
      "Epoch 1013/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5909 - mean_euclidean_error: 0.4321 - val_loss: 0.7856 - val_mean_euclidean_error: 0.6708\n",
      "Epoch 1014/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6002 - mean_euclidean_error: 0.4660 - val_loss: 0.8009 - val_mean_euclidean_error: 0.6887\n",
      "Epoch 1015/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6033 - mean_euclidean_error: 0.4656 - val_loss: 0.7767 - val_mean_euclidean_error: 0.6384\n",
      "Epoch 1016/1500\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.5940 - mean_euclidean_error: 0.4492 - val_loss: 0.7874 - val_mean_euclidean_error: 0.6892\n",
      "Epoch 1017/1500\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6050 - mean_euclidean_error: 0.4699 - val_loss: 0.8052 - val_mean_euclidean_error: 0.7203\n",
      "Epoch 1018/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5972 - mean_euclidean_error: 0.4495 - val_loss: 0.7634 - val_mean_euclidean_error: 0.6152\n",
      "Epoch 1019/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5915 - mean_euclidean_error: 0.4363 - val_loss: 0.7726 - val_mean_euclidean_error: 0.6458\n",
      "Epoch 1020/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6020 - mean_euclidean_error: 0.4567 - val_loss: 0.7691 - val_mean_euclidean_error: 0.6549\n",
      "Epoch 1021/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5943 - mean_euclidean_error: 0.4451 - val_loss: 0.7850 - val_mean_euclidean_error: 0.6291\n",
      "Epoch 1022/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.5910 - mean_euclidean_error: 0.4419 - val_loss: 0.7757 - val_mean_euclidean_error: 0.6403\n",
      "Epoch 1023/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5946 - mean_euclidean_error: 0.4446 - val_loss: 0.8088 - val_mean_euclidean_error: 0.7019\n",
      "Epoch 1024/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5952 - mean_euclidean_error: 0.4489 - val_loss: 0.7882 - val_mean_euclidean_error: 0.6539\n",
      "Epoch 1025/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.6009 - mean_euclidean_error: 0.4565 - val_loss: 0.7992 - val_mean_euclidean_error: 0.7103\n",
      "Epoch 1026/1500\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.5958 - mean_euclidean_error: 0.4451 - val_loss: 0.7907 - val_mean_euclidean_error: 0.6793\n",
      "Epoch 1027/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5950 - mean_euclidean_error: 0.4411 - val_loss: 0.7930 - val_mean_euclidean_error: 0.6764\n",
      "Epoch 1028/1500\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6008 - mean_euclidean_error: 0.4674 - val_loss: 0.7994 - val_mean_euclidean_error: 0.6600\n",
      "Epoch 1029/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6054 - mean_euclidean_error: 0.4847 - val_loss: 0.7963 - val_mean_euclidean_error: 0.6900\n",
      "Epoch 1030/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6002 - mean_euclidean_error: 0.4655 - val_loss: 0.8022 - val_mean_euclidean_error: 0.6843\n",
      "Epoch 1031/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5948 - mean_euclidean_error: 0.4478 - val_loss: 0.7908 - val_mean_euclidean_error: 0.6794\n",
      "Epoch 1032/1500\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5939 - mean_euclidean_error: 0.4389 - val_loss: 0.7877 - val_mean_euclidean_error: 0.6636\n",
      "Epoch 1033/1500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5872 - mean_euclidean_error: 0.4387 - val_loss: 0.7661 - val_mean_euclidean_error: 0.6268\n",
      "Epoch 1034/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5918 - mean_euclidean_error: 0.4328 - val_loss: 0.7886 - val_mean_euclidean_error: 0.6720\n",
      "Epoch 1035/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5959 - mean_euclidean_error: 0.4520 - val_loss: 0.8210 - val_mean_euclidean_error: 0.7668\n",
      "Epoch 1036/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.6069 - mean_euclidean_error: 0.4736 - val_loss: 0.7875 - val_mean_euclidean_error: 0.6356\n",
      "Epoch 1037/1500\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.5903 - mean_euclidean_error: 0.4314 - val_loss: 0.7808 - val_mean_euclidean_error: 0.6726\n",
      "Epoch 1038/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5950 - mean_euclidean_error: 0.4396 - val_loss: 0.7990 - val_mean_euclidean_error: 0.6835\n",
      "Epoch 1039/1500\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.6006 - mean_euclidean_error: 0.4603 - val_loss: 0.7797 - val_mean_euclidean_error: 0.6406\n",
      "Epoch 1040/1500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6001 - mean_euclidean_error: 0.4570 - val_loss: 0.7697 - val_mean_euclidean_error: 0.6515\n",
      "Epoch 1041/1500\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5925 - mean_euclidean_error: 0.4354 - val_loss: 0.8015 - val_mean_euclidean_error: 0.7328\n",
      "Epoch 1042/1500\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5972 - mean_euclidean_error: 0.4495 - val_loss: 0.8020 - val_mean_euclidean_error: 0.6920\n",
      "Epoch 1043/1500\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.5933 - mean_euclidean_error: 0.4453Restoring model weights from the end of the best epoch: 943.\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5918 - mean_euclidean_error: 0.4399 - val_loss: 0.7765 - val_mean_euclidean_error: 0.6817\n",
      "\n",
      "Epoch 1043: early stopping.\n",
      "Best validation mean_euclidean_error: 0.6107163429260254\n"
     ]
    }
   ],
   "source": [
    "best_config_adam_cup = {\n",
    "    'lr': 0.001,\n",
    "    'h_dim': 64,\n",
    "    'n_layers': 2,\n",
    "    'activation': 'tanh',\n",
    "    'reg': 0.001,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.99,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "optimizer_adam = Adam(learning_rate=best_config_adam_cup['lr'], beta_1=best_config_adam_cup['beta_1'], beta_2=best_config_adam_cup['beta_2'])\n",
    "model_nn_adam_cup = get_nn_regressor(optimizer_adam, best_config_adam_cup)\n",
    "solver_adam = Solver(model_nn_adam_cup, x_train_cup, y_train_cup, x_internal_test_cup, y_internal_test_cup, target='mean_euclidean_error')\n",
    "solver_adam.train(epochs=1500, patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82492ee-bef4-4324-b503-43f7c712d36b",
   "metadata": {},
   "source": [
    "# Ensamble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d304de33-2af1-4853-94e4-fd7b66dc9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svr_preds_train = multi_svr.predict(x_train_cup)\n",
    "nn_sgd_preds_train = model_nn_sgd_cup.predict(x_train_cup)\n",
    "nn_adam_preds_train = model_nn_adam_cup.predict(x_train_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acd13a1d-a6b5-4bf6-a606-f2a747a58285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7059 - mean_euclidean_error: 0.3865\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5887 - mean_euclidean_error: 0.4227\n"
     ]
    }
   ],
   "source": [
    "# MEE of each model\n",
    "mee_svr_train = mee(y_train_cup, svr_preds_train)\n",
    "mee_nn_sgd_train = model_nn_sgd_cup.evaluate(x_train_cup, y_train_cup)[1]\n",
    "mee_nn_adam_train = model_nn_adam_cup.evaluate(x_train_cup, y_train_cup)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffeb898b-d8c7-4be6-8d24-5082e9bcd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Arithmetic and Weighted Averange\n",
    "ensemble_train = np.zeros(y_train_cup.shape)\n",
    "\n",
    "en_av_train = ensemble_arithmetic_averange(ensemble_train, svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train)\n",
    "\n",
    "en_we_train = ensemble_weighted_averange(ensemble_train, 1,\n",
    "                                       svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train,\n",
    "                                       mee_svr_train, mee_nn_sgd_train, mee_nn_adam_train)\n",
    "\n",
    "# Ensemble Stacking. Valid estimator: LinearRegression, Ridge or Lasso\n",
    "en_stack_train = ensemble_stacking_cup(estimator='LinearRegression')\n",
    "x_stack_cup_train = np.hstack((svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train))\n",
    "en_stack_train.fit(x_stack_cup_train, y_train_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1643c-dbbd-445b-8da2-95bd733cbd4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyper-parameters Tuning for Stacking Ensamble\n",
    "ValidationCurveDisplay is used to identify which of the three models: LinearRegression, Ridge or Lasso have lower error as alpha changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bf3afbe-4408-40ae-a7e4-5cbebd6460a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_name = \"alpha\"\n",
    "param_range = np.linspace(0, 20, 100)\n",
    "\n",
    "ValidationCurveDisplay.from_estimator(Ridge(), \n",
    "                                      x_stack_cup_train, \n",
    "                                      y_train_cup, \n",
    "                                      param_name=param_name, \n",
    "                                      param_range=param_range,\n",
    "                                      cv=KFold(n_splits=5, shuffle=True, random_state=128),\n",
    "                                      scoring= make_scorer(mee, greater_is_better = False),\n",
    "                                      negate_score = True,\n",
    "                                      score_name=\"MEE\",\n",
    "                                      verbose=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd3067-f12d-41f2-9876-f06e51822d5e",
   "metadata": {},
   "source": [
    "The curve is monotonically increasing, the best alpha is 0. Ridge(alpha=0) = LinearRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c38aed8a-4290-4ecc-9268-8b11f6c512c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_name = \"alpha\"\n",
    "param_range = np.linspace(0.01, 0.5, 100)\n",
    "\n",
    "ValidationCurveDisplay.from_estimator(Lasso(), \n",
    "                                      x_stack_cup_train, \n",
    "                                      y_train_cup, \n",
    "                                      param_name=param_name, \n",
    "                                      param_range=param_range,\n",
    "                                      cv=KFold(n_splits=5, shuffle=True, random_state=128),\n",
    "                                      scoring= make_scorer(mee, greater_is_better = False),\n",
    "                                      negate_score = True,\n",
    "                                      score_name=\"MEE\",\n",
    "                                      verbose=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25cabb-d7df-479e-9fcb-7db3dc13b3af",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "826dfa49-23eb-452f-bc31-8dd82bdd7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT MEE Models --\n",
      "MEE SVC: 0.2146 - MEE NN-SGD: 0.3865 - MEE NN-Adam: 0.4227\n",
      "\n",
      "-- DEVELOPMENT Arithmetic Averange--\n",
      "Loss (MSE): 0.0409 - MEE: 0.2963\n",
      "\n",
      "-- DEVELOPMENT Weighted Averange --\n",
      "Loss (MSE): 0.0377 - MEE: 0.2840\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0235 - MEE: 0.2146\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_train:.4f} - MEE NN-SGD: {mee_nn_sgd_train:.4f} - MEE NN-Adam: {mee_nn_adam_train:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Arithmetic Averange--')\n",
    "mee_train_av_cup = mee(y_train_cup, en_av_train)\n",
    "mse_train_av_cup = mean_squared_error(y_train_cup, en_av_train)\n",
    "print(f'Loss (MSE): {mse_train_av_cup:.4f} - MEE: {mee_train_av_cup:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Averange --')\n",
    "mee_train_we_cup = mee(y_train_cup, en_we_train)\n",
    "mse_train_we_cup = mean_squared_error(y_train_cup, en_we_train)\n",
    "print(f'Loss (MSE): {mse_train_we_cup:.4f} - MEE: {mee_train_we_cup:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "mee_train_stack_cup = mee(y_train_cup, en_stack_train.predict(x_stack_cup_train))\n",
    "mse_train_stack_cup = mean_squared_error(y_train_cup, en_stack_train.predict(x_stack_cup_train))\n",
    "print(f'Loss (MSE): {mse_train_stack_cup:.4f} - MEE: {mee_train_stack_cup:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34b36b-78f8-4a5b-b82b-165b3b5cf064",
   "metadata": {},
   "source": [
    "# Ensamble Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24bca8e6-d7f7-47b3-a0ae-1c6698c502d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svr_preds_internal_test = multi_svr.predict(x_internal_test_cup)\n",
    "nn_sgd_preds_internal_test = model_nn_sgd_cup.predict(x_internal_test_cup)\n",
    "nn_adam_preds_internal_test = model_nn_adam_cup.predict(x_internal_test_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c0c882c-72d6-4394-a908-01e6c26cbe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8055 - mean_euclidean_error: 0.5157\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7809 - mean_euclidean_error: 0.6107\n"
     ]
    }
   ],
   "source": [
    "# MEE of each model\n",
    "mee_svr_internal_test = mee(y_internal_test_cup, svr_preds_internal_test)\n",
    "mee_nn_sgd_internal_test = model_nn_sgd_cup.evaluate(x_internal_test_cup, y_internal_test_cup)[1]\n",
    "mee_nn_adam_internal_test = model_nn_adam_cup.evaluate(x_internal_test_cup, y_internal_test_cup)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbb671a6-6b3c-4fd6-a48c-72900f2aa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "ensemble_internal_test = np.zeros(y_internal_test_cup.shape)\n",
    "\n",
    "en_av_internal_test = ensemble_arithmetic_averange(ensemble_internal_test, svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test)\n",
    "\n",
    "en_we_internal_test = ensemble_weighted_averange(ensemble_internal_test, 1,\n",
    "                                       svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test,\n",
    "                                       mee_svr_internal_test, mee_nn_sgd_internal_test, mee_nn_adam_internal_test)\n",
    "\n",
    "x_stack_cup_internal_test = np.hstack((svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73949eda-48ec-4124-abe1-1295c2070ed5",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "acf72550-17e4-46b8-bb75-b2a21206f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST MEE Models --\n",
      "MEE SVC: 0.5778 - MEE NN-SGD: 0.5157 - MEE NN-Adam: 0.6107\n",
      "\n",
      "-- TEST Arithmetric Averange--\n",
      "Loss (MSE): 0.1650 - MEE: 0.5172\n",
      "\n",
      "-- TEST Weighted Averange --\n",
      "Loss (MSE): 0.1586 - MEE: 0.5120\n",
      "\n",
      "-- TEST Stacking Schema --\n",
      "Loss (MSE): 0.3000 - MEE: 0.5658\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_internal_test:.4f} - MEE NN-SGD: {mee_nn_sgd_internal_test:.4f} - MEE NN-Adam: {mee_nn_adam_internal_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Arithmetric Averange--')\n",
    "mee_internal_test_av_cup = mee(y_internal_test_cup, en_av_internal_test)\n",
    "mse_internal_test_av_cup = mean_squared_error(y_internal_test_cup, en_av_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_av_cup:.4f} - MEE: {mee_internal_test_av_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Averange --')\n",
    "mee_internal_test_we_cup = mee(y_internal_test_cup, en_we_internal_test)\n",
    "mse_internal_test_we_cup = mean_squared_error(y_internal_test_cup, en_we_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_we_cup:.4f} - MEE: {mee_internal_test_we_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Stacking Schema --')\n",
    "mee_internal_test_stack_cup = mee(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "mse_internal_test_stack_cup = mean_squared_error(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "print(f'Loss (MSE): {mse_internal_test_stack_cup:.4f} - MEE: {mee_internal_test_stack_cup:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59161f-059d-403b-b3ba-9e395dc4e004",
   "metadata": {},
   "source": [
    "## Retraining stacking model and Blind Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "380f974c-c16b-42c3-bc0f-85bff5d5fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Retraining with all dataset the stacking model\n",
    "x_stack_dev_cup = np.append(x_stack_cup_train, x_stack_cup_internal_test,axis=0)\n",
    "en_stack_train.fit(x_stack_dev_cup, y_dev_cup)\n",
    "\n",
    "# Blind test set predictions\n",
    "svr_preds_test = multi_svr.predict(x_test_cup)\n",
    "nn_sgd_preds_test = model_nn_sgd_cup.predict(x_test_cup)\n",
    "nn_adam_preds_test = model_nn_adam_cup.predict(x_test_cup)\n",
    "x_stack_test = np.hstack((svr_preds_test, nn_sgd_preds_test, nn_adam_preds_test))\n",
    "nn_preds_cup = en_stack_train.predict(x_stack_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89020a2f-92a1-446c-8828-9a23df6eb762",
   "metadata": {},
   "source": [
    "## Store Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3243c1b-4ce3-4dd7-82db-55583fe4d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_nn = {\n",
    "    'dev_arithmetic': {'mee': mee_train_av_cup, 'mse': mse_train_av_cup},\n",
    "    'test_arithmetic': {'mee': mee_internal_test_av_cup, 'mse': mse_internal_test_av_cup},\n",
    "    'dev_weighted': {'mee': mee_train_we_cup, 'mse': mse_train_we_cup},\n",
    "    'test_weighted': {'mee': mee_internal_test_we_cup, 'mse': mse_internal_test_we_cup},\n",
    "    'dev_stacking': {'mee': mee_train_stack_cup, 'mse': mse_train_stack_cup},\n",
    "    'test_stacking': {'mee': mee_internal_test_stack_cup, 'mse': mse_internal_test_stack_cup}\n",
    "}\n",
    "\n",
    "store_cup_result(results_dir + '/CUP/', en_stack_train.get_params(), report_nn, nn_preds_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c35525-6277-4e7a-86e0-da493c42c90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
