{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d3416e-3aee-496b-9a46-d86fab3fe008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15985a7e-4206-4f13-aaad-d38982df5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, ValidationCurveDisplay\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.initializers import RandomUniform, RandomNormal, HeNormal, GlorotUniform, Constant, Zeros\n",
    "from keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "dir_parts = os.getcwd().split(os.path.sep)\n",
    "root_index = dir_parts.index('ML-B')\n",
    "root_path = os.path.sep.join(dir_parts[:root_index + 1])\n",
    "sys.path.append(root_path + '/code/')\n",
    "from data.data_config import Dataset\n",
    "from data.data_utils import load_monk, load_cup, store_monk_result, store_cup_result\n",
    "from hyperparameter_tuning import grid_search, random_search, tuning_search_top_configs\n",
    "from training.solver import Solver\n",
    "from training.metrics import mean_euclidean_error as mee\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c866a15-7062-4d33-a206-2ec35f8643f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a076d-71ee-46dc-949f-caa3a3bf2df7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfe3c3-e764-453e-879e-96937623ab48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Ensemble'\n",
    "INTERNAL_TEST_SPLIT = 0.1 # internal test split percentage\n",
    "RANDOM_STATE = 128 # reproducibility\n",
    "N_SPLITS = 5 # cross-validation\n",
    "POLY_DEGREE = 3 # Polynomial features pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84564330-d564-4700-9865-88576073b71b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b342ae0-1ef2-4bdb-9128-cd10ac83adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "results_dir = root_path + '/results/' + MODEL_NAME\n",
    "\n",
    "# Filepaths (MONK)\n",
    "m1_dev_path, m1_test_path = Dataset.MONK_1.dev_path, Dataset.MONK_1.test_path # MONK 1\n",
    "m2_dev_path, m2_test_path = Dataset.MONK_2.dev_path, Dataset.MONK_2.test_path # MONK 2\n",
    "m3_dev_path, m3_test_path = Dataset.MONK_3.dev_path, Dataset.MONK_3.test_path # MONK 3\n",
    "\n",
    "# Filepaths (CUP)\n",
    "cup_dev_path, cup_test_path = Dataset.CUP.dev_path, Dataset.CUP.test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645437d0-0b3d-412a-a595-51c05110bd03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MONK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad13309-e6ed-43ce-b6be-b641c3a9f418",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model: NN-SGD and NN-Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8787a40f-87d1-45e9-b24d-90b45367ab60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nn_classifier( optimizer, hparams):\n",
    "    initializer = GlorotUniform(seed=RANDOM_STATE) # Glorot (Xavier)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(hparams['h_dim'], activation='tanh', input_shape=(17,), kernel_initializer=initializer),\n",
    "        Dense(1, activation='sigmoid', kernel_regularizer=l2(hparams['reg']))\n",
    "    ])\n",
    "       \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', 'mse'])\n",
    "    \n",
    "    model.hparams = hparams\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a5983-8312-4a05-891d-8f919b7935f3",
   "metadata": {},
   "source": [
    "## Ensemble Majority Voting Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6e6cfb-13c1-4cee-8c1b-5d15008633d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_majority_voting(ensemble, svc_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    for i in range(len(ensemble)):\n",
    "        if (svc_preds[i] + nn_sgd_preds[i] + nn_adam_preds[i]) > 1:\n",
    "            ensemble[i] = 1\n",
    "            \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6663eb-164a-426a-8198-6ce6f8b97b1d",
   "metadata": {},
   "source": [
    "## Ensemble Weigheted Voting Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563f4e9b-62fc-4146-8fda-3798e3ab89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weights used are the accuracy\n",
    "def ensemble_weighted_voting(ensemble, svc_preds, nn_sgd_preds, nn_adam_preds, acc_svc, acc_nn_sgd, acc_nn_adam):\n",
    "    for i in range(len(ensemble)):\n",
    "        if (svc_preds[i]*acc_svc + nn_sgd_preds[i]*acc_nn_sgd + nn_adam_preds[i]*acc_nn_adam)/(acc_svc + acc_nn_sgd + acc_nn_adam) >= 0.5:\n",
    "            ensemble[i] = 1\n",
    "            \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05596903-1255-4b87-9ca9-9caa36ad3172",
   "metadata": {},
   "source": [
    "## Ensemble Stacking Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7beb21f-c3de-4d86-9e07-4c383ae0035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_stacking(svc_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    svc_preds = svc_preds.reshape(-1,1)\n",
    "    x_stack = np.hstack((svc_preds, nn_sgd_preds, nn_adam_preds))\n",
    "    clf = LogisticRegression(random_state=RANDOM_STATE)\n",
    "    return clf, x_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859824b9-6c6c-4f09-b4d9-ad5f9c5e2b29",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MONK-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905cca8a-3ad3-4f0f-a1d8-8ff6253f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-1\n",
    "x_dev_m1, y_dev_m1, x_test_m1, y_test_m1 = load_monk(m1_dev_path, m1_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5a366-1520-4768-a26e-f461426e2393",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e2540a-245b-47fb-a675-e53749c02f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m1 = SVC(C=10, degree=2, kernel='poly')\n",
    "svc_m1.fit(x_dev_m1, y_dev_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102a1f41-1825-41af-9d22-e526af69b270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 01:09:28.446847: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6823 - accuracy: 0.6048 - mse: 0.2445\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6597 - accuracy: 0.6129 - mse: 0.2338\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6435 - accuracy: 0.6290 - mse: 0.2260\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.6694 - mse: 0.2193\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.6855 - mse: 0.2133\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6048 - accuracy: 0.6855 - mse: 0.2076\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5935 - accuracy: 0.6935 - mse: 0.2024\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5827 - accuracy: 0.7097 - mse: 0.1974\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5723 - accuracy: 0.7258 - mse: 0.1927\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5623 - accuracy: 0.7339 - mse: 0.1883\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5527 - accuracy: 0.7419 - mse: 0.1841\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5435 - accuracy: 0.7581 - mse: 0.1801\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5347 - accuracy: 0.7581 - mse: 0.1763\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5263 - accuracy: 0.7742 - mse: 0.1728\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5183 - accuracy: 0.7661 - mse: 0.1694\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5108 - accuracy: 0.7742 - mse: 0.1663\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5038 - accuracy: 0.7742 - mse: 0.1634\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4972 - accuracy: 0.7742 - mse: 0.1608\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4910 - accuracy: 0.7903 - mse: 0.1583\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4854 - accuracy: 0.8065 - mse: 0.1561\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4801 - accuracy: 0.8065 - mse: 0.1540\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4752 - accuracy: 0.7984 - mse: 0.1521\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4707 - accuracy: 0.7984 - mse: 0.1504\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4665 - accuracy: 0.7984 - mse: 0.1487\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4626 - accuracy: 0.7984 - mse: 0.1472\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4589 - accuracy: 0.7984 - mse: 0.1458\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4555 - accuracy: 0.8065 - mse: 0.1445\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4523 - accuracy: 0.8145 - mse: 0.1433\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4492 - accuracy: 0.8226 - mse: 0.1421\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4463 - accuracy: 0.8226 - mse: 0.1410\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4436 - accuracy: 0.8387 - mse: 0.1399\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.8387 - mse: 0.1389\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.8387 - mse: 0.1379\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4359 - accuracy: 0.8387 - mse: 0.1370\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4335 - accuracy: 0.8387 - mse: 0.1360\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.8387 - mse: 0.1352\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4289 - accuracy: 0.8387 - mse: 0.1343\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4266 - accuracy: 0.8387 - mse: 0.1334\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4243 - accuracy: 0.8468 - mse: 0.1326\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4221 - accuracy: 0.8468 - mse: 0.1318\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8387 - mse: 0.1310\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8387 - mse: 0.1302\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8387 - mse: 0.1294\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8387 - mse: 0.1287\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8468 - mse: 0.1280\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4091 - accuracy: 0.8468 - mse: 0.1272\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.8468 - mse: 0.1265\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4049 - accuracy: 0.8468 - mse: 0.1258\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4028 - accuracy: 0.8468 - mse: 0.1252\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.8468 - mse: 0.1245\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3986 - accuracy: 0.8468 - mse: 0.1238\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.8468 - mse: 0.1232\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3945 - accuracy: 0.8468 - mse: 0.1226\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3924 - accuracy: 0.8468 - mse: 0.1220\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3904 - accuracy: 0.8468 - mse: 0.1214\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3884 - accuracy: 0.8468 - mse: 0.1208\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.8468 - mse: 0.1202\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3845 - accuracy: 0.8468 - mse: 0.1196\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3825 - accuracy: 0.8468 - mse: 0.1190\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3806 - accuracy: 0.8468 - mse: 0.1185\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3787 - accuracy: 0.8468 - mse: 0.1179\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3768 - accuracy: 0.8468 - mse: 0.1174\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3750 - accuracy: 0.8468 - mse: 0.1168\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3731 - accuracy: 0.8468 - mse: 0.1163\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3713 - accuracy: 0.8468 - mse: 0.1158\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3695 - accuracy: 0.8468 - mse: 0.1153\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3677 - accuracy: 0.8468 - mse: 0.1148\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3660 - accuracy: 0.8468 - mse: 0.1143\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3642 - accuracy: 0.8468 - mse: 0.1138\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3625 - accuracy: 0.8468 - mse: 0.1133\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3608 - accuracy: 0.8468 - mse: 0.1128\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3590 - accuracy: 0.8468 - mse: 0.1123\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3574 - accuracy: 0.8468 - mse: 0.1118\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3557 - accuracy: 0.8468 - mse: 0.1113\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3540 - accuracy: 0.8468 - mse: 0.1108\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3523 - accuracy: 0.8468 - mse: 0.1103\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.8468 - mse: 0.1098\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3490 - accuracy: 0.8468 - mse: 0.1093\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3474 - accuracy: 0.8468 - mse: 0.1088\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3457 - accuracy: 0.8548 - mse: 0.1083\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3441 - accuracy: 0.8548 - mse: 0.1078\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3425 - accuracy: 0.8548 - mse: 0.1073\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8548 - mse: 0.1068\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3392 - accuracy: 0.8548 - mse: 0.1063\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3376 - accuracy: 0.8548 - mse: 0.1058\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3359 - accuracy: 0.8548 - mse: 0.1053\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3343 - accuracy: 0.8548 - mse: 0.1048\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3326 - accuracy: 0.8548 - mse: 0.1042\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3309 - accuracy: 0.8548 - mse: 0.1037\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3293 - accuracy: 0.8548 - mse: 0.1031\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.8548 - mse: 0.1026\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3259 - accuracy: 0.8548 - mse: 0.1020\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3242 - accuracy: 0.8629 - mse: 0.1015\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3225 - accuracy: 0.8629 - mse: 0.1009\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3208 - accuracy: 0.8629 - mse: 0.1003\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3190 - accuracy: 0.8629 - mse: 0.0997\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3173 - accuracy: 0.8629 - mse: 0.0991\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3155 - accuracy: 0.8629 - mse: 0.0985\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3137 - accuracy: 0.8629 - mse: 0.0979\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3120 - accuracy: 0.8629 - mse: 0.0973\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3102 - accuracy: 0.8629 - mse: 0.0966\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3083 - accuracy: 0.8629 - mse: 0.0960\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3065 - accuracy: 0.8629 - mse: 0.0953\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3047 - accuracy: 0.8629 - mse: 0.0947\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3028 - accuracy: 0.8629 - mse: 0.0940\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3010 - accuracy: 0.8629 - mse: 0.0933\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2991 - accuracy: 0.8629 - mse: 0.0926\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2972 - accuracy: 0.8629 - mse: 0.0919\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2953 - accuracy: 0.8629 - mse: 0.0912\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2934 - accuracy: 0.8629 - mse: 0.0905\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2915 - accuracy: 0.8629 - mse: 0.0898\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2896 - accuracy: 0.8710 - mse: 0.0891\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2877 - accuracy: 0.8710 - mse: 0.0884\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2858 - accuracy: 0.8710 - mse: 0.0876\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2838 - accuracy: 0.8710 - mse: 0.0869\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2819 - accuracy: 0.8710 - mse: 0.0862\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2800 - accuracy: 0.8710 - mse: 0.0854\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2780 - accuracy: 0.8710 - mse: 0.0847\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2761 - accuracy: 0.8710 - mse: 0.0839\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2742 - accuracy: 0.8790 - mse: 0.0832\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2722 - accuracy: 0.8790 - mse: 0.0824\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 0.8790 - mse: 0.0817\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2683 - accuracy: 0.8790 - mse: 0.0809\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2664 - accuracy: 0.8790 - mse: 0.0801\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2644 - accuracy: 0.8871 - mse: 0.0794\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2625 - accuracy: 0.8871 - mse: 0.0786\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2605 - accuracy: 0.8790 - mse: 0.0779\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2586 - accuracy: 0.8790 - mse: 0.0771\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2566 - accuracy: 0.8790 - mse: 0.0763\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 0.8790 - mse: 0.0756\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.8790 - mse: 0.0748\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.8790 - mse: 0.0740\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2489 - accuracy: 0.8871 - mse: 0.0733\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2470 - accuracy: 0.8952 - mse: 0.0725\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2451 - accuracy: 0.8952 - mse: 0.0718\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2431 - accuracy: 0.8952 - mse: 0.0710\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2412 - accuracy: 0.8952 - mse: 0.0703\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2393 - accuracy: 0.8952 - mse: 0.0695\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2374 - accuracy: 0.8952 - mse: 0.0688\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2355 - accuracy: 0.8952 - mse: 0.0680\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2337 - accuracy: 0.9113 - mse: 0.0673\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2318 - accuracy: 0.9113 - mse: 0.0666\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2299 - accuracy: 0.9113 - mse: 0.0658\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2280 - accuracy: 0.9194 - mse: 0.0651\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2262 - accuracy: 0.9274 - mse: 0.0644\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.9355 - mse: 0.0637\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.9355 - mse: 0.0629\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2206 - accuracy: 0.9355 - mse: 0.0622\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2188 - accuracy: 0.9355 - mse: 0.0615\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2170 - accuracy: 0.9355 - mse: 0.0608\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2151 - accuracy: 0.9355 - mse: 0.0601\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2133 - accuracy: 0.9355 - mse: 0.0594\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2114 - accuracy: 0.9355 - mse: 0.0586\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9355 - mse: 0.0579\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2077 - accuracy: 0.9355 - mse: 0.0572\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2058 - accuracy: 0.9355 - mse: 0.0565\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2040 - accuracy: 0.9355 - mse: 0.0558\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2021 - accuracy: 0.9355 - mse: 0.0550\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2002 - accuracy: 0.9355 - mse: 0.0543\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.9355 - mse: 0.0535\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1963 - accuracy: 0.9355 - mse: 0.0528\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1943 - accuracy: 0.9355 - mse: 0.0520\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1924 - accuracy: 0.9435 - mse: 0.0513\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1904 - accuracy: 0.9435 - mse: 0.0505\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1883 - accuracy: 0.9435 - mse: 0.0497\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1863 - accuracy: 0.9435 - mse: 0.0489\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1843 - accuracy: 0.9435 - mse: 0.0481\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1822 - accuracy: 0.9516 - mse: 0.0474\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1801 - accuracy: 0.9516 - mse: 0.0466\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9597 - mse: 0.0458\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1759 - accuracy: 0.9597 - mse: 0.0449\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1738 - accuracy: 0.9597 - mse: 0.0441\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9597 - mse: 0.0433\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1695 - accuracy: 0.9597 - mse: 0.0425\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1674 - accuracy: 0.9597 - mse: 0.0417\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1653 - accuracy: 0.9597 - mse: 0.0409\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1631 - accuracy: 0.9677 - mse: 0.0401\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.9677 - mse: 0.0393\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9677 - mse: 0.0384\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9758 - mse: 0.0376\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1545 - accuracy: 0.9758 - mse: 0.0368\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1524 - accuracy: 0.9839 - mse: 0.0360\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1502 - accuracy: 0.9839 - mse: 0.0352\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1480 - accuracy: 0.9839 - mse: 0.0344\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1459 - accuracy: 0.9839 - mse: 0.0336\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1437 - accuracy: 0.9919 - mse: 0.0327\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1415 - accuracy: 0.9919 - mse: 0.0319\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1393 - accuracy: 0.9919 - mse: 0.0311\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1371 - accuracy: 0.9919 - mse: 0.0303\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9919 - mse: 0.0295\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1327 - accuracy: 0.9919 - mse: 0.0287\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1305 - accuracy: 0.9919 - mse: 0.0279\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9919 - mse: 0.0271\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1260 - accuracy: 0.9919 - mse: 0.0263\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1237 - accuracy: 0.9919 - mse: 0.0255\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1215 - accuracy: 0.9919 - mse: 0.0247\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 1.0000 - mse: 0.0239\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1170 - accuracy: 1.0000 - mse: 0.0231\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1147 - accuracy: 1.0000 - mse: 0.0223\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1125 - accuracy: 1.0000 - mse: 0.0215\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1103 - accuracy: 1.0000 - mse: 0.0208\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1081 - accuracy: 1.0000 - mse: 0.0201\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1060 - accuracy: 1.0000 - mse: 0.0193\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1039 - accuracy: 1.0000 - mse: 0.0186\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1018 - accuracy: 1.0000 - mse: 0.0180\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0998 - accuracy: 1.0000 - mse: 0.0173\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 1.0000 - mse: 0.0167\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0959 - accuracy: 1.0000 - mse: 0.0161\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0940 - accuracy: 1.0000 - mse: 0.0155\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0921 - accuracy: 1.0000 - mse: 0.0149\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0903 - accuracy: 1.0000 - mse: 0.0144\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0886 - accuracy: 1.0000 - mse: 0.0138\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0869 - accuracy: 1.0000 - mse: 0.0134\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0853 - accuracy: 1.0000 - mse: 0.0129\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0837 - accuracy: 1.0000 - mse: 0.0124\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 1.0000 - mse: 0.0120\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0808 - accuracy: 1.0000 - mse: 0.0116\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0793 - accuracy: 1.0000 - mse: 0.0112\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 1.0000 - mse: 0.0108\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0766 - accuracy: 1.0000 - mse: 0.0105\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0753 - accuracy: 1.0000 - mse: 0.0101\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0741 - accuracy: 1.0000 - mse: 0.0098\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0729 - accuracy: 1.0000 - mse: 0.0095\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0717 - accuracy: 1.0000 - mse: 0.0092\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 1.0000 - mse: 0.0089\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0695 - accuracy: 1.0000 - mse: 0.0086\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0684 - accuracy: 1.0000 - mse: 0.0084\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0674 - accuracy: 1.0000 - mse: 0.0081\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0664 - accuracy: 1.0000 - mse: 0.0079\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 1.0000 - mse: 0.0076\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0645 - accuracy: 1.0000 - mse: 0.0074\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0635 - accuracy: 1.0000 - mse: 0.0072\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0627 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0618 - accuracy: 1.0000 - mse: 0.0068\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0610 - accuracy: 1.0000 - mse: 0.0066\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0601 - accuracy: 1.0000 - mse: 0.0065\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0593 - accuracy: 1.0000 - mse: 0.0063\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0586 - accuracy: 1.0000 - mse: 0.0061\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0578 - accuracy: 1.0000 - mse: 0.0060\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0571 - accuracy: 1.0000 - mse: 0.0058\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 1.0000 - mse: 0.0057\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 1.0000 - mse: 0.0055\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 1.0000 - mse: 0.0054\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0543 - accuracy: 1.0000 - mse: 0.0053\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 1.0000 - mse: 0.0051\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 1.0000 - mse: 0.0050\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 1.0000 - mse: 0.0049\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0519 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 1.0000 - mse: 0.0047\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0507 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0501 - accuracy: 1.0000 - mse: 0.0045\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0490 - accuracy: 1.0000 - mse: 0.0043\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0485 - accuracy: 1.0000 - mse: 0.0042\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0470 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 1.0000 - mse: 0.0038\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 1.0000 - mse: 0.0033\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0380 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0371 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 1.0000 - mse: 0.0019\n",
      "Restoring best model weights.\n",
      "Best loss: 0.032545305788517\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.7, 'h_dim': 4, 'reg': 0.0}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m1 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m1, x_dev_m1, y_dev_m1, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938c77fa-41a3-4d60-9f47-8b40befe52d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.7197 - accuracy: 0.5000 - mse: 0.2621\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8254 - accuracy: 0.5000 - mse: 0.3056\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6093 - accuracy: 0.7016 - mse: 0.2093\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.5000 - mse: 0.2448\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6547 - accuracy: 0.5000 - mse: 0.2335\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5711 - accuracy: 0.7500 - mse: 0.1928\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5308 - accuracy: 0.7258 - mse: 0.1748\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5300 - accuracy: 0.6774 - mse: 0.1781\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5006 - accuracy: 0.7016 - mse: 0.1677\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4532 - accuracy: 0.7339 - mse: 0.1482\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4324 - accuracy: 0.7984 - mse: 0.1394\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4023 - accuracy: 0.8548 - mse: 0.1271\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3469 - accuracy: 0.8710 - mse: 0.1059\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3137 - accuracy: 0.8629 - mse: 0.0956\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2977 - accuracy: 0.8629 - mse: 0.0904\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2735 - accuracy: 0.8629 - mse: 0.0816\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2400 - accuracy: 0.8710 - mse: 0.0700\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2111 - accuracy: 0.8790 - mse: 0.0607\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1825 - accuracy: 0.9113 - mse: 0.0513\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1512 - accuracy: 0.9194 - mse: 0.0395\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1287 - accuracy: 0.9919 - mse: 0.0306\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1081 - accuracy: 1.0000 - mse: 0.0223\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0891 - accuracy: 1.0000 - mse: 0.0158\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0731 - accuracy: 1.0000 - mse: 0.0108\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0604 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0509 - accuracy: 1.0000 - mse: 0.0046\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0426 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0260 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 1.0000 - mse: 7.8844e-04\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 1.0000 - mse: 5.6961e-04\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - mse: 4.0172e-04\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 1.0000 - mse: 2.8542e-04\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0121 - accuracy: 1.0000 - mse: 2.0701e-04\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0105 - accuracy: 1.0000 - mse: 1.5337e-04\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000 - mse: 1.1554e-04\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0080 - accuracy: 1.0000 - mse: 8.7995e-05\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 1.0000 - mse: 6.7476e-05\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - mse: 5.2065e-05\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - mse: 4.0509e-05\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - mse: 3.1863e-05\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - mse: 2.5363e-05\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - mse: 2.0405e-05\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - mse: 1.6548e-05\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - mse: 1.3487e-05\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - mse: 1.1030e-05\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 1.0000 - mse: 9.0530e-06\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - mse: 7.4662e-06\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - mse: 6.1978e-06\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 1.0000 - mse: 5.1863e-06\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - mse: 4.3791e-06\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - mse: 3.7329e-06\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - mse: 3.2127e-06\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - mse: 2.7908e-06\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - mse: 2.4458e-06\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 2.1608e-06\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - mse: 1.9230e-06\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9047e-04 - accuracy: 1.0000 - mse: 1.7224e-06\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.2682e-04 - accuracy: 1.0000 - mse: 1.5514e-06\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6947e-04 - accuracy: 1.0000 - mse: 1.4040e-06\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1757e-04 - accuracy: 1.0000 - mse: 1.2757e-06\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7042e-04 - accuracy: 1.0000 - mse: 1.1629e-06\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2741e-04 - accuracy: 1.0000 - mse: 1.0631e-06\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.8803e-04 - accuracy: 1.0000 - mse: 9.7398e-07\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.5188e-04 - accuracy: 1.0000 - mse: 8.9394e-07\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.1858e-04 - accuracy: 1.0000 - mse: 8.2167e-07\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.8785e-04 - accuracy: 1.0000 - mse: 7.5610e-07\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.5942e-04 - accuracy: 1.0000 - mse: 6.9638e-07\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3306e-04 - accuracy: 1.0000 - mse: 6.4183e-07\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0859e-04 - accuracy: 1.0000 - mse: 5.9185e-07\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.8582e-04 - accuracy: 1.0000 - mse: 5.4595e-07\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6459e-04 - accuracy: 1.0000 - mse: 5.0373e-07\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4477e-04 - accuracy: 1.0000 - mse: 4.6482e-07\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2622e-04 - accuracy: 1.0000 - mse: 4.2893e-07\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.0882e-04 - accuracy: 1.0000 - mse: 3.9579e-07\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.9248e-04 - accuracy: 1.0000 - mse: 3.6517e-07\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7708e-04 - accuracy: 1.0000 - mse: 3.3687e-07\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.6256e-04 - accuracy: 1.0000 - mse: 3.1071e-07\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4883e-04 - accuracy: 1.0000 - mse: 2.8652e-07\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.3583e-04 - accuracy: 1.0000 - mse: 2.6418e-07\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.2350e-04 - accuracy: 1.0000 - mse: 2.4353e-07\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1177e-04 - accuracy: 1.0000 - mse: 2.2448e-07\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0061e-04 - accuracy: 1.0000 - mse: 2.0689e-07\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8998e-04 - accuracy: 1.0000 - mse: 1.9068e-07\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.7983e-04 - accuracy: 1.0000 - mse: 1.7573e-07\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.7013e-04 - accuracy: 1.0000 - mse: 1.6197e-07\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6085e-04 - accuracy: 1.0000 - mse: 1.4930e-07\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5197e-04 - accuracy: 1.0000 - mse: 1.3764e-07\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4345e-04 - accuracy: 1.0000 - mse: 1.2692e-07\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3528e-04 - accuracy: 1.0000 - mse: 1.1707e-07\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2744e-04 - accuracy: 1.0000 - mse: 1.0802e-07\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1989e-04 - accuracy: 1.0000 - mse: 9.9698e-08\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1263e-04 - accuracy: 1.0000 - mse: 9.2055e-08\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0564e-04 - accuracy: 1.0000 - mse: 8.5031e-08\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9889e-04 - accuracy: 1.0000 - mse: 7.8575e-08\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9238e-04 - accuracy: 1.0000 - mse: 7.2644e-08\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8609e-04 - accuracy: 1.0000 - mse: 6.7190e-08\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8000e-04 - accuracy: 1.0000 - mse: 6.2171e-08\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7411e-04 - accuracy: 1.0000 - mse: 5.7554e-08\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6840e-04 - accuracy: 1.0000 - mse: 5.3300e-08\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6286e-04 - accuracy: 1.0000 - mse: 4.9381e-08\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5749e-04 - accuracy: 1.0000 - mse: 4.5766e-08\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5226e-04 - accuracy: 1.0000 - mse: 4.2432e-08\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4718e-04 - accuracy: 1.0000 - mse: 3.9351e-08\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4224e-04 - accuracy: 1.0000 - mse: 3.6502e-08\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3743e-04 - accuracy: 1.0000 - mse: 3.3868e-08\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3274e-04 - accuracy: 1.0000 - mse: 3.1431e-08\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2817e-04 - accuracy: 1.0000 - mse: 2.9172e-08\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2372e-04 - accuracy: 1.0000 - mse: 2.7077e-08\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1938e-04 - accuracy: 1.0000 - mse: 2.5134e-08\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1515e-04 - accuracy: 1.0000 - mse: 2.3330e-08\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1102e-04 - accuracy: 1.0000 - mse: 2.1654e-08\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0700e-04 - accuracy: 1.0000 - mse: 2.0095e-08\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0307e-04 - accuracy: 1.0000 - mse: 1.8646e-08\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.9248e-05 - accuracy: 1.0000 - mse: 1.7297e-08\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5522e-05 - accuracy: 1.0000 - mse: 1.6041e-08\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1892e-05 - accuracy: 1.0000 - mse: 1.4872e-08\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.8358e-05 - accuracy: 1.0000 - mse: 1.3783e-08\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4919e-05 - accuracy: 1.0000 - mse: 1.2767e-08\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1574e-05 - accuracy: 1.0000 - mse: 1.1820e-08\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.8322e-05 - accuracy: 1.0000 - mse: 1.0937e-08\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5163e-05 - accuracy: 1.0000 - mse: 1.0114e-08\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2095e-05 - accuracy: 1.0000 - mse: 9.3458e-09\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9119e-05 - accuracy: 1.0000 - mse: 8.6307e-09\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6232e-05 - accuracy: 1.0000 - mse: 7.9633e-09\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3435e-05 - accuracy: 1.0000 - mse: 7.3409e-09\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.0727e-05 - accuracy: 1.0000 - mse: 6.7613e-09\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.8106e-05 - accuracy: 1.0000 - mse: 6.2212e-09\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.5571e-05 - accuracy: 1.0000 - mse: 5.7185e-09\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.3122e-05 - accuracy: 1.0000 - mse: 5.2503e-09\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0757e-05 - accuracy: 1.0000 - mse: 4.8156e-09\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8474e-05 - accuracy: 1.0000 - mse: 4.4109e-09\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6273e-05 - accuracy: 1.0000 - mse: 4.0357e-09\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.4152e-05 - accuracy: 1.0000 - mse: 3.6876e-09\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.2109e-05 - accuracy: 1.0000 - mse: 3.3656e-09\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0143e-05 - accuracy: 1.0000 - mse: 3.0674e-09\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8252e-05 - accuracy: 1.0000 - mse: 2.7922e-09\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6435e-05 - accuracy: 1.0000 - mse: 2.5383e-09\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4690e-05 - accuracy: 1.0000 - mse: 2.3041e-09\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3015e-05 - accuracy: 1.0000 - mse: 2.0893e-09\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1409e-05 - accuracy: 1.0000 - mse: 1.8923e-09\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9869e-05 - accuracy: 1.0000 - mse: 1.7116e-09\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8395e-05 - accuracy: 1.0000 - mse: 1.5464e-09\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6985e-05 - accuracy: 1.0000 - mse: 1.3957e-09\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5636e-05 - accuracy: 1.0000 - mse: 1.2582e-09\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4346e-05 - accuracy: 1.0000 - mse: 1.1332e-09\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3115e-05 - accuracy: 1.0000 - mse: 1.0198e-09\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.1940e-05 - accuracy: 1.0000 - mse: 9.1695e-10\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.0819e-05 - accuracy: 1.0000 - mse: 8.2401e-10\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9750e-05 - accuracy: 1.0000 - mse: 7.3960e-10\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8732e-05 - accuracy: 1.0000 - mse: 6.6392e-10\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7762e-05 - accuracy: 1.0000 - mse: 5.9527e-10\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6839e-05 - accuracy: 1.0000 - mse: 5.3388e-10\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5961e-05 - accuracy: 1.0000 - mse: 4.7826e-10\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5126e-05 - accuracy: 1.0000 - mse: 4.2845e-10\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4333e-05 - accuracy: 1.0000 - mse: 3.8377e-10\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3579e-05 - accuracy: 1.0000 - mse: 3.4375e-10\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2863e-05 - accuracy: 1.0000 - mse: 3.0764e-10\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2183e-05 - accuracy: 1.0000 - mse: 2.7547e-10\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1538e-05 - accuracy: 1.0000 - mse: 2.4658e-10\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0926e-05 - accuracy: 1.0000 - mse: 2.2083e-10\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0346e-05 - accuracy: 1.0000 - mse: 1.9759e-10\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7957e-06 - accuracy: 1.0000 - mse: 1.7702e-10\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2741e-06 - accuracy: 1.0000 - mse: 1.5841e-10\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.7798e-06 - accuracy: 1.0000 - mse: 1.4193e-10\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3115e-06 - accuracy: 1.0000 - mse: 1.2717e-10\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8679e-06 - accuracy: 1.0000 - mse: 1.1384e-10\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7.4479e-06 - accuracy: 1.0000 - mse: 1.0202e-10\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.0502e-06 - accuracy: 1.0000 - mse: 9.1404e-11\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.6738e-06 - accuracy: 1.0000 - mse: 8.1907e-11\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3175e-06 - accuracy: 1.0000 - mse: 7.3466e-11\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.9803e-06 - accuracy: 1.0000 - mse: 6.5779e-11\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.6612e-06 - accuracy: 1.0000 - mse: 5.9077e-11\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3594e-06 - accuracy: 1.0000 - mse: 5.2889e-11\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.0738e-06 - accuracy: 1.0000 - mse: 4.7512e-11\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8037e-06 - accuracy: 1.0000 - mse: 4.2621e-11\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.5482e-06 - accuracy: 1.0000 - mse: 3.8214e-11\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.3065e-06 - accuracy: 1.0000 - mse: 3.4355e-11\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.0779e-06 - accuracy: 1.0000 - mse: 3.0792e-11\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8617e-06 - accuracy: 1.0000 - mse: 2.7646e-11\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6572e-06 - accuracy: 1.0000 - mse: 2.4807e-11\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4638e-06 - accuracy: 1.0000 - mse: 2.2259e-11\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.2809e-06 - accuracy: 1.0000 - mse: 1.9990e-11\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1079e-06 - accuracy: 1.0000 - mse: 1.7988e-11\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9442e-06 - accuracy: 1.0000 - mse: 1.6158e-11\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.7894e-06 - accuracy: 1.0000 - mse: 1.4521e-11\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6430e-06 - accuracy: 1.0000 - mse: 1.3052e-11\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5045e-06 - accuracy: 1.0000 - mse: 1.1695e-11\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3735e-06 - accuracy: 1.0000 - mse: 1.0540e-11\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2496e-06 - accuracy: 1.0000 - mse: 9.4793e-12\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1324e-06 - accuracy: 1.0000 - mse: 8.5264e-12\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0215e-06 - accuracy: 1.0000 - mse: 7.6322e-12\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9165e-06 - accuracy: 1.0000 - mse: 6.8953e-12\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8172e-06 - accuracy: 1.0000 - mse: 6.1893e-12\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7233e-06 - accuracy: 1.0000 - mse: 5.5720e-12\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6343e-06 - accuracy: 1.0000 - mse: 5.0104e-12\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5502e-06 - accuracy: 1.0000 - mse: 4.4992e-12\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4705e-06 - accuracy: 1.0000 - mse: 4.0572e-12\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3951e-06 - accuracy: 1.0000 - mse: 3.6339e-12\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3236e-06 - accuracy: 1.0000 - mse: 3.2692e-12\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2560e-06 - accuracy: 1.0000 - mse: 2.9631e-12\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1920e-06 - accuracy: 1.0000 - mse: 2.6476e-12\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1314e-06 - accuracy: 1.0000 - mse: 2.3965e-12\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0739e-06 - accuracy: 1.0000 - mse: 2.1662e-12\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0195e-06 - accuracy: 1.0000 - mse: 1.9317e-12\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.6799e-07 - accuracy: 1.0000 - mse: 1.7607e-12\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.1910e-07 - accuracy: 1.0000 - mse: 1.5731e-12\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.7281e-07 - accuracy: 1.0000 - mse: 1.4205e-12\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.2895e-07 - accuracy: 1.0000 - mse: 1.2789e-12\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.8735e-07 - accuracy: 1.0000 - mse: 1.1511e-12\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.4793e-07 - accuracy: 1.0000 - mse: 1.0310e-12\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1059e-07 - accuracy: 1.0000 - mse: 9.3452e-13\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7522e-07 - accuracy: 1.0000 - mse: 8.4121e-13\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.4167e-07 - accuracy: 1.0000 - mse: 7.5648e-13\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.0984e-07 - accuracy: 1.0000 - mse: 6.9682e-13\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.7965e-07 - accuracy: 1.0000 - mse: 6.2388e-13\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5105e-07 - accuracy: 1.0000 - mse: 5.5439e-13\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.2395e-07 - accuracy: 1.0000 - mse: 5.1050e-13\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9825e-07 - accuracy: 1.0000 - mse: 4.6071e-13\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7385e-07 - accuracy: 1.0000 - mse: 4.1136e-13\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.5069e-07 - accuracy: 1.0000 - mse: 3.7569e-13\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.2866e-07 - accuracy: 1.0000 - mse: 3.3895e-13\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0777e-07 - accuracy: 1.0000 - mse: 3.0821e-13\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8798e-07 - accuracy: 1.0000 - mse: 2.7295e-13\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6923e-07 - accuracy: 1.0000 - mse: 2.4687e-13\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5147e-07 - accuracy: 1.0000 - mse: 2.2480e-13\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3461e-07 - accuracy: 1.0000 - mse: 2.0493e-13\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1861e-07 - accuracy: 1.0000 - mse: 1.8668e-13\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0340e-07 - accuracy: 1.0000 - mse: 1.7114e-13\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8893e-07 - accuracy: 1.0000 - mse: 1.5211e-13\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7515e-07 - accuracy: 1.0000 - mse: 1.3708e-13\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6203e-07 - accuracy: 1.0000 - mse: 1.2420e-13\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4953e-07 - accuracy: 1.0000 - mse: 1.1874e-13\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3771e-07 - accuracy: 1.0000 - mse: 1.0739e-13\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2654e-07 - accuracy: 1.0000 - mse: 9.6750e-14\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1596e-07 - accuracy: 1.0000 - mse: 8.6233e-14\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0596e-07 - accuracy: 1.0000 - mse: 7.5199e-14\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.9647e-07 - accuracy: 1.0000 - mse: 7.0923e-14\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8748e-07 - accuracy: 1.0000 - mse: 6.2457e-14\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7897e-07 - accuracy: 1.0000 - mse: 5.9146e-14\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7089e-07 - accuracy: 1.0000 - mse: 5.1816e-14\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6320e-07 - accuracy: 1.0000 - mse: 4.9164e-14\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5589e-07 - accuracy: 1.0000 - mse: 4.2918e-14\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4894e-07 - accuracy: 1.0000 - mse: 4.0839e-14\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4232e-07 - accuracy: 1.0000 - mse: 3.9009e-14\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3600e-07 - accuracy: 1.0000 - mse: 3.3970e-14\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2996e-07 - accuracy: 1.0000 - mse: 3.2576e-14\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2419e-07 - accuracy: 1.0000 - mse: 2.8275e-14\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1869e-07 - accuracy: 1.0000 - mse: 2.2958e-14\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1344e-07 - accuracy: 1.0000 - mse: 2.1881e-14\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0844e-07 - accuracy: 1.0000 - mse: 2.1104e-14\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0368e-07 - accuracy: 1.0000 - mse: 1.7923e-14\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9156e-08 - accuracy: 1.0000 - mse: 1.7369e-14\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4878e-08 - accuracy: 1.0000 - mse: 1.8285e-14\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0847e-08 - accuracy: 1.0000 - mse: 1.8743e-14\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7053e-08 - accuracy: 1.0000 - mse: 1.5102e-14\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3435e-08 - accuracy: 1.0000 - mse: 1.4954e-14\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9968e-08 - accuracy: 1.0000 - mse: 1.3810e-14\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6652e-08 - accuracy: 1.0000 - mse: 1.3999e-14\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3506e-08 - accuracy: 1.0000 - mse: 1.1399e-14\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0551e-08 - accuracy: 1.0000 - mse: 1.1482e-14\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7812e-08 - accuracy: 1.0000 - mse: 1.0113e-14\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5313e-08 - accuracy: 1.0000 - mse: 7.9093e-15\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3068e-08 - accuracy: 1.0000 - mse: 8.8315e-15\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1088e-08 - accuracy: 1.0000 - mse: 7.1816e-15\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9378e-08 - accuracy: 1.0000 - mse: 8.4599e-15\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7936e-08 - accuracy: 1.0000 - mse: 6.4747e-15\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6758e-08 - accuracy: 1.0000 - mse: 7.7820e-15\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5794e-08 - accuracy: 1.0000 - mse: 6.3926e-15\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4894e-08 - accuracy: 1.0000 - mse: 6.4925e-15\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3638e-08 - accuracy: 1.0000 - mse: 5.1765e-15\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1976e-08 - accuracy: 1.0000 - mse: 5.8636e-15\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0239e-08 - accuracy: 1.0000 - mse: 5.6834e-15\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8606e-08 - accuracy: 1.0000 - mse: 5.4228e-15\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7152e-08 - accuracy: 1.0000 - mse: 5.9351e-15\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5866e-08 - accuracy: 1.0000 - mse: 5.3011e-15\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4752e-08 - accuracy: 1.0000 - mse: 4.4372e-15\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3795e-08 - accuracy: 1.0000 - mse: 4.3763e-15\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2981e-08 - accuracy: 1.0000 - mse: 4.5464e-15\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2301e-08 - accuracy: 1.0000 - mse: 5.4067e-15\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1749e-08 - accuracy: 1.0000 - mse: 5.0095e-15\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1318e-08 - accuracy: 1.0000 - mse: 3.8137e-15\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0986e-08 - accuracy: 1.0000 - mse: 4.3411e-15\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0732e-08 - accuracy: 1.0000 - mse: 3.4404e-15\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0497e-08 - accuracy: 1.0000 - mse: 3.8630e-15\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0202e-08 - accuracy: 1.0000 - mse: 5.0653e-15\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9729e-08 - accuracy: 1.0000 - mse: 3.2091e-15\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9082e-08 - accuracy: 1.0000 - mse: 3.1635e-15\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8330e-08 - accuracy: 1.0000 - mse: 4.4684e-15\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7576e-08 - accuracy: 1.0000 - mse: 2.9385e-15\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6874e-08 - accuracy: 1.0000 - mse: 4.2743e-15\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6257e-08 - accuracy: 1.0000 - mse: 4.4928e-15\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5715e-08 - accuracy: 1.0000 - mse: 2.3047e-15\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5278e-08 - accuracy: 1.0000 - mse: 3.3251e-15\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4936e-08 - accuracy: 1.0000 - mse: 4.0016e-15\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4682e-08 - accuracy: 1.0000 - mse: 4.5636e-15\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4551e-08 - accuracy: 1.0000 - mse: 3.0619e-15\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4491e-08 - accuracy: 1.0000 - mse: 4.1960e-15\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4498e-08 - accuracy: 1.0000 - mse: 3.6398e-15\n",
      "Restoring best model weights.\n",
      "Best loss: 3.449123653354036e-08\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m1 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m1, x_dev_m1, y_dev_m1, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de513a-1019-4b7c-b919-054ff7b325f0",
   "metadata": {},
   "source": [
    "## Ensemble - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9436244f-e383-486e-a1f7-38b02bb9cefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m1_preds_dev = svc_m1.predict(x_dev_m1)\n",
    "nn_sgd_m1_preds_dev = (np.rint(nn_sgd_m1.predict(x_dev_m1))).astype(int)\n",
    "nn_adam_m1_preds_dev = (np.rint(nn_adam_m1.predict(x_dev_m1))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m1_preds_dev = nn_sgd_m1.predict(x_dev_m1)\n",
    "#nn_adam_m1_preds_dev = nn_adam_m1.predict(x_dev_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c393712e-d64d-4882-b7a2-18d0a39ccb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0323 - accuracy: 1.0000 - mse: 0.0019\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.4498e-08 - accuracy: 1.0000 - mse: 3.6398e-15\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m1_dev = accuracy_score(y_dev_m1, svc_m1_preds_dev)\n",
    "acc_nn_sgd_m1_dev = nn_sgd_m1.evaluate(x_dev_m1, y_dev_m1)[1]\n",
    "acc_nn_adam_m1_dev = nn_adam_m1.evaluate(x_dev_m1, y_dev_m1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42799ad8-01e6-43de-94c2-02419f441d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m1), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev,\n",
    "                                          acc_svc_m1_dev, acc_nn_sgd_m1_dev, acc_nn_sgd_m1_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m1_preds_dev, nn_sgd_m1_preds_dev, nn_adam_m1_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3896e0-9ec9-41d9-a223-a72d2dee5d8e",
   "metadata": {},
   "source": [
    "## Results Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79ac744c-68b2-412d-ae72-cc3126fd83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m1_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m1_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m1_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m1 = accuracy_score(y_dev_m1, en_maj_vot_dev)\n",
    "mse_dev_maj_m1 = mean_squared_error(y_dev_m1, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m1:.4f} - Accuracy: {acc_dev_maj_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m1 = accuracy_score(y_dev_m1, en_wei_vot_dev)\n",
    "mse_dev_wei_m1 = mean_squared_error(y_dev_m1, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m1:.4f} - Accuracy: {acc_dev_wei_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m1 = accuracy_score(y_dev_m1, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m1 = mean_squared_error(y_dev_m1, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m1:.4f} - Accuracy: {acc_dev_stack_m1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc6df2-8fb3-4ca2-ac7f-16ae27be5d33",
   "metadata": {},
   "source": [
    "## Ensemble - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43942a9b-6a3d-4632-980b-218318def3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m1_preds_test = svc_m1.predict(x_test_m1)\n",
    "nn_sgd_m1_preds_test = (np.rint(nn_sgd_m1.predict(x_test_m1))).astype(int)\n",
    "nn_adam_m1_preds_test = (np.rint(nn_adam_m1.predict(x_test_m1))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m1_preds_test = nn_sgd_m1.predict(x_test_m1)\n",
    "#nn_adam_m1_preds_test = nn_adam_m1.predict(x_test_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe94d7c-b02e-4f3b-aa57-452da7cb9c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9907 - mse: 0.0108\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.5582e-08 - accuracy: 1.0000 - mse: 3.8154e-15\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m1_test = accuracy_score(y_test_m1, svc_m1_preds_test)\n",
    "acc_nn_sgd_m1_test = nn_sgd_m1.evaluate(x_test_m1, y_test_m1)[1]\n",
    "acc_nn_adam_m1_test = nn_adam_m1.evaluate(x_test_m1, y_test_m1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce695a3d-1d2d-4dc1-85f8-a1eb008294e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema\n",
    "ensemble_test = np.zeros(len(x_test_m1), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test,\n",
    "                                          acc_svc_m1_test, acc_nn_sgd_m1_test, acc_nn_sgd_m1_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m1_preds_test, nn_sgd_m1_preds_test, nn_adam_m1_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m1)                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1f2e6-b6f9-47ed-b997-5ec19b9aa8fa",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e328d0-7a8e-463d-b9f3-0b2bdd3700c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 0.9907 - Accuracy NN-Adam: 1.0000\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m1_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m1_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m1_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m1 = accuracy_score(y_test_m1, en_maj_vot_test)\n",
    "mse_test_maj_m1 = mean_squared_error(y_test_m1, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m1:.4f} - Accuracy: {acc_test_maj_m1:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m1 = accuracy_score(y_test_m1, en_wei_vot_test)\n",
    "mse_test_wei_m1 = mean_squared_error(y_test_m1, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m1:.4f} - Accuracy: {acc_test_wei_m1:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m1 = accuracy_score(y_test_m1, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m1 = mean_squared_error(y_test_m1, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m1:.4f} - Accuracy: {acc_test_stack_m1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a9e02-7de5-4fe0-8b53-5d7e98839b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523b49cf-3f01-496d-a99a-d7bded86f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m1 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m1, 'mse': mse_dev_maj_m1},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m1, 'mse': mse_test_maj_m1},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m1, 'mse': mse_dev_wei_m1},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m1, 'mse': mse_test_wei_m1},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m1, 'mse': mse_dev_stack_m1},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m1, 'mse': mse_test_stack_m1}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK1/', en_stack_dev.get_params(), report_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216aed0-5ba0-4816-a889-a3be455e73c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MONK-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9efe875-d6ff-42c0-b719-85a47a5855b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-2\n",
    "x_dev_m2, y_dev_m2, x_test_m2, y_test_m2 = load_monk(m2_dev_path, m2_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd9659-b9c0-4412-8c1f-f93964735cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2099dfaa-54d5-46e9-b887-112af690e70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=50, degree=2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=50, degree=2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=50, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m2 = SVC(C=50, degree=2, kernel='poly')\n",
    "svc_m2.fit(x_dev_m2, y_dev_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5886e2a0-bc71-4c89-8b71-8f87283334e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6605 - accuracy: 0.6154 - mse: 0.2337\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6505 - accuracy: 0.6272 - mse: 0.2287\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6467 - accuracy: 0.6568 - mse: 0.2270\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6442 - accuracy: 0.6686 - mse: 0.2258\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.6627 - mse: 0.2249\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6400 - accuracy: 0.6686 - mse: 0.2240\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.6686 - mse: 0.2232\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6362 - accuracy: 0.6627 - mse: 0.2224\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6344 - accuracy: 0.6568 - mse: 0.2216\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6326 - accuracy: 0.6568 - mse: 0.2208\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6308 - accuracy: 0.6627 - mse: 0.2201\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6289 - accuracy: 0.6627 - mse: 0.2193\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6271 - accuracy: 0.6568 - mse: 0.2185\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6252 - accuracy: 0.6568 - mse: 0.2177\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6233 - accuracy: 0.6627 - mse: 0.2169\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6214 - accuracy: 0.6627 - mse: 0.2160\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6194 - accuracy: 0.6627 - mse: 0.2152\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6173 - accuracy: 0.6627 - mse: 0.2143\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6152 - accuracy: 0.6627 - mse: 0.2134\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6130 - accuracy: 0.6746 - mse: 0.2125\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6108 - accuracy: 0.6746 - mse: 0.2115\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6085 - accuracy: 0.6805 - mse: 0.2105\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6061 - accuracy: 0.6864 - mse: 0.2095\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6805 - mse: 0.2085\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.6805 - mse: 0.2074\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5984 - accuracy: 0.6805 - mse: 0.2063\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.6746 - mse: 0.2052\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5929 - accuracy: 0.6864 - mse: 0.2040\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5900 - accuracy: 0.6864 - mse: 0.2028\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5871 - accuracy: 0.6864 - mse: 0.2016\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5841 - accuracy: 0.6805 - mse: 0.2004\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5810 - accuracy: 0.6746 - mse: 0.1991\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5779 - accuracy: 0.6686 - mse: 0.1978\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5747 - accuracy: 0.6686 - mse: 0.1965\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5714 - accuracy: 0.6746 - mse: 0.1952\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.6805 - mse: 0.1938\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5647 - accuracy: 0.6864 - mse: 0.1924\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5613 - accuracy: 0.6923 - mse: 0.1910\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5579 - accuracy: 0.6982 - mse: 0.1896\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5544 - accuracy: 0.6982 - mse: 0.1882\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5508 - accuracy: 0.6982 - mse: 0.1868\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5473 - accuracy: 0.6982 - mse: 0.1854\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5437 - accuracy: 0.6923 - mse: 0.1839\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5401 - accuracy: 0.6982 - mse: 0.1825\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.7041 - mse: 0.1810\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7101 - mse: 0.1796\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7160 - mse: 0.1781\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5257 - accuracy: 0.7160 - mse: 0.1767\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5220 - accuracy: 0.7160 - mse: 0.1752\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5184 - accuracy: 0.7278 - mse: 0.1738\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.7278 - mse: 0.1723\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5113 - accuracy: 0.7456 - mse: 0.1709\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5077 - accuracy: 0.7515 - mse: 0.1695\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5042 - accuracy: 0.7515 - mse: 0.1680\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5007 - accuracy: 0.7515 - mse: 0.1666\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.7633 - mse: 0.1653\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4938 - accuracy: 0.7633 - mse: 0.1639\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4904 - accuracy: 0.7692 - mse: 0.1625\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4870 - accuracy: 0.7751 - mse: 0.1612\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4836 - accuracy: 0.7751 - mse: 0.1598\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4803 - accuracy: 0.7751 - mse: 0.1585\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4771 - accuracy: 0.7751 - mse: 0.1572\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4738 - accuracy: 0.7811 - mse: 0.1559\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.7811 - mse: 0.1547\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.7811 - mse: 0.1534\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4644 - accuracy: 0.7870 - mse: 0.1522\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4613 - accuracy: 0.7988 - mse: 0.1510\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4583 - accuracy: 0.7988 - mse: 0.1498\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4553 - accuracy: 0.7988 - mse: 0.1486\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4524 - accuracy: 0.7929 - mse: 0.1474\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4495 - accuracy: 0.7929 - mse: 0.1463\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4466 - accuracy: 0.7929 - mse: 0.1452\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7929 - mse: 0.1440\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4410 - accuracy: 0.7988 - mse: 0.1429\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4382 - accuracy: 0.7988 - mse: 0.1419\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4355 - accuracy: 0.8047 - mse: 0.1408\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4328 - accuracy: 0.8107 - mse: 0.1397\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4301 - accuracy: 0.8107 - mse: 0.1387\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.8166 - mse: 0.1377\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.8166 - mse: 0.1367\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.8166 - mse: 0.1357\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8166 - mse: 0.1347\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4173 - accuracy: 0.8166 - mse: 0.1337\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4148 - accuracy: 0.8225 - mse: 0.1327\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4124 - accuracy: 0.8343 - mse: 0.1318\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8343 - mse: 0.1308\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.8462 - mse: 0.1299\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8521 - mse: 0.1290\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8521 - mse: 0.1281\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4004 - accuracy: 0.8521 - mse: 0.1271\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8580 - mse: 0.1262\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8580 - mse: 0.1253\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3935 - accuracy: 0.8580 - mse: 0.1244\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8580 - mse: 0.1235\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3889 - accuracy: 0.8639 - mse: 0.1227\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3866 - accuracy: 0.8698 - mse: 0.1218\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3843 - accuracy: 0.8698 - mse: 0.1209\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3821 - accuracy: 0.8698 - mse: 0.1200\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3798 - accuracy: 0.8698 - mse: 0.1191\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3775 - accuracy: 0.8698 - mse: 0.1182\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3753 - accuracy: 0.8698 - mse: 0.1174\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3730 - accuracy: 0.8698 - mse: 0.1165\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3707 - accuracy: 0.8698 - mse: 0.1156\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3684 - accuracy: 0.8698 - mse: 0.1147\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.8698 - mse: 0.1138\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.8698 - mse: 0.1129\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3616 - accuracy: 0.8757 - mse: 0.1120\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3592 - accuracy: 0.8757 - mse: 0.1111\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3569 - accuracy: 0.8757 - mse: 0.1102\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3546 - accuracy: 0.8817 - mse: 0.1092\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3522 - accuracy: 0.8817 - mse: 0.1083\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3498 - accuracy: 0.8817 - mse: 0.1074\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8757 - mse: 0.1064\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3450 - accuracy: 0.8757 - mse: 0.1055\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8757 - mse: 0.1045\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.8757 - mse: 0.1035\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3375 - accuracy: 0.8757 - mse: 0.1025\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.8757 - mse: 0.1015\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3324 - accuracy: 0.8757 - mse: 0.1005\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8757 - mse: 0.0994\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8757 - mse: 0.0984\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8757 - mse: 0.0973\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3219 - accuracy: 0.8757 - mse: 0.0963\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.8757 - mse: 0.0952\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8757 - mse: 0.0941\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8757 - mse: 0.0930\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3108 - accuracy: 0.8757 - mse: 0.0918\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.8757 - mse: 0.0907\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3050 - accuracy: 0.8757 - mse: 0.0895\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8757 - mse: 0.0883\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2991 - accuracy: 0.8757 - mse: 0.0872\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2961 - accuracy: 0.8817 - mse: 0.0859\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2930 - accuracy: 0.8817 - mse: 0.0847\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.8935 - mse: 0.0834\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2867 - accuracy: 0.8994 - mse: 0.0822\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2835 - accuracy: 0.9053 - mse: 0.0809\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2802 - accuracy: 0.9053 - mse: 0.0795\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2768 - accuracy: 0.9053 - mse: 0.0781\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2733 - accuracy: 0.9112 - mse: 0.0767\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2697 - accuracy: 0.9172 - mse: 0.0753\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2660 - accuracy: 0.9172 - mse: 0.0738\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2622 - accuracy: 0.9172 - mse: 0.0722\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2583 - accuracy: 0.9172 - mse: 0.0706\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.9172 - mse: 0.0689\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2498 - accuracy: 0.9290 - mse: 0.0672\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.9290 - mse: 0.0653\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9349 - mse: 0.0634\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9349 - mse: 0.0613\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 0.9349 - mse: 0.0592\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2251 - accuracy: 0.9408 - mse: 0.0569\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2196 - accuracy: 0.9527 - mse: 0.0546\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2138 - accuracy: 0.9586 - mse: 0.0522\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2080 - accuracy: 0.9586 - mse: 0.0497\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2021 - accuracy: 0.9704 - mse: 0.0472\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1962 - accuracy: 0.9763 - mse: 0.0448\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1904 - accuracy: 0.9763 - mse: 0.0424\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1847 - accuracy: 0.9763 - mse: 0.0401\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1793 - accuracy: 0.9941 - mse: 0.0379\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1740 - accuracy: 0.9941 - mse: 0.0358\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1689 - accuracy: 0.9941 - mse: 0.0339\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1640 - accuracy: 0.9941 - mse: 0.0321\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1593 - accuracy: 0.9941 - mse: 0.0303\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1548 - accuracy: 0.9941 - mse: 0.0287\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9941 - mse: 0.0272\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.9941 - mse: 0.0258\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.9941 - mse: 0.0245\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 1.0000 - mse: 0.0233\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 1.0000 - mse: 0.0221\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 1.0000 - mse: 0.0211\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 1.0000 - mse: 0.0200\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 1.0000 - mse: 0.0191\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1218 - accuracy: 1.0000 - mse: 0.0182\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 1.0000 - mse: 0.0173\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1159 - accuracy: 1.0000 - mse: 0.0165\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1132 - accuracy: 1.0000 - mse: 0.0158\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1105 - accuracy: 1.0000 - mse: 0.0151\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 1.0000 - mse: 0.0144\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1055 - accuracy: 1.0000 - mse: 0.0138\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1032 - accuracy: 1.0000 - mse: 0.0132\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 1.0000 - mse: 0.0126\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0987 - accuracy: 1.0000 - mse: 0.0121\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0966 - accuracy: 1.0000 - mse: 0.0116\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 1.0000 - mse: 0.0111\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0925 - accuracy: 1.0000 - mse: 0.0106\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0906 - accuracy: 1.0000 - mse: 0.0102\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0888 - accuracy: 1.0000 - mse: 0.0098\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 1.0000 - mse: 0.0094\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 1.0000 - mse: 0.0091\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 1.0000 - mse: 0.0087\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 1.0000 - mse: 0.0084\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 1.0000 - mse: 0.0081\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 1.0000 - mse: 0.0078\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0775 - accuracy: 1.0000 - mse: 0.0075\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 1.0000 - mse: 0.0072\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 1.0000 - mse: 0.0070\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0734 - accuracy: 1.0000 - mse: 0.0067\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0721 - accuracy: 1.0000 - mse: 0.0065\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0709 - accuracy: 1.0000 - mse: 0.0063\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 1.0000 - mse: 0.0061\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0685 - accuracy: 1.0000 - mse: 0.0059\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 1.0000 - mse: 0.0057\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0662 - accuracy: 1.0000 - mse: 0.0055\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 1.0000 - mse: 0.0053\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0641 - accuracy: 1.0000 - mse: 0.0051\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 1.0000 - mse: 0.0050\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 1.0000 - mse: 0.0048\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 1.0000 - mse: 0.0047\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 1.0000 - mse: 0.0045\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 1.0000 - mse: 0.0044\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 1.0000 - mse: 0.0043\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 1.0000 - mse: 0.0041\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 1.0000 - mse: 0.0040\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0558 - accuracy: 1.0000 - mse: 0.0039\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 1.0000 - mse: 0.0038\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 1.0000 - mse: 0.0037\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 1.0000 - mse: 0.0036\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 1.0000 - mse: 0.0035\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 1.0000 - mse: 0.0034\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 1.0000 - mse: 0.0033\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0506 - accuracy: 1.0000 - mse: 0.0032\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0493 - accuracy: 1.0000 - mse: 0.0031\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 1.0000 - mse: 0.0030\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 1.0000 - mse: 0.0029\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 1.0000 - mse: 0.0028\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 1.0000 - mse: 0.0027\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0451 - accuracy: 1.0000 - mse: 0.0026\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 1.0000 - mse: 0.0025\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0435 - accuracy: 1.0000 - mse: 0.0024\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0430 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0425 - accuracy: 1.0000 - mse: 0.0023\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0420 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0415 - accuracy: 1.0000 - mse: 0.0022\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0410 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0406 - accuracy: 1.0000 - mse: 0.0021\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0397 - accuracy: 1.0000 - mse: 0.0020\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 1.0000 - mse: 0.0019\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 1.0000 - mse: 0.0018\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 1.0000 - mse: 0.0017\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 1.0000 - mse: 0.0016\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0346 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 1.0000 - mse: 0.0015\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0333 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 1.0000 - mse: 0.0014\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 1.0000 - mse: 0.0013\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0309 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 1.0000 - mse: 0.0012\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 1.0000 - mse: 0.0011\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0288 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 1.0000 - mse: 0.0010\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0281 - accuracy: 1.0000 - mse: 9.9419e-04\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 1.0000 - mse: 9.7787e-04\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 1.0000 - mse: 9.6194e-04\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0274 - accuracy: 1.0000 - mse: 9.4637e-04\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0272 - accuracy: 1.0000 - mse: 9.3117e-04\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0270 - accuracy: 1.0000 - mse: 9.1630e-04\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 1.0000 - mse: 9.0178e-04\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - mse: 8.8758e-04\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000 - mse: 8.7370e-04\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 1.0000 - mse: 8.6013e-04\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 1.0000 - mse: 8.4686e-04\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 1.0000 - mse: 8.3388e-04\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 1.0000 - mse: 8.2119e-04\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 1.0000 - mse: 8.0877e-04\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 1.0000 - mse: 7.9661e-04\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0249 - accuracy: 1.0000 - mse: 7.8472e-04\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 1.0000 - mse: 7.7308e-04\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 1.0000 - mse: 7.6169e-04\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 1.0000 - mse: 7.5053e-04\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 1.0000 - mse: 7.3961e-04\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 1.0000 - mse: 7.2892e-04\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 1.0000 - mse: 7.1844e-04\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 1.0000 - mse: 7.0819e-04\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 1.0000 - mse: 6.9814e-04\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 1.0000 - mse: 6.8829e-04\n",
      "Restoring best model weights.\n",
      "Best loss: 0.023355450481176376\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.8, 'h_dim': 4, 'reg': 0}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m2 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m2, x_dev_m2, y_dev_m2, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb58a4ea-352b-43b8-b829-2681b07069e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.8006 - accuracy: 0.4024 - mse: 0.3004\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6655 - accuracy: 0.6213 - mse: 0.2363\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7250 - accuracy: 0.3787 - mse: 0.2658\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.6213 - mse: 0.2364\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6887 - accuracy: 0.6213 - mse: 0.2460\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7009 - accuracy: 0.6213 - mse: 0.2508\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6739 - accuracy: 0.6213 - mse: 0.2399\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6653 - accuracy: 0.6213 - mse: 0.2362\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6856 - accuracy: 0.6213 - mse: 0.2462\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6836 - accuracy: 0.6213 - mse: 0.2452\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2367\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6666 - accuracy: 0.6213 - mse: 0.2367\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6787 - accuracy: 0.6213 - mse: 0.2419\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6772 - accuracy: 0.6213 - mse: 0.2413\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6661 - accuracy: 0.6213 - mse: 0.2365\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6649 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6736 - accuracy: 0.6213 - mse: 0.2403\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6729 - accuracy: 0.6213 - mse: 0.2399\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6650 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6710 - accuracy: 0.6213 - mse: 0.2387\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6697 - accuracy: 0.6213 - mse: 0.2381\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6641 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6694 - accuracy: 0.6213 - mse: 0.2382\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.6213 - mse: 0.2369\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2366\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6676 - accuracy: 0.6213 - mse: 0.2372\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6641 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6668 - accuracy: 0.6213 - mse: 0.2369\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6650 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.6213 - mse: 0.2364\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6651 - accuracy: 0.6213 - mse: 0.2361\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2359\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6649 - accuracy: 0.6213 - mse: 0.2360\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6648 - accuracy: 0.6213 - mse: 0.2359\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6643 - accuracy: 0.6213 - mse: 0.2357\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2356\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6640 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6639 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6638 - accuracy: 0.6213 - mse: 0.2355\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6635 - accuracy: 0.6213 - mse: 0.2353\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.6213 - mse: 0.2354\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354Restoring model weights from the end of the best epoch: 27.\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6636 - accuracy: 0.6213 - mse: 0.2354\n",
      "\n",
      "Epoch 77: early stopping.\n",
      "Best loss: 0.6634232997894287\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m2 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m2, x_dev_m2, y_dev_m2, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbf914-d70e-4b69-be8f-737c7779d4ee",
   "metadata": {},
   "source": [
    "## Ensemble - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4723375-3d8a-4ab4-9ffc-4b200a8d9bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m2_preds_dev = svc_m2.predict(x_dev_m2)\n",
    "nn_sgd_m2_preds_dev = (np.rint(nn_sgd_m2.predict(x_dev_m2))).astype(int)\n",
    "nn_adam_m2_preds_dev = (np.rint(nn_adam_m2.predict(x_dev_m2))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m2_preds_dev = nn_sgd_m2.predict(x_dev_m2)\n",
    "#nn_adam_m2_preds_dev = nn_adam_m2.predict(x_dev_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2366af5b-9db8-463f-b7f0-4a9d0971cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 1.0000 - mse: 6.7865e-04\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6663 - accuracy: 0.6213 - mse: 0.2366\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m2_dev = accuracy_score(y_dev_m2, svc_m2_preds_dev)\n",
    "acc_nn_sgd_m2_dev = nn_sgd_m2.evaluate(x_dev_m2, y_dev_m2)[1]\n",
    "acc_nn_adam_m2_dev = nn_adam_m2.evaluate(x_dev_m2, y_dev_m2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1361156e-0e28-4dca-b57e-e99104b7d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m2), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev,\n",
    "                                          acc_svc_m2_dev, acc_nn_sgd_m2_dev, acc_nn_sgd_m2_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m2_preds_dev, nn_sgd_m2_preds_dev, nn_adam_m2_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m2)\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcaddb-2d9a-4c04-ad07-c67574eb444d",
   "metadata": {},
   "source": [
    "## Results Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9bc7730-ce5d-42c6-84fc-2348ba2adead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 0.6213\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m2_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m2_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m2_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m2 = accuracy_score(y_dev_m2, en_maj_vot_dev)\n",
    "mse_dev_maj_m2 = mean_squared_error(y_dev_m2, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m2:.4f} - Accuracy: {acc_dev_maj_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m2 = accuracy_score(y_dev_m2, en_wei_vot_dev)\n",
    "mse_dev_wei_m2 = mean_squared_error(y_dev_m2, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m2:.4f} - Accuracy: {acc_dev_wei_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m2 = accuracy_score(y_dev_m2, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m2 = mean_squared_error(y_dev_m2, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m2:.4f} - Accuracy: {acc_dev_stack_m2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e770d-0fd9-4ea5-b60c-28101d3e4275",
   "metadata": {},
   "source": [
    "## Ensemble - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46ed0440-ed1d-4052-956c-e54183d293a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "14/14 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m2_preds_test = svc_m2.predict(x_test_m2)\n",
    "nn_sgd_m2_preds_test = (np.rint(nn_sgd_m2.predict(x_test_m2))).astype(int)\n",
    "nn_adam_m2_preds_test = (np.rint(nn_adam_m2.predict(x_test_m2))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m2_preds_test = nn_sgd_m2.predict(x_test_m2)\n",
    "#nn_adam_m2_preds_test = nn_adam_m2.predict(x_test_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afdd5e3f-3e76-4646-a6eb-7675b4f21632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - mse: 0.0012\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6713 - mse: 0.2208\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m2_test = accuracy_score(y_test_m2, svc_m2_preds_test)\n",
    "acc_nn_sgd_m2_test = nn_sgd_m2.evaluate(x_test_m2, y_test_m2)[1]\n",
    "acc_nn_adam_m2_test = nn_adam_m2.evaluate(x_test_m2, y_test_m2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c456953f-d5e5-4614-895b-33f7e8831390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema\n",
    "ensemble_test = np.zeros(len(x_test_m2), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test,\n",
    "                                          acc_svc_m2_test, acc_nn_sgd_m2_test, acc_nn_sgd_m2_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m2_preds_test, nn_sgd_m2_preds_test, nn_adam_m2_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m2)                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921dd99a-cb67-4b69-9922-2bd678eac91d",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0932bbe8-665d-4647-8771-9a9c53e489db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 1.0000 - Accuracy NN-SGD: 1.0000 - Accuracy NN-Adam: 0.6713\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0000 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m2_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m2_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m2_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m2 = accuracy_score(y_test_m2, en_maj_vot_test)\n",
    "mse_test_maj_m2 = mean_squared_error(y_test_m2, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m2:.4f} - Accuracy: {acc_test_maj_m2:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m2 = accuracy_score(y_test_m2, en_wei_vot_test)\n",
    "mse_test_wei_m2 = mean_squared_error(y_test_m2, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m2:.4f} - Accuracy: {acc_test_wei_m2:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m2 = accuracy_score(y_test_m2, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m2 = mean_squared_error(y_test_m2, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m2:.4f} - Accuracy: {acc_test_stack_m2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ca457-cb8a-48d7-9c9e-4e9d473efe3a",
   "metadata": {},
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "569ead2f-5368-4648-b36c-73f9aa69b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m2 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m2, 'mse': mse_dev_maj_m2},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m2, 'mse': mse_test_maj_m2},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m2, 'mse': mse_dev_wei_m2},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m2, 'mse': mse_test_wei_m2},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m2, 'mse': mse_dev_stack_m2},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m2, 'mse': mse_test_stack_m2}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK2/', en_stack_dev.get_params(), report_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2e408-6d1b-4c43-b70b-c4fec0da831d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MONK-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f02aae1-f31b-4403-9d85-fbfaf144d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MONK-3\n",
    "x_dev_m3, y_dev_m3, x_test_m3, y_test_m3 = load_monk(m3_dev_path, m3_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef02d30-2efb-4f50-9f4c-c097cb021264",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5461f5ae-6536-4b50-ab54-f1f81e4444bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, degree=2, gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, degree=2, gamma=&#x27;auto&#x27;, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, degree=2, gamma='auto', kernel='poly')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC Training\n",
    "svc_m3 = SVC(C=10, degree=2, gamma='auto', kernel='poly')\n",
    "svc_m3.fit(x_dev_m3, y_dev_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e89050a9-a2d0-4a50-9ba1-8839be3bc549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.6720 - accuracy: 0.6557 - mse: 0.2392\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6583 - accuracy: 0.6721 - mse: 0.2324\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6444 - accuracy: 0.7295 - mse: 0.2255\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6298 - accuracy: 0.7951 - mse: 0.2183\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6143 - accuracy: 0.8033 - mse: 0.2106\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5975 - accuracy: 0.8115 - mse: 0.2024\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5796 - accuracy: 0.8197 - mse: 0.1938\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5606 - accuracy: 0.8361 - mse: 0.1846\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5406 - accuracy: 0.8607 - mse: 0.1752\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5200 - accuracy: 0.8607 - mse: 0.1656\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4989 - accuracy: 0.9016 - mse: 0.1559\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.9098 - mse: 0.1464\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.9262 - mse: 0.1371\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.9262 - mse: 0.1283\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.9262 - mse: 0.1200\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3987 - accuracy: 0.9262 - mse: 0.1123\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3813 - accuracy: 0.9344 - mse: 0.1052\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3652 - accuracy: 0.9344 - mse: 0.0988\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3503 - accuracy: 0.9344 - mse: 0.0931\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3366 - accuracy: 0.9344 - mse: 0.0880\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3241 - accuracy: 0.9344 - mse: 0.0834\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3129 - accuracy: 0.9344 - mse: 0.0794\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.9344 - mse: 0.0760\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2934 - accuracy: 0.9344 - mse: 0.0729\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2851 - accuracy: 0.9344 - mse: 0.0702\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2776 - accuracy: 0.9344 - mse: 0.0679\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2708 - accuracy: 0.9344 - mse: 0.0658\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2647 - accuracy: 0.9344 - mse: 0.0641\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2591 - accuracy: 0.9344 - mse: 0.0625\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2541 - accuracy: 0.9344 - mse: 0.0611\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9344 - mse: 0.0598\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9344 - mse: 0.0587\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2414 - accuracy: 0.9344 - mse: 0.0577\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2378 - accuracy: 0.9344 - mse: 0.0568\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2345 - accuracy: 0.9344 - mse: 0.0560\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2314 - accuracy: 0.9344 - mse: 0.0552\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2285 - accuracy: 0.9344 - mse: 0.0545\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2258 - accuracy: 0.9344 - mse: 0.0539\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2233 - accuracy: 0.9344 - mse: 0.0532\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2209 - accuracy: 0.9344 - mse: 0.0527\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9344 - mse: 0.0522\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2165 - accuracy: 0.9344 - mse: 0.0517\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2145 - accuracy: 0.9344 - mse: 0.0512\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2126 - accuracy: 0.9344 - mse: 0.0507\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2108 - accuracy: 0.9344 - mse: 0.0503\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2090 - accuracy: 0.9344 - mse: 0.0499\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2073 - accuracy: 0.9344 - mse: 0.0495\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2057 - accuracy: 0.9344 - mse: 0.0491\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2042 - accuracy: 0.9344 - mse: 0.0488\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2027 - accuracy: 0.9344 - mse: 0.0484\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2013 - accuracy: 0.9344 - mse: 0.0481\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1999 - accuracy: 0.9344 - mse: 0.0478\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1986 - accuracy: 0.9344 - mse: 0.0475\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1973 - accuracy: 0.9344 - mse: 0.0472\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1961 - accuracy: 0.9344 - mse: 0.0469\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1949 - accuracy: 0.9344 - mse: 0.0466\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1937 - accuracy: 0.9344 - mse: 0.0463\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.9344 - mse: 0.0461\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1915 - accuracy: 0.9344 - mse: 0.0458\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1905 - accuracy: 0.9344 - mse: 0.0455\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1894 - accuracy: 0.9344 - mse: 0.0453\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1884 - accuracy: 0.9344 - mse: 0.0450\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1874 - accuracy: 0.9344 - mse: 0.0448\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1865 - accuracy: 0.9344 - mse: 0.0446\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9344 - mse: 0.0443\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1847 - accuracy: 0.9344 - mse: 0.0441\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1838 - accuracy: 0.9344 - mse: 0.0439\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1829 - accuracy: 0.9344 - mse: 0.0437\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1821 - accuracy: 0.9344 - mse: 0.0435\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1813 - accuracy: 0.9344 - mse: 0.0433\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1805 - accuracy: 0.9344 - mse: 0.0431\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 0.9344 - mse: 0.0429\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1790 - accuracy: 0.9344 - mse: 0.0427\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1782 - accuracy: 0.9344 - mse: 0.0425\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1775 - accuracy: 0.9344 - mse: 0.0423\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1768 - accuracy: 0.9344 - mse: 0.0421\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1761 - accuracy: 0.9344 - mse: 0.0419\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1754 - accuracy: 0.9344 - mse: 0.0417\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1747 - accuracy: 0.9344 - mse: 0.0415\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1741 - accuracy: 0.9344 - mse: 0.0414\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1734 - accuracy: 0.9344 - mse: 0.0412\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1728 - accuracy: 0.9344 - mse: 0.0410\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1722 - accuracy: 0.9426 - mse: 0.0409\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1716 - accuracy: 0.9426 - mse: 0.0407\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1710 - accuracy: 0.9426 - mse: 0.0405\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1704 - accuracy: 0.9426 - mse: 0.0404\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1698 - accuracy: 0.9426 - mse: 0.0402\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1693 - accuracy: 0.9426 - mse: 0.0400\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1687 - accuracy: 0.9426 - mse: 0.0399\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1682 - accuracy: 0.9426 - mse: 0.0397\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1676 - accuracy: 0.9426 - mse: 0.0396\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1671 - accuracy: 0.9426 - mse: 0.0394\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1666 - accuracy: 0.9426 - mse: 0.0393\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1661 - accuracy: 0.9426 - mse: 0.0391\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1655 - accuracy: 0.9426 - mse: 0.0390\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1650 - accuracy: 0.9426 - mse: 0.0388\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1646 - accuracy: 0.9426 - mse: 0.0387\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1641 - accuracy: 0.9426 - mse: 0.0386\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9426 - mse: 0.0384\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.9426 - mse: 0.0383\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1626 - accuracy: 0.9426 - mse: 0.0381\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1622 - accuracy: 0.9426 - mse: 0.0380\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1617 - accuracy: 0.9426 - mse: 0.0379\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1613 - accuracy: 0.9426 - mse: 0.0377\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1608 - accuracy: 0.9426 - mse: 0.0376\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1604 - accuracy: 0.9426 - mse: 0.0375\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1600 - accuracy: 0.9426 - mse: 0.0373\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1595 - accuracy: 0.9426 - mse: 0.0372\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 0.9426 - mse: 0.0371\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1587 - accuracy: 0.9426 - mse: 0.0369\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9426 - mse: 0.0368\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1578 - accuracy: 0.9426 - mse: 0.0367\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1574 - accuracy: 0.9426 - mse: 0.0366\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1570 - accuracy: 0.9426 - mse: 0.0364\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9426 - mse: 0.0363\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1562 - accuracy: 0.9426 - mse: 0.0362\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1558 - accuracy: 0.9426 - mse: 0.0361\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1554 - accuracy: 0.9426 - mse: 0.0359\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1550 - accuracy: 0.9426 - mse: 0.0358\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1547 - accuracy: 0.9426 - mse: 0.0357\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1543 - accuracy: 0.9426 - mse: 0.0356\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1539 - accuracy: 0.9426 - mse: 0.0355\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1535 - accuracy: 0.9426 - mse: 0.0353\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1531 - accuracy: 0.9426 - mse: 0.0352\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1528 - accuracy: 0.9426 - mse: 0.0351\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1524 - accuracy: 0.9426 - mse: 0.0350\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1520 - accuracy: 0.9426 - mse: 0.0349\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9426 - mse: 0.0348\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1513 - accuracy: 0.9426 - mse: 0.0346\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9426 - mse: 0.0345\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1506 - accuracy: 0.9426 - mse: 0.0344\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1503 - accuracy: 0.9426 - mse: 0.0343\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1499 - accuracy: 0.9426 - mse: 0.0342\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1496 - accuracy: 0.9426 - mse: 0.0341\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1492 - accuracy: 0.9426 - mse: 0.0340\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1489 - accuracy: 0.9426 - mse: 0.0338\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1485 - accuracy: 0.9426 - mse: 0.0337\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1482 - accuracy: 0.9426 - mse: 0.0336\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1479 - accuracy: 0.9426 - mse: 0.0335\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 0.9426 - mse: 0.0334\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1472 - accuracy: 0.9426 - mse: 0.0333\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1469 - accuracy: 0.9426 - mse: 0.0332\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1465 - accuracy: 0.9426 - mse: 0.0331\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1462 - accuracy: 0.9426 - mse: 0.0330\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1459 - accuracy: 0.9426 - mse: 0.0329\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 0.9426 - mse: 0.0328\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1452 - accuracy: 0.9426 - mse: 0.0327\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1449 - accuracy: 0.9426 - mse: 0.0325\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1446 - accuracy: 0.9426 - mse: 0.0324\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1443 - accuracy: 0.9508 - mse: 0.0323\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1440 - accuracy: 0.9590 - mse: 0.0322\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1437 - accuracy: 0.9590 - mse: 0.0321\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1434 - accuracy: 0.9590 - mse: 0.0320\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1431 - accuracy: 0.9590 - mse: 0.0319\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1427 - accuracy: 0.9590 - mse: 0.0318\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1424 - accuracy: 0.9590 - mse: 0.0317\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1421 - accuracy: 0.9590 - mse: 0.0316\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1418 - accuracy: 0.9590 - mse: 0.0315\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1415 - accuracy: 0.9590 - mse: 0.0314\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9590 - mse: 0.0313\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9590 - mse: 0.0312\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1407 - accuracy: 0.9590 - mse: 0.0311\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9590 - mse: 0.0310\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9590 - mse: 0.0309\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1398 - accuracy: 0.9590 - mse: 0.0308\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1395 - accuracy: 0.9590 - mse: 0.0307\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1392 - accuracy: 0.9590 - mse: 0.0307\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1389 - accuracy: 0.9590 - mse: 0.0306\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1386 - accuracy: 0.9590 - mse: 0.0305\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1384 - accuracy: 0.9590 - mse: 0.0304\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1381 - accuracy: 0.9590 - mse: 0.0303\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1378 - accuracy: 0.9590 - mse: 0.0302\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1375 - accuracy: 0.9590 - mse: 0.0301\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1372 - accuracy: 0.9590 - mse: 0.0300\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1370 - accuracy: 0.9672 - mse: 0.0299\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9672 - mse: 0.0298\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9672 - mse: 0.0297\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1362 - accuracy: 0.9672 - mse: 0.0296\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1359 - accuracy: 0.9672 - mse: 0.0296\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1356 - accuracy: 0.9672 - mse: 0.0295\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1353 - accuracy: 0.9672 - mse: 0.0294\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9672 - mse: 0.0293\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1348 - accuracy: 0.9672 - mse: 0.0292\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1346 - accuracy: 0.9672 - mse: 0.0291\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1343 - accuracy: 0.9672 - mse: 0.0290\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1340 - accuracy: 0.9672 - mse: 0.0289\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 0.9672 - mse: 0.0289\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1335 - accuracy: 0.9672 - mse: 0.0288\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1333 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9672 - mse: 0.0286\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1327 - accuracy: 0.9672 - mse: 0.0285\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1325 - accuracy: 0.9672 - mse: 0.0284\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1322 - accuracy: 0.9672 - mse: 0.0284\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.9672 - mse: 0.0283\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1317 - accuracy: 0.9672 - mse: 0.0282\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.9672 - mse: 0.0281\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1312 - accuracy: 0.9672 - mse: 0.0280\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1310 - accuracy: 0.9672 - mse: 0.0280\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1308 - accuracy: 0.9672 - mse: 0.0279\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1305 - accuracy: 0.9672 - mse: 0.0278\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1303 - accuracy: 0.9672 - mse: 0.0277\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1300 - accuracy: 0.9672 - mse: 0.0276\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1298 - accuracy: 0.9672 - mse: 0.0276\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1295 - accuracy: 0.9672 - mse: 0.0275\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1293 - accuracy: 0.9672 - mse: 0.0274\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1291 - accuracy: 0.9672 - mse: 0.0273\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9672 - mse: 0.0273\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1286 - accuracy: 0.9672 - mse: 0.0272\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1284 - accuracy: 0.9672 - mse: 0.0271\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1281 - accuracy: 0.9672 - mse: 0.0270\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9672 - mse: 0.0270\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9672 - mse: 0.0269\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1274 - accuracy: 0.9672 - mse: 0.0268\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1272 - accuracy: 0.9672 - mse: 0.0267\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1270 - accuracy: 0.9672 - mse: 0.0267\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9754 - mse: 0.0266\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1265 - accuracy: 0.9754 - mse: 0.0265\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1263 - accuracy: 0.9754 - mse: 0.0264\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1261 - accuracy: 0.9754 - mse: 0.0264\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1258 - accuracy: 0.9754 - mse: 0.0263\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1256 - accuracy: 0.9754 - mse: 0.0262\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1254 - accuracy: 0.9754 - mse: 0.0262\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1252 - accuracy: 0.9754 - mse: 0.0261\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.9754 - mse: 0.0260\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9754 - mse: 0.0260\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1245 - accuracy: 0.9754 - mse: 0.0259\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1243 - accuracy: 0.9754 - mse: 0.0258\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1241 - accuracy: 0.9754 - mse: 0.0258\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9754 - mse: 0.0257\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1236 - accuracy: 0.9754 - mse: 0.0256\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1234 - accuracy: 0.9754 - mse: 0.0255\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1232 - accuracy: 0.9754 - mse: 0.0255\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1230 - accuracy: 0.9754 - mse: 0.0254\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1228 - accuracy: 0.9754 - mse: 0.0253\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1225 - accuracy: 0.9754 - mse: 0.0253\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1223 - accuracy: 0.9754 - mse: 0.0252\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.9754 - mse: 0.0251\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1219 - accuracy: 0.9754 - mse: 0.0251\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1217 - accuracy: 0.9754 - mse: 0.0250\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1215 - accuracy: 0.9754 - mse: 0.0250\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1213 - accuracy: 0.9754 - mse: 0.0249\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1211 - accuracy: 0.9754 - mse: 0.0248\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1209 - accuracy: 0.9754 - mse: 0.0248\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1206 - accuracy: 0.9754 - mse: 0.0247\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9754 - mse: 0.0246\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1202 - accuracy: 0.9754 - mse: 0.0246\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1200 - accuracy: 0.9754 - mse: 0.0245\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9754 - mse: 0.0244\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1196 - accuracy: 0.9754 - mse: 0.0244\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1194 - accuracy: 0.9754 - mse: 0.0243\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1192 - accuracy: 0.9754 - mse: 0.0243\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9754 - mse: 0.0242\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1188 - accuracy: 0.9754 - mse: 0.0241\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1186 - accuracy: 0.9754 - mse: 0.0241\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1184 - accuracy: 0.9754 - mse: 0.0240\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1182 - accuracy: 0.9754 - mse: 0.0240\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1180 - accuracy: 0.9754 - mse: 0.0239\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1178 - accuracy: 0.9754 - mse: 0.0238\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1176 - accuracy: 0.9754 - mse: 0.0238\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1174 - accuracy: 0.9754 - mse: 0.0237\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1172 - accuracy: 0.9754 - mse: 0.0237\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1170 - accuracy: 0.9754 - mse: 0.0236\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1168 - accuracy: 0.9754 - mse: 0.0235\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1166 - accuracy: 0.9754 - mse: 0.0235\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9754 - mse: 0.0234\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1162 - accuracy: 0.9754 - mse: 0.0234\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9754 - mse: 0.0233\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1158 - accuracy: 0.9754 - mse: 0.0232\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1156 - accuracy: 0.9754 - mse: 0.0232\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.9754 - mse: 0.0231\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1152 - accuracy: 0.9754 - mse: 0.0231\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1150 - accuracy: 0.9754 - mse: 0.0230\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.9754 - mse: 0.0229\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1146 - accuracy: 0.9754 - mse: 0.0229\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1144 - accuracy: 0.9754 - mse: 0.0228\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1143 - accuracy: 0.9754 - mse: 0.0228\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1139 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1137 - accuracy: 0.9754 - mse: 0.0226\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1135 - accuracy: 0.9754 - mse: 0.0225\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1133 - accuracy: 0.9754 - mse: 0.0225\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1131 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1129 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1127 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9754 - mse: 0.0222\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1122 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1120 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1118 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1116 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1114 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1112 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1110 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1108 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1106 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1105 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1103 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1101 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1099 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9754 - mse: 0.0214\n",
      "Restoring best model weights.\n",
      "Best loss: 0.1097170040011406\n"
     ]
    }
   ],
   "source": [
    "# NN-SGD Training\n",
    "hparams_sgd={'lr': 0.6, 'h_dim': 4, 'reg': 0.001}\n",
    "optimizer_sgd = SGD(learning_rate=hparams_sgd['lr'])\n",
    "nn_sgd_m3 = get_nn_classifier(optimizer_sgd, hparams_sgd)\n",
    "solver_sgd = Solver(nn_sgd_m3, x_dev_m3, y_dev_m3, target='loss')\n",
    "solver_sgd.train(epochs=300, patience=50, batch_size=len(x_dev_m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47b7771d-67c6-433f-b0ef-da8f41c7fc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.6830 - accuracy: 0.6230 - mse: 0.2300\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6561 - accuracy: 0.5902 - mse: 0.2252\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5538 - accuracy: 0.7377 - mse: 0.1761\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5137 - accuracy: 0.7459 - mse: 0.1609\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4058 - accuracy: 0.8689 - mse: 0.1125\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.9344 - mse: 0.0764\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3068 - accuracy: 0.9262 - mse: 0.0683\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2996 - accuracy: 0.9262 - mse: 0.0610\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.9426 - mse: 0.0529\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2872 - accuracy: 0.9344 - mse: 0.0493\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.9344 - mse: 0.0453\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9508 - mse: 0.0430\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2722 - accuracy: 0.9508 - mse: 0.0423\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9508 - mse: 0.0419\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2512 - accuracy: 0.9426 - mse: 0.0424\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2448 - accuracy: 0.9426 - mse: 0.0438\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2407 - accuracy: 0.9426 - mse: 0.0443\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9426 - mse: 0.0437\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2349 - accuracy: 0.9590 - mse: 0.0428\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2290 - accuracy: 0.9590 - mse: 0.0414\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2209 - accuracy: 0.9590 - mse: 0.0398\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2137 - accuracy: 0.9590 - mse: 0.0385\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2091 - accuracy: 0.9426 - mse: 0.0378\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9426 - mse: 0.0373\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2089 - accuracy: 0.9344 - mse: 0.0369\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2105 - accuracy: 0.9344 - mse: 0.0365\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2102 - accuracy: 0.9344 - mse: 0.0357\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2079 - accuracy: 0.9344 - mse: 0.0348\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2039 - accuracy: 0.9426 - mse: 0.0341\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2007 - accuracy: 0.9426 - mse: 0.0340\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1993 - accuracy: 0.9508 - mse: 0.0344\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1987 - accuracy: 0.9508 - mse: 0.0348\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1973 - accuracy: 0.9508 - mse: 0.0346\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9508 - mse: 0.0337\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.9590 - mse: 0.0325\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9590 - mse: 0.0313\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1887 - accuracy: 0.9590 - mse: 0.0305\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1892 - accuracy: 0.9590 - mse: 0.0300\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9590 - mse: 0.0298\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1899 - accuracy: 0.9590 - mse: 0.0294\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1887 - accuracy: 0.9672 - mse: 0.0290\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1873 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1865 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1861 - accuracy: 0.9754 - mse: 0.0287\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1856 - accuracy: 0.9754 - mse: 0.0289\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1849 - accuracy: 0.9590 - mse: 0.0289\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1842 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1838 - accuracy: 0.9754 - mse: 0.0286\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9672 - mse: 0.0286\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1830 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1822 - accuracy: 0.9672 - mse: 0.0288\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9590 - mse: 0.0290\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.9590 - mse: 0.0290\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.9672 - mse: 0.0287\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1814 - accuracy: 0.9754 - mse: 0.0281\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1808 - accuracy: 0.9754 - mse: 0.0276\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1804 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1801 - accuracy: 0.9836 - mse: 0.0269\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1798 - accuracy: 0.9836 - mse: 0.0269\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1797 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1795 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1790 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9836 - mse: 0.0270\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1781 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1779 - accuracy: 0.9836 - mse: 0.0273\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.9836 - mse: 0.0274\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1773 - accuracy: 0.9836 - mse: 0.0271\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1770 - accuracy: 0.9836 - mse: 0.0266\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1769 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1767 - accuracy: 0.9836 - mse: 0.0261\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1762 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1760 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1759 - accuracy: 0.9836 - mse: 0.0262\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1757 - accuracy: 0.9836 - mse: 0.0263\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1754 - accuracy: 0.9836 - mse: 0.0264\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1752 - accuracy: 0.9836 - mse: 0.0263\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1750 - accuracy: 0.9836 - mse: 0.0261\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1748 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1746 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1743 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1742 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1740 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1738 - accuracy: 0.9836 - mse: 0.0259\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1736 - accuracy: 0.9836 - mse: 0.0258\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1735 - accuracy: 0.9836 - mse: 0.0256\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1732 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1729 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1728 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1727 - accuracy: 0.9836 - mse: 0.0255\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1726 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1724 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1722 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1721 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1720 - accuracy: 0.9836 - mse: 0.0253\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0252\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1718 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1717 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1715 - accuracy: 0.9836 - mse: 0.0250\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1715 - accuracy: 0.9836 - mse: 0.0253\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1714 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1713 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1713 - accuracy: 0.9836 - mse: 0.0254\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1711 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9836 - mse: 0.0250\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1710 - accuracy: 0.9836 - mse: 0.0251\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1709 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1708 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1708 - accuracy: 0.9836 - mse: 0.0251\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1707 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1705 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1704 - accuracy: 0.9836 - mse: 0.0249\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1704 - accuracy: 0.9836 - mse: 0.0246\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1702 - accuracy: 0.9836 - mse: 0.0248\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 0.9836 - mse: 0.0245\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1676 - accuracy: 0.9836 - mse: 0.0234\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.9836 - mse: 0.0229\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1654 - accuracy: 0.9754 - mse: 0.0230\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1651 - accuracy: 0.9754 - mse: 0.0227\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1618 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 0.9836 - mse: 0.0226\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1624 - accuracy: 0.9836 - mse: 0.0225\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.9754 - mse: 0.0224\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1619 - accuracy: 0.9754 - mse: 0.0223\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1618 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1612 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.9754 - mse: 0.0220\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1606 - accuracy: 0.9754 - mse: 0.0222\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0221\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1603 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1601 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1599 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1597 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1595 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1593 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1589 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9754 - mse: 0.0219\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1582 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1580 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1579 - accuracy: 0.9754 - mse: 0.0218\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1577 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1574 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1573 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1572 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1571 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9754 - mse: 0.0217\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1568 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0213\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0216\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0212\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0215\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1566 - accuracy: 0.9754 - mse: 0.0214\n",
      "Restoring best model weights.\n",
      "Best loss: 0.15661567449569702\n"
     ]
    }
   ],
   "source": [
    "# NN-Adam Training\n",
    "hparams_adam={'lr': 0.3, 'h_dim': 4, 'reg': 0.02, 'beta_1': 0.9, 'beta_2': 0.9}\n",
    "optimizer_adam = Adam(learning_rate=hparams_adam['lr'], beta_1=hparams_adam['beta_1'], beta_2=hparams_adam['beta_2'])\n",
    "nn_adam_m3 = get_nn_classifier(optimizer_adam, hparams_adam)\n",
    "solver_adam = Solver(nn_adam_m3, x_dev_m3, y_dev_m3, target='loss')\n",
    "solver_adam.train(epochs=300, patience=50, batch_size=len(x_dev_m3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc6223-3887-4dc6-a8c4-ef3be5bb5f6f",
   "metadata": {},
   "source": [
    "## Ensamble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "283bd661-8ec6-4ad3-8a4b-ba2b9528c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m3_preds_dev = svc_m3.predict(x_dev_m3)\n",
    "nn_sgd_m3_preds_dev = (np.rint(nn_sgd_m3.predict(x_dev_m3))).astype(int)\n",
    "nn_adam_m3_preds_dev = (np.rint(nn_adam_m3.predict(x_dev_m3))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m3_preds_dev = nn_sgd_m3.predict(x_dev_m3)\n",
    "#nn_adam_m3_preds_dev = nn_adam_m3.predict(x_dev_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee8351ac-616e-447e-af38-df77294e0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1095 - accuracy: 0.9754 - mse: 0.0214\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9754 - mse: 0.0213\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m3_dev = accuracy_score(y_dev_m3, svc_m3_preds_dev)\n",
    "acc_nn_sgd_m3_dev = nn_sgd_m3.evaluate(x_dev_m3, y_dev_m3)[1]\n",
    "acc_nn_adam_m3_dev = nn_adam_m3.evaluate(x_dev_m3, y_dev_m3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a1981a7-7abb-46c2-8cf3-3d56319425b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=128)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=128)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble - Majority and Weighted Voting schema \n",
    "ensemble_dev = np.zeros(len(x_dev_m3), dtype=int)\n",
    "\n",
    "en_maj_vot_dev = ensemble_majority_voting(ensemble_dev, \n",
    "                                          svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev)\n",
    "\n",
    "en_wei_vot_dev = ensemble_weighted_voting(ensemble_dev, \n",
    "                                          svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev,\n",
    "                                          acc_svc_m3_dev, acc_nn_sgd_m3_dev, acc_nn_sgd_m3_dev)\n",
    "\n",
    "en_stack_dev, x_stack_dev = ensemble_stacking(svc_m3_preds_dev, nn_sgd_m3_preds_dev, nn_adam_m3_preds_dev)\n",
    "en_stack_dev.fit(x_stack_dev, y_dev_m3)\n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477543b-56cb-4e3b-b2d5-fe631eb411a6",
   "metadata": {},
   "source": [
    "## Result Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b9d834e-67e2-4797-8cff-1add6d7a233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT Accuracy Models --\n",
      "Accuracy SVC: 0.9344 - Accuracy NN-SGD: 0.9754 - Accuracy NN-Adam: 0.9754\n",
      "\n",
      "-- DEVELOPMENT Majority Voting Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n",
      "\n",
      "-- DEVELOPMENT Weighted Voting Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0328 - Accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT Accuracy Models --')\n",
    "print(f'Accuracy SVC: {acc_svc_m3_dev:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m3_dev:.4f} - Accuracy NN-Adam: {acc_nn_adam_m3_dev:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Majority Voting Schema --')\n",
    "acc_dev_maj_m3 = accuracy_score(y_dev_m3, en_maj_vot_dev)\n",
    "mse_dev_maj_m3 = mean_squared_error(y_dev_m3, en_maj_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_maj_m3:.4f} - Accuracy: {acc_dev_maj_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Voting Schema --')\n",
    "acc_dev_wei_m3 = accuracy_score(y_dev_m3, en_wei_vot_dev)\n",
    "mse_dev_wei_m3 = mean_squared_error(y_dev_m3, en_wei_vot_dev)\n",
    "print(f'Loss (MSE): {mse_dev_wei_m3:.4f} - Accuracy: {acc_dev_wei_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_dev_stack_m3 = accuracy_score(y_dev_m3, en_stack_dev.predict(x_stack_dev))\n",
    "mse_dev_stack_m3 = mean_squared_error(y_dev_m3, en_stack_dev.predict(x_stack_dev))\n",
    "print(f'Loss (MSE): {mse_dev_stack_m3:.4f} - Accuracy: {acc_dev_stack_m3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b54f4c-5040-4fdf-b31d-f612f95376c9",
   "metadata": {},
   "source": [
    "## Ensamble Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89d2f28c-83be-4229-ab0d-675d86bb99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svc_m3_preds_test = svc_m3.predict(x_test_m3)\n",
    "nn_sgd_m3_preds_test = (np.rint(nn_sgd_m3.predict(x_test_m3))).astype(int)\n",
    "nn_adam_m3_preds_test = (np.rint(nn_adam_m3.predict(x_test_m3))).astype(int)\n",
    "\n",
    "# Probability\n",
    "#nn_sgd_m3_preds_test = nn_sgd_m3.predict(x_test_m3)\n",
    "#nn_adam_m3_preds_test = nn_adam_m3.predict(x_test_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d73ddb0e-4f44-4c91-91c7-b4ebad218738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9630 - mse: 0.0250\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9491 - mse: 0.0341\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model\n",
    "acc_svc_m3_test = accuracy_score(y_test_m3, svc_m3_preds_test)\n",
    "acc_nn_sgd_m3_test = nn_sgd_m3.evaluate(x_test_m3, y_test_m3)[1]\n",
    "acc_nn_adam_m3_test = nn_adam_m3.evaluate(x_test_m3, y_test_m3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4da56bc-b2de-4a86-8f8d-aeebc6262916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble - Majority and Weighted Voting schemaR\n",
    "ensemble_test = np.zeros(len(x_test_m3), dtype=int)\n",
    "\n",
    "en_maj_vot_test = ensemble_majority_voting(ensemble_test,\n",
    "                                           svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test)\n",
    "\n",
    "en_wei_vot_test = ensemble_weighted_voting(ensemble_test, \n",
    "                                          svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test,\n",
    "                                          acc_svc_m3_test, acc_nn_sgd_m3_test, acc_nn_sgd_m3_test)\n",
    "\n",
    "en_stack_test, x_stack_test = ensemble_stacking(svc_m3_preds_test, nn_sgd_m3_preds_test, nn_adam_m3_preds_test)\n",
    "#en_stack_test.fit(x_stack_test, y_test_m3)                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0b1c4-031a-43d1-ab61-cc749109f1d8",
   "metadata": {},
   "source": [
    "## Results Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f0c4840-309f-4086-bc5a-df31d33dc756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST Accuracy Models--\n",
      "Accuracy SVC: 0.9722 - Accuracy NN-SGD: 0.9630 - Accuracy NN-Adam: 0.9491\n",
      "\n",
      "-- TEST Majority Voting Schema--\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n",
      "\n",
      "-- TEST Weighted Voting Schema--\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0440 - Accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST Accuracy Models--')\n",
    "print(f'Accuracy SVC: {acc_svc_m3_test:.4f} - Accuracy NN-SGD: {acc_nn_sgd_m3_test:.4f} - Accuracy NN-Adam: {acc_nn_adam_m3_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Majority Voting Schema--')\n",
    "acc_test_maj_m3 = accuracy_score(y_test_m3, en_maj_vot_test)\n",
    "mse_test_maj_m3 = mean_squared_error(y_test_m3, en_maj_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_maj_m3:.4f} - Accuracy: {acc_test_maj_m3:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Voting Schema--')\n",
    "acc_test_wei_m3 = accuracy_score(y_test_m3, en_wei_vot_test)\n",
    "mse_test_wei_m3 = mean_squared_error(y_test_m3, en_wei_vot_test)\n",
    "print(f'Loss (MSE): {mse_test_wei_m3:.4f} - Accuracy: {acc_test_wei_m3:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "acc_test_stack_m3 = accuracy_score(y_test_m3, en_stack_dev.predict(x_stack_test))\n",
    "mse_test_stack_m3 = mean_squared_error(y_test_m3, en_stack_dev.predict(x_stack_test))\n",
    "print(f'Loss (MSE): {mse_test_stack_m3:.4f} - Accuracy: {acc_test_stack_m3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb110c7d-e148-4c70-9be3-e43803d20f10",
   "metadata": {},
   "source": [
    "## Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f77e7d4-97a9-4ceb-87d0-a4a2a0f0f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_m3 = {\n",
    "    'dev_majority': {'accuracy': acc_dev_maj_m3, 'mse': mse_dev_maj_m3},\n",
    "    'test_majority': {'accuracy': acc_test_maj_m3, 'mse': mse_test_maj_m3},\n",
    "    'dev_weighted': {'accuracy': acc_dev_wei_m3, 'mse': mse_dev_wei_m3},\n",
    "    'test_weighted': {'accuracy': acc_test_wei_m3, 'mse': mse_test_wei_m3},\n",
    "    'dev_stacking': {'accuracy': acc_dev_stack_m3, 'mse': mse_dev_stack_m3},\n",
    "    'test_stacking': {'accuracy': acc_test_stack_m3, 'mse': mse_test_stack_m3}\n",
    "}\n",
    "\n",
    "store_monk_result(results_dir + '/MONK3/', en_stack_dev.get_params(), report_m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f6603-97eb-4bf3-ae71-b1a62be020bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Ensemble - CUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec7e3ff-908a-480a-bc16-bd7a020f41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CUP\n",
    "x_dev_cup, y_dev_cup, x_test_cup = load_cup(cup_dev_path, cup_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1274b55b-f97f-48d0-8d4c-8afa1c001b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.utils.register_keras_serializable()\n",
    "def mean_euclidean_error(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Utility function to compute the Mean Euclidean Error (MEE) between \n",
    "    true and predicted values for a tensorflow model. \n",
    "    Return the MEE score as a tensor.\n",
    "\n",
    "    Required arguments:\n",
    "    - y_true: array containing true values (ground truth).\n",
    "    - y_pred: array containing predicted values.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(y_pred - y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ae8aa-990f-4b6d-a301-186c83d60e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dev - Internal Test Split \n",
    "The development dataset is split between training and internal test ($90-10$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371a0d14-f694-4424-a2f8-f497f42203e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dev data into train - internal test\n",
    "x_train_cup, x_internal_test_cup, y_train_cup, y_internal_test_cup = train_test_split(\n",
    "    x_dev_cup, \n",
    "    y_dev_cup, \n",
    "    test_size=INTERNAL_TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d1bdf-28f4-442a-8e27-7087dce760ee",
   "metadata": {},
   "source": [
    "## Polynomial features\n",
    "We create a version of our dataset to which PolynoMialFeatures pre-processing is applied with a fixed degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdecf5e5-fbb6-4af5-8960-454c8c649435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features pre-processing\n",
    "poly = PolynomialFeatures(degree=POLY_DEGREE) # Polynomial features pre-processing\n",
    "x_train_cup_poly = poly.fit_transform(x_train_cup)\n",
    "x_internal_test_cup_poly = poly.transform(x_internal_test_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a5958-8ecf-487d-95a3-de87a52ec0e3",
   "metadata": {},
   "source": [
    "## Models and Ensemles - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7eb6f38-bf75-4e8e-b2be-ffbe854bd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_regressor(optimizer, hparams):\n",
    "    if hparams['activation'] == 'tanh':\n",
    "        initializer = GlorotUniform(seed=RANDOM_STATE) # Glorot (Xavier)\n",
    "        bias_initializer = Zeros()\n",
    "    elif hparams['activation'] == 'ReLU':\n",
    "        initializer = HeNormal(seed=RANDOM_STATE) # He (Kaiming)\n",
    "        bias_initializer = Constant(0.1)\n",
    "        \n",
    "    reg = l2(hparams['reg'])\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        hparams['h_dim'], \n",
    "        activation=hparams['activation'], \n",
    "        input_shape=(10,), \n",
    "        kernel_regularizer=l2(hparams['reg']),\n",
    "        kernel_initializer=initializer,\n",
    "        bias_initializer=bias_initializer))\n",
    "\n",
    "    h_dim = hparams['h_dim']\n",
    "    for i in range(hparams['n_layers'] - 1):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                h_dim, \n",
    "                activation=hparams['activation'],\n",
    "                kernel_regularizer=l2(hparams['reg']),\n",
    "                kernel_initializer=initializer,\n",
    "                bias_initializer=bias_initializer))\n",
    "        h_dim //= 2\n",
    "\n",
    "    model.add(Dense(\n",
    "        3, \n",
    "        activation='linear', \n",
    "        kernel_regularizer=l2(hparams['reg']), \n",
    "        kernel_initializer=initializer,\n",
    "        bias_initializer=bias_initializer))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[mean_euclidean_error])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d98a38-c495-4396-90fd-b28eaf9b7f37",
   "metadata": {},
   "source": [
    "## Ensemble Arithmetic Averange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a32250c6-31dd-493c-b074-6bd413052825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_arithmetic_averange(ensemble, svr_preds, nn_sgd_preds, nn_adam_preds):\n",
    "    #for i, j in ensemble.shape:\n",
    "        #ensemble[i][j] = (svr_preds[i][j] + nn_sgd_preds[i][j]+ nn_adam_preds[i][j])/3 \n",
    "            \n",
    "    return (svr_preds + nn_sgd_preds + nn_adam_preds)/3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ac349-f4c6-4801-8989-a6a661ac4b7c",
   "metadata": {},
   "source": [
    "## Ensemble Weighted Averange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2661372c-0a21-4245-a443-aab90a47cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weight used is (N - mee)\n",
    "def ensemble_weighted_averange(ensemble, N, svr_preds, nn_sgd_preds, nn_adam_preds, mee_svr, mee_nn_sgd, mee_nn_adam):\n",
    "    \n",
    "    if (N < mee_svr or N < mee_nn_sgd or N < mee_nn_adam):\n",
    "        raise ValueError(\"N must be greater than mee\")\n",
    "        \n",
    "    #for i in range(len(ensemble)):\n",
    "    #    ensemble[i] = svc_preds[i]*(N-mee_svr) + nn_sgd_preds[i]*(N-mee_nn_sgd) + nn_adam_preds[i]*(N-mee_nn_adam)/(3*N - (mee_svr + mee_nn_sgd + mee_nn_adam))\n",
    "            \n",
    "    return (svr_preds*(N-mee_svr) + nn_sgd_preds*(N-mee_nn_sgd) + nn_adam_preds*(N-mee_nn_adam))/(3*N - (mee_svr + mee_nn_sgd + mee_nn_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c7aac-b3dc-4f08-ae15-58c7c9c564b1",
   "metadata": {},
   "source": [
    "## Ensemble Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27960dce-1ce8-4c03-b9c5-a3e5389c930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_stacking_cup(estimator):\n",
    "    if(estimator == 'LinearRegression'): ensemble = LinearRegression()\n",
    "    elif(estimator == 'Ridge'): ensemble = Ridge()\n",
    "    elif(estimator == 'Lasso'): ensemble = Lasso(alpha=0.035)\n",
    "    else: raise ValueError(\"Estimator not valid\")\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8734a58-90f9-4155-aee9-eadaf1d6c8b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82eb0ba7-fed8-4d33-bdc0-fdeaaf91b540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=2000, epsilon=0.07)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=2000, epsilon=0.07)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR(C=2000, epsilon=0.07))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR Traning\n",
    "multi_svr = MultiOutputRegressor(SVR(C=2000, epsilon=0.07, kernel='rbf', gamma='scale'))\n",
    "multi_svr.fit(x_train_cup, y_train_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3a6c5-cc26-4afe-9018-441fba2b2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN-SGD Training\n",
    "best_config_sgd_cup = {\n",
    "    'lr': 0.00035,\n",
    "    'h_dim': 100,\n",
    "    'n_layers': 3,\n",
    "    'activation': 'tanh',\n",
    "    'reg': 0.001,\n",
    "    'momentum': 0.95, \n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "optimizer_sgd = SGD(learning_rate=best_config_sgd_cup['lr'], momentum=best_config_sgd_cup['momentum'])\n",
    "model_nn_sgd_cup = get_nn_regressor(optimizer_sgd, best_config_sgd_cup)\n",
    "solver_sgd = Solver(model_nn_sgd_cup, x_train_cup, y_train_cup, x_internal_test_cup, y_internal_test_cup, target='mean_euclidean_error')\n",
    "solver_sgd.train(epochs=1500, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddbf68-bd7a-422d-bf8e-75ba8cfa45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_adam_cup = {\n",
    "    'lr': 0.001,\n",
    "    'h_dim': 64,\n",
    "    'n_layers': 2,\n",
    "    'activation': 'tanh',\n",
    "    'reg': 0.001,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.99,\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "optimizer_adam = Adam(learning_rate=best_config_adam_cup['lr'], beta_1=best_config_adam_cup['beta_1'], beta_2=best_config_adam_cup['beta_2'])\n",
    "model_nn_adam_cup = get_nn_regressor(optimizer_adam, best_config_adam_cup)\n",
    "solver_adam = Solver(model_nn_adam_cup, x_train_cup, y_train_cup, x_internal_test_cup, y_internal_test_cup, target='mean_euclidean_error')\n",
    "solver_adam.train(epochs=1500, patience=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82492ee-bef4-4324-b503-43f7c712d36b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ensamble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d304de33-2af1-4853-94e4-fd7b66dc9ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svr_preds_train = multi_svr.predict(x_train_cup)\n",
    "nn_sgd_preds_train = model_nn_sgd_cup.predict(x_train_cup)\n",
    "nn_adam_preds_train = model_nn_adam_cup.predict(x_train_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acd13a1d-a6b5-4bf6-a606-f2a747a58285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 5ms/step - loss: 0.7059 - mean_euclidean_error: 0.3865\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5887 - mean_euclidean_error: 0.4227\n"
     ]
    }
   ],
   "source": [
    "# MEE of each model\n",
    "mee_svr_train = mee(y_train_cup, svr_preds_train)\n",
    "mee_nn_sgd_train = model_nn_sgd_cup.evaluate(x_train_cup, y_train_cup)[1]\n",
    "mee_nn_adam_train = model_nn_adam_cup.evaluate(x_train_cup, y_train_cup)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffeb898b-d8c7-4be6-8d24-5082e9bcd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Arithmetic and Weighted Averange\n",
    "ensemble_train = np.zeros(y_train_cup.shape)\n",
    "\n",
    "en_av_train = ensemble_arithmetic_averange(ensemble_train, svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train)\n",
    "\n",
    "en_we_train = ensemble_weighted_averange(ensemble_train, 1,\n",
    "                                       svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train,\n",
    "                                       mee_svr_train, mee_nn_sgd_train, mee_nn_adam_train)\n",
    "\n",
    "# Ensemble Stacking. Valid estimator: LinearRegression, Ridge or Lasso\n",
    "en_stack_train = ensemble_stacking_cup(estimator='LinearRegression')\n",
    "x_stack_cup_train = np.hstack((svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train))\n",
    "en_stack_train.fit(x_stack_cup_train, y_train_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1643c-dbbd-445b-8da2-95bd733cbd4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyper-parameters Tuning for Stacking Ensamble\n",
    "ValidationCurveDisplay is used to identify which of the three models: LinearRegression, Ridge or Lasso have lower error as alpha changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bf3afbe-4408-40ae-a7e4-5cbebd6460a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_name = \"alpha\"\n",
    "param_range = np.linspace(0, 20, 100)\n",
    "\n",
    "ValidationCurveDisplay.from_estimator(Ridge(), \n",
    "                                      x_stack_cup_train, \n",
    "                                      y_train_cup, \n",
    "                                      param_name=param_name, \n",
    "                                      param_range=param_range,\n",
    "                                      cv=KFold(n_splits=5, shuffle=True, random_state=128),\n",
    "                                      scoring= make_scorer(mee, greater_is_better = False),\n",
    "                                      negate_score = True,\n",
    "                                      score_name=\"MEE\",\n",
    "                                      verbose=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd3067-f12d-41f2-9876-f06e51822d5e",
   "metadata": {},
   "source": [
    "The curve is monotonically increasing, the best alpha is 0. Ridge(alpha=0) = LinearRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c38aed8a-4290-4ecc-9268-8b11f6c512c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_name = \"alpha\"\n",
    "param_range = np.linspace(0.01, 0.5, 100)\n",
    "\n",
    "ValidationCurveDisplay.from_estimator(Lasso(), \n",
    "                                      x_stack_cup_train, \n",
    "                                      y_train_cup, \n",
    "                                      param_name=param_name, \n",
    "                                      param_range=param_range,\n",
    "                                      cv=KFold(n_splits=5, shuffle=True, random_state=128),\n",
    "                                      scoring= make_scorer(mee, greater_is_better = False),\n",
    "                                      negate_score = True,\n",
    "                                      score_name=\"MEE\",\n",
    "                                      verbose=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25cabb-d7df-479e-9fcb-7db3dc13b3af",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "826dfa49-23eb-452f-bc31-8dd82bdd7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DEVELOPMENT MEE Models --\n",
      "MEE SVC: 0.2146 - MEE NN-SGD: 0.3865 - MEE NN-Adam: 0.4227\n",
      "\n",
      "-- DEVELOPMENT Arithmetic Averange--\n",
      "Loss (MSE): 0.0409 - MEE: 0.2963\n",
      "\n",
      "-- DEVELOPMENT Weighted Averange --\n",
      "Loss (MSE): 0.0377 - MEE: 0.2840\n",
      "\n",
      "-- DEVELOPMENT Stacking Schema --\n",
      "Loss (MSE): 0.0235 - MEE: 0.2146\n"
     ]
    }
   ],
   "source": [
    "print('-- DEVELOPMENT MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_train:.4f} - MEE NN-SGD: {mee_nn_sgd_train:.4f} - MEE NN-Adam: {mee_nn_adam_train:.4f}' )\n",
    "\n",
    "print('\\n-- DEVELOPMENT Arithmetic Averange--')\n",
    "mee_train_av_cup = mee(y_train_cup, en_av_train)\n",
    "mse_train_av_cup = mean_squared_error(y_train_cup, en_av_train)\n",
    "print(f'Loss (MSE): {mse_train_av_cup:.4f} - MEE: {mee_train_av_cup:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Weighted Averange --')\n",
    "mee_train_we_cup = mee(y_train_cup, en_we_train)\n",
    "mse_train_we_cup = mean_squared_error(y_train_cup, en_we_train)\n",
    "print(f'Loss (MSE): {mse_train_we_cup:.4f} - MEE: {mee_train_we_cup:.4f}')\n",
    "\n",
    "print('\\n-- DEVELOPMENT Stacking Schema --')\n",
    "mee_train_stack_cup = mee(y_train_cup, en_stack_train.predict(x_stack_cup_train))\n",
    "mse_train_stack_cup = mean_squared_error(y_train_cup, en_stack_train.predict(x_stack_cup_train))\n",
    "print(f'Loss (MSE): {mse_train_stack_cup:.4f} - MEE: {mee_train_stack_cup:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34b36b-78f8-4a5b-b82b-165b3b5cf064",
   "metadata": {},
   "source": [
    "# Ensamble Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24bca8e6-d7f7-47b3-a0ae-1c6698c502d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction of each model\n",
    "svr_preds_internal_test = multi_svr.predict(x_internal_test_cup)\n",
    "nn_sgd_preds_internal_test = model_nn_sgd_cup.predict(x_internal_test_cup)\n",
    "nn_adam_preds_internal_test = model_nn_adam_cup.predict(x_internal_test_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c0c882c-72d6-4394-a908-01e6c26cbe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8055 - mean_euclidean_error: 0.5157\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7809 - mean_euclidean_error: 0.6107\n"
     ]
    }
   ],
   "source": [
    "# MEE of each model\n",
    "mee_svr_internal_test = mee(y_internal_test_cup, svr_preds_internal_test)\n",
    "mee_nn_sgd_internal_test = model_nn_sgd_cup.evaluate(x_internal_test_cup, y_internal_test_cup)[1]\n",
    "mee_nn_adam_internal_test = model_nn_adam_cup.evaluate(x_internal_test_cup, y_internal_test_cup)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbb671a6-6b3c-4fd6-a48c-72900f2aa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "ensemble_internal_test = np.zeros(y_internal_test_cup.shape)\n",
    "\n",
    "en_av_internal_test = ensemble_arithmetic_averange(ensemble_internal_test, svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test)\n",
    "\n",
    "en_we_internal_test = ensemble_weighted_averange(ensemble_internal_test, 1,\n",
    "                                       svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test,\n",
    "                                       mee_svr_internal_test, mee_nn_sgd_internal_test, mee_nn_adam_internal_test)\n",
    "\n",
    "x_stack_cup_internal_test = np.hstack((svr_preds_internal_test, nn_sgd_preds_internal_test, nn_adam_preds_internal_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73949eda-48ec-4124-abe1-1295c2070ed5",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "acf72550-17e4-46b8-bb75-b2a21206f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST MEE Models --\n",
      "MEE SVC: 0.5778 - MEE NN-SGD: 0.5157 - MEE NN-Adam: 0.6107\n",
      "\n",
      "-- TEST Arithmetric Averange--\n",
      "Loss (MSE): 0.1650 - MEE: 0.5172\n",
      "\n",
      "-- TEST Weighted Averange --\n",
      "Loss (MSE): 0.1586 - MEE: 0.5120\n",
      "\n",
      "-- TEST Stacking Schema --\n",
      "Loss (MSE): 0.3000 - MEE: 0.5658\n"
     ]
    }
   ],
   "source": [
    "print('-- TEST MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_internal_test:.4f} - MEE NN-SGD: {mee_nn_sgd_internal_test:.4f} - MEE NN-Adam: {mee_nn_adam_internal_test:.4f}')\n",
    "\n",
    "print('\\n-- TEST Arithmetric Averange--')\n",
    "mee_internal_test_av_cup = mee(y_internal_test_cup, en_av_internal_test)\n",
    "mse_internal_test_av_cup = mean_squared_error(y_internal_test_cup, en_av_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_av_cup:.4f} - MEE: {mee_internal_test_av_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Averange --')\n",
    "mee_internal_test_we_cup = mee(y_internal_test_cup, en_we_internal_test)\n",
    "mse_internal_test_we_cup = mean_squared_error(y_internal_test_cup, en_we_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_we_cup:.4f} - MEE: {mee_internal_test_we_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Stacking Schema --')\n",
    "mee_internal_test_stack_cup = mee(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "mse_internal_test_stack_cup = mean_squared_error(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "print(f'Loss (MSE): {mse_internal_test_stack_cup:.4f} - MEE: {mee_internal_test_stack_cup:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59161f-059d-403b-b3ba-9e395dc4e004",
   "metadata": {},
   "source": [
    "## Retraining stacking model and Blind Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "380f974c-c16b-42c3-bc0f-85bff5d5fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 6ms/step\n",
      "29/29 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Retraining with all dataset the stacking model\n",
    "x_stack_dev_cup = np.append(x_stack_cup_train, x_stack_cup_internal_test,axis=0)\n",
    "en_stack_train.fit(x_stack_dev_cup, y_dev_cup)\n",
    "\n",
    "# Blind test set predictions\n",
    "svr_preds_test = multi_svr.predict(x_test_cup)\n",
    "nn_sgd_preds_test = model_nn_sgd_cup.predict(x_test_cup)\n",
    "nn_adam_preds_test = model_nn_adam_cup.predict(x_test_cup)\n",
    "x_stack_test = np.hstack((svr_preds_test, nn_sgd_preds_test, nn_adam_preds_test))\n",
    "nn_preds_cup = en_stack_train.predict(x_stack_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89020a2f-92a1-446c-8828-9a23df6eb762",
   "metadata": {},
   "source": [
    "## Store Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3243c1b-4ce3-4dd7-82db-55583fe4d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_nn = {\n",
    "    'dev_arithmetic': {'mee': mee_train_av_cup, 'mse': mse_train_av_cup},\n",
    "    'test_arithmetic': {'mee': mee_internal_test_av_cup, 'mse': mse_internal_test_av_cup},\n",
    "    'dev_weighted': {'mee': mee_train_we_cup, 'mse': mse_train_we_cup},\n",
    "    'test_weighted': {'mee': mee_internal_test_we_cup, 'mse': mse_internal_test_we_cup},\n",
    "    'dev_stacking': {'mee': mee_train_stack_cup, 'mse': mse_train_stack_cup},\n",
    "    'test_stacking': {'mee': mee_internal_test_stack_cup, 'mse': mse_internal_test_stack_cup}\n",
    "}\n",
    "\n",
    "store_cup_result(results_dir + '/CUP/', en_stack_train.get_params(), report_nn, nn_preds_cup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84610a6f-cd1b-4845-9436-97a3b1a3ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_nn_sgd_cup = load_model(root_path + '/results/NN-SGD/CUP/model_sgd_poly.keras')\n",
    "model_nn_adam_cup = load_model(root_path + '/results/NN-ADAM/CUP/model_adam_poly.keras')\n",
    "multi_svr = joblib.load(root_path + '/results/SVM/CUP/SVR_poly.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "182c15da-eeaa-4217-9fb1-e450f9b7498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Models predictions\n",
    "nn_sgd_preds_internal_test = nn_sgd_regressor.predict(x_internal_test_cup_poly)\n",
    "nn_adam_preds_internal_test = nn_adam_regressor.predict(x_internal_test_cup_poly)\n",
    "svr_preds_internal_test = multi_svr.predict(x_internal_test_cup_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc7276f4-e98e-4526-a064-7cbf0cff7970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST ---\n",
      "NN-SGD MEE: 0.466595513029402\n",
      "NN-ADAM MEE: 0.5090522871421475\n",
      "SVR MEE: 0.5590546352107608\n"
     ]
    }
   ],
   "source": [
    "# MEE of each model\n",
    "print(\"--- TEST ---\")\n",
    "print(f\"NN-SGD MEE: {mean_euclidean_error(y_internal_test_cup, nn_sgd_preds_internal_test)}\")\n",
    "print(f\"NN-ADAM MEE: {mean_euclidean_error(y_internal_test_cup, nn_adam_preds_internal_test)}\")\n",
    "print(f\"SVR MEE: {mee(y_internal_test_cup, svr_preds_internal_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43ed2146-aa06-45cd-adaa-b90e9bbeb771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- TEST MEE Models --\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mee_nn_sgd_internal_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-- TEST MEE Models --\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEE SVC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmee_svr_internal_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - MEE NN-SGD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmee_nn_sgd_internal_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - MEE NN-Adam: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmee_nn_adam_internal_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mee_nn_sgd_internal_test' is not defined"
     ]
    }
   ],
   "source": [
    "print('-- TEST MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_internal_test:.4f} - MEE NN-SGD: {mee_nn_sgd_internal_test:.4f} - MEE NN-Adam: {mee_nn_adam_internal_test:.4f}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd255d5-830a-4bfc-a9bc-d0492f4e6c9a",
   "metadata": {},
   "source": [
    "## Arithmetic Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5264a99-4954-4a4e-85a6-cc48fbcd9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Arithmetic and Weighted Averange\n",
    "ensemble_train = np.zeros(y_train_cup.shape)\n",
    "\n",
    "en_av_train = ensemble_arithmetic_averange(ensemble_train, svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train)\n",
    "\n",
    "en_we_train = ensemble_weighted_averange(ensemble_train, 1,\n",
    "                                       svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train,\n",
    "                                       mee_svr_train, mee_nn_sgd_train, mee_nn_adam_train)\n",
    "\n",
    "# Ensemble Stacking. Valid estimator: LinearRegression, Ridge or Lasso\n",
    "en_stack_train = ensemble_stacking_cup(estimator='LinearRegression')\n",
    "x_stack_cup_train = np.hstack((svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train))\n",
    "en_stack_train.fit(x_stack_cup_train, y_train_cup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9169c30-8e4f-480f-9a34-679322a7f5d6",
   "metadata": {},
   "source": [
    "## Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de10070-6c5b-4a7b-9717-9377529bfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_we_train = ensemble_weighted_averange(ensemble_train, 1,\n",
    "                                       svr_preds_train, nn_sgd_preds_train, nn_adam_preds_train,\n",
    "                                       mee_svr_train, mee_nn_sgd_train, mee_nn_adam_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e2ec9-05d5-489f-ac1a-dc0d3ff1ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- TEST MEE Models --')\n",
    "print(f'MEE SVC: {mee_svr_internal_test:.4f} - MEE NN-SGD: {mee_nn_sgd_internal_test:.4f} - MEE NN-Adam: {mee_nn_adam_internal_test:.4f}' )\n",
    "\n",
    "print('\\n-- TEST Arithmetric Averange--')\n",
    "mee_internal_test_av_cup = mee(y_internal_test_cup, en_av_internal_test)\n",
    "mse_internal_test_av_cup = mean_squared_error(y_internal_test_cup, en_av_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_av_cup:.4f} - MEE: {mee_internal_test_av_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Weighted Averange --')\n",
    "mee_internal_test_we_cup = mee(y_internal_test_cup, en_we_internal_test)\n",
    "mse_internal_test_we_cup = mean_squared_error(y_internal_test_cup, en_we_internal_test)\n",
    "print(f'Loss (MSE): {mse_internal_test_we_cup:.4f} - MEE: {mee_internal_test_we_cup:.4f}')\n",
    "\n",
    "print('\\n-- TEST Stacking Schema --')\n",
    "mee_internal_test_stack_cup = mee(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "mse_internal_test_stack_cup = mean_squared_error(y_internal_test_cup, en_stack_train.predict(x_stack_cup_internal_test))\n",
    "print(f'Loss (MSE): {mse_internal_test_stack_cup:.4f} - MEE: {mee_internal_test_stack_cup:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlt",
   "language": "python",
   "name": "hlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
